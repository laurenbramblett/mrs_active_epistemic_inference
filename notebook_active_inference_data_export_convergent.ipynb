{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'aif_functions_isobeliefs_convergent' from 'c:\\\\Users\\\\qbr5kx\\\\OneDrive - University of Virginia\\\\Desktop\\\\UVA\\\\PhD Scratch\\\\Active_Epistemic_Inference\\\\aif_multi_robot//aif_catkin_ws/aif_gazebo/scripts\\\\aif_functions_isobeliefs_convergent.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os, sys, importlib, itertools\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Import the aif module\n",
    "pwd = os.path.abspath('') + \"/\"\n",
    "sys.path.insert(1,pwd + '/aif_catkin_ws/aif_gazebo/scripts/')\n",
    "import aif_functions_isobeliefs_convergent as aif\n",
    "\n",
    "importlib.reload(aif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9: Agents have selected goals [0, 0]. Execution Time: 0.0010004043579101562s Agents have converged to Goal 0 after 9 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [1, 1]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 1 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.0009226799011230469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2]. Execution Time: 0.0009987354278564453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.0019965171813964844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.001996755599975586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 2]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 3]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.0039937496185302734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 2]. Execution Time: 0.004998445510864258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 2, 3]. Execution Time: 0.006003141403198242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 3, 0]. Execution Time: 0.0039980411529541016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 10: Agents have selected goals [0, 0]. Execution Time: 0.014001607894897461s Agents have converged to Goal 0 after 10 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.015001058578491211s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.015088319778442383s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.016001462936401367s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.026993513107299805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [1, 1, 1]. Execution Time: 0.029999971389770508s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 80: Agents have selected goals [1, 1, 1]. Execution Time: 0.03190875053405762s Agents have converged to Goal 1 after 80 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 4]. Execution Time: 0.03300023078918457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.047995805740356445s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.06300067901611328s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 65: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.054939985275268555s Agents have converged to Goal 1 after 65 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05811476707458496s Agents have converged to Goal 2 after 26 iterations. Use EP: True\n",
      "Iteration 45: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07590174674987793s Agents have converged to Goal 0 after 45 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11454391479492188s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 55: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.11398625373840332s Agents have converged to Goal 1 after 55 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09300732612609863s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [0, 0]. Execution Time: 0.007092475891113281s Agents have converged to Goal 0 after 10 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [0, 0]. Execution Time: 0.007004737854003906s Agents have converged to Goal 0 after 22 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [1, 1]. Execution Time: 0.008091926574707031s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.010003089904785156s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.015000581741333008s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 2]. Execution Time: 0.013010501861572266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 64: Agents have selected goals [0, 0, 0]. Execution Time: 0.011904716491699219s Agents have converged to Goal 0 after 64 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [1, 1, 1]. Execution Time: 0.012999296188354492s Agents have converged to Goal 1 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.02099609375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 0]. Execution Time: 0.02699875831604004s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 2]. Execution Time: 0.02000117301940918s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 48: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.024999380111694336s Agents have converged to Goal 0 after 48 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 0]. Execution Time: 0.024999618530273438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 2, 0]. Execution Time: 0.032988786697387695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.036000728607177734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2, 2]. Execution Time: 0.034087181091308594s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  0.0 %-------------------\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.0009057521820068359s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [0, 0]. Execution Time: 0.0010023117065429688s Agents have converged to Goal 0 after 8 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [0, 0]. Execution Time: 0.0009996891021728516s Agents have converged to Goal 0 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0019834041595458984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.0009961128234863281s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 11: Agents have selected goals [0, 0, 0]. Execution Time: 0.0010063648223876953s Agents have converged to Goal 0 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.002000570297241211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0]. Execution Time: 0.0029964447021484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 1]. Execution Time: 0.00299835205078125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 4]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0, 0]. Execution Time: 0.005999326705932617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.0039997100830078125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 1, 0]. Execution Time: 0.0050029754638671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 4, 2]. Execution Time: 0.004000425338745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 12: Agents have selected goals [1, 1]. Execution Time: 0.018999814987182617s Agents have converged to Goal 1 after 12 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.018005847930908203s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [0, 0]. Execution Time: 0.021017789840698242s Agents have converged to Goal 0 after 10 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.023998260498046875s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.03799939155578613s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.0370020866394043s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0, 0]. Execution Time: 0.04001283645629883s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 0, 0]. Execution Time: 0.04096865653991699s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.055999040603637695s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04890775680541992s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3]. Execution Time: 0.055965423583984375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05388689041137695s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07391047477722168s Agents have converged to Goal 0 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0780026912689209s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11890363693237305s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.09399938583374023s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.008999347686767578s Agents have converged to Goal 1 after 31 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.006999015808105469s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [0, 0]. Execution Time: 0.008001565933227539s Agents have converged to Goal 0 after 31 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.008006811141967773s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.012942314147949219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.012080192565917969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.014010429382324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [3, 3, 3]. Execution Time: 0.013000011444091797s Agents have converged to Goal 3 after 33 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01990675926208496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018082618713378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 1]. Execution Time: 0.018008708953857422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 63: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.020093917846679688s Agents have converged to Goal 0 after 63 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.02700042724609375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 0]. Execution Time: 0.02499985694885254s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 0, 3]. Execution Time: 0.04699873924255371s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.038008928298950195s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  2.0 %-------------------\n",
      "Iteration 14: Agents have selected goals [1, 1]. Execution Time: 0.002916574478149414s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [2, 2]. Execution Time: 0.0s Agents have converged to Goal 2 after 13 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.001005411148071289s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0019397735595703125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3]. Execution Time: 0.0009984970092773438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3]. Execution Time: 0.0010309219360351562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.001991748809814453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 3]. Execution Time: 0.002089262008666992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1]. Execution Time: 0.003003358840942383s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2, 1]. Execution Time: 0.004000425338745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 3, 1]. Execution Time: 0.0040018558502197266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1, 0]. Execution Time: 0.005014657974243164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [1, 1]. Execution Time: 0.014991044998168945s Agents have converged to Goal 1 after 41 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.020104169845581055s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [2, 2]. Execution Time: 0.015001773834228516s Agents have converged to Goal 2 after 13 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1]. Execution Time: 0.017908573150634766s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.029000043869018555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [2, 2, 2]. Execution Time: 0.034922122955322266s Agents have converged to Goal 2 after 26 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [1, 1, 1]. Execution Time: 0.031021595001220703s Agents have converged to Goal 1 after 47 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3, 3]. Execution Time: 0.031999826431274414s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04899859428405762s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.053999900817871094s Agents have converged to Goal 2 after 32 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05299997329711914s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05999946594238281s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0839986801147461s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 1]. Execution Time: 0.08900022506713867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 59: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.12800121307373047s Agents have converged to Goal 2 after 59 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.10500001907348633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.006999969482421875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.007998228073120117s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 13: Agents have selected goals [2, 2]. Execution Time: 0.008000850677490234s Agents have converged to Goal 2 after 13 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.00901484489440918s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013997316360473633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [2, 2, 2]. Execution Time: 0.013000011444091797s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [2, 2, 2]. Execution Time: 0.011994361877441406s Agents have converged to Goal 2 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.012999773025512695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.021001100540161133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01801609992980957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.02201676368713379s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 99: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01990032196044922s Agents have converged to Goal 2 after 99 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 1]. Execution Time: 0.027013063430786133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 1]. Execution Time: 0.02691483497619629s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 58: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.031017065048217773s Agents have converged to Goal 2 after 58 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 2, 2]. Execution Time: 0.02900552749633789s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  4.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.00104522705078125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 13: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 13 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [3, 3]. Execution Time: 0.0009119510650634766s Agents have converged to Goal 3 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 1]. Execution Time: 0.0009846687316894531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 13: Agents have selected goals [1, 1, 1]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 1 after 13 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0019998550415039062s Agents have converged to Goal 1 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 0]. Execution Time: 0.002998828887939453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 0, 4]. Execution Time: 0.0009675025939941406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.0029036998748779297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.0029866695404052734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 0, 1]. Execution Time: 0.00499725341796875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 0, 4, 1]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 65: Agents have selected goals [0, 0]. Execution Time: 0.014000177383422852s Agents have converged to Goal 0 after 65 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [1, 1]. Execution Time: 0.014998912811279297s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [3, 3]. Execution Time: 0.01799774169921875s Agents have converged to Goal 3 after 13 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3]. Execution Time: 0.01600050926208496s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.031000614166259766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [1, 1, 1]. Execution Time: 0.028980255126953125s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.03399991989135742s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.03408360481262207s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.05891013145446777s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05599570274353027s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0610501766204834s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05798459053039551s Agents have converged to Goal 1 after 39 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.07899880409240723s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.08396673202514648s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1100013256072998s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0910794734954834s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 66: Agents have selected goals [0, 0]. Execution Time: 0.006996631622314453s Agents have converged to Goal 0 after 66 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.008996248245239258s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 13: Agents have selected goals [3, 3]. Execution Time: 0.007995128631591797s Agents have converged to Goal 3 after 13 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [3, 3]. Execution Time: 0.008084535598754883s Agents have converged to Goal 3 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.013025522232055664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013998031616210938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [1, 1, 1]. Execution Time: 0.017998695373535156s Agents have converged to Goal 1 after 18 iterations. Use EP: False\n",
      "Iteration 43: Agents have selected goals [1, 1, 1]. Execution Time: 0.016918420791625977s Agents have converged to Goal 1 after 43 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.019094228744506836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01900005340576172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01890087127685547s Agents have converged to Goal 1 after 26 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.020002365112304688s Agents have converged to Goal 1 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.026106834411621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.02610325813293457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.03200054168701172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.032087087631225586s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  6.0 %-------------------\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.001003265380859375s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.0009860992431640625s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.0010001659393310547s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009839534759521484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0]. Execution Time: 0.0009992122650146484s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2, 2]. Execution Time: 0.0010135173797607422s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 4]. Execution Time: 0.0010256767272949219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.002986907958984375s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 1]. Execution Time: 0.0020008087158203125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2]. Execution Time: 0.0020437240600585938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 4, 4]. Execution Time: 0.0020208358764648438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 1, 2]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2, 2]. Execution Time: 0.00400543212890625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 4, 4, 4]. Execution Time: 0.004083156585693359s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [0, 0]. Execution Time: 0.017999649047851562s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.018013715744018555s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2]. Execution Time: 0.01798701286315918s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.016996145248413086s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.034000396728515625s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.03492856025695801s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.031000614166259766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [2, 2, 2]. Execution Time: 0.03699946403503418s Agents have converged to Goal 2 after 43 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05099892616271973s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 68: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.050012826919555664s Agents have converged to Goal 2 after 68 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0570981502532959s Agents have converged to Goal 2 after 48 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.05388808250427246s Agents have converged to Goal 4 after 40 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08599996566772461s Agents have converged to Goal 0 after 47 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.07999110221862793s Agents have converged to Goal 2 after 55 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13500070571899414s Agents have converged to Goal 2 after 48 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.10900378227233887s Agents have converged to Goal 4 after 40 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.007010221481323242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.0069997310638427734s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [2, 2]. Execution Time: 0.007999897003173828s Agents have converged to Goal 2 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.00800013542175293s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.012998104095458984s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013092517852783203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.012084484100341797s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [2, 2, 2]. Execution Time: 0.013024330139160156s Agents have converged to Goal 2 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0]. Execution Time: 0.018080472946166992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019998788833618164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 69: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.019999027252197266s Agents have converged to Goal 2 after 69 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.020000696182250977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 0]. Execution Time: 0.024999618530273438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.02899909019470215s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 69: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.032002925872802734s Agents have converged to Goal 2 after 69 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 4, 2]. Execution Time: 0.028914928436279297s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  8.0 %-------------------\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.0009963512420654297s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.0s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0, 0]. Execution Time: 0.0020003318786621094s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2]. Execution Time: 0.0020024776458740234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 3]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0019998550415039062s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 3]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 3, 4]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.003078460693359375s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2, 2]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 3, 2]. Execution Time: 0.004001140594482422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 3, 4, 3]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [1, 1]. Execution Time: 0.016000747680664062s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.024982690811157227s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [1, 1]. Execution Time: 0.014999866485595703s Agents have converged to Goal 1 after 42 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4]. Execution Time: 0.019016027450561523s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 60: Agents have selected goals [1, 1, 1]. Execution Time: 0.0319976806640625s Agents have converged to Goal 1 after 60 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.030002117156982422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [2, 2, 2]. Execution Time: 0.029985666275024414s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [4, 4, 4]. Execution Time: 0.09299969673156738s Agents have converged to Goal 4 after 30 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.050916194915771484s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05407905578613281s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.052098751068115234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05491924285888672s Agents have converged to Goal 3 after 35 iterations. Use EP: True\n",
      "Iteration 58: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.0789039134979248s Agents have converged to Goal 0 after 58 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.07797813415527344s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 65: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11498284339904785s Agents have converged to Goal 2 after 65 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.10008978843688965s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [1, 1]. Execution Time: 0.008134126663208008s Agents have converged to Goal 1 after 38 iterations. Use EP: False\n",
      "Iteration 38: Agents have selected goals [0, 0]. Execution Time: 0.007999897003173828s Agents have converged to Goal 0 after 38 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [0, 0]. Execution Time: 0.009011268615722656s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [4, 4]. Execution Time: 0.008916378021240234s Agents have converged to Goal 4 after 36 iterations. Use EP: False\n",
      "Iteration 55: Agents have selected goals [0, 0, 0]. Execution Time: 0.016907215118408203s Agents have converged to Goal 0 after 55 iterations. Use EP: False\n",
      "Iteration 46: Agents have selected goals [0, 0, 0]. Execution Time: 0.012928485870361328s Agents have converged to Goal 0 after 46 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [2, 2, 2]. Execution Time: 0.011998653411865234s Agents have converged to Goal 2 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.012908458709716797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0]. Execution Time: 0.01900172233581543s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.020000457763671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.018983840942382812s Agents have converged to Goal 2 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 0]. Execution Time: 0.020979642868041992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.025127887725830078s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.02599644660949707s Agents have converged to Goal 0 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.03201651573181152s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 2, 4]. Execution Time: 0.02800297737121582s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  10.0 %-------------------\n",
      "Iteration 27: Agents have selected goals [0, 0]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0010194778442382812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [0, 0, 0]. Execution Time: 0.0010001659393310547s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 2, 2]. Execution Time: 0.0020084381103515625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3]. Execution Time: 0.0010089874267578125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 4]. Execution Time: 0.0019659996032714844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.003086090087890625s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 2]. Execution Time: 0.0020041465759277344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 3]. Execution Time: 0.002007722854614258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 4, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.0040323734283447266s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 2, 2]. Execution Time: 0.003022909164428711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 3, 0]. Execution Time: 0.004999637603759766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 4, 0, 0]. Execution Time: 0.003999233245849609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 40: Agents have selected goals [1, 1]. Execution Time: 0.020963430404663086s Agents have converged to Goal 1 after 40 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.016011953353881836s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.016091346740722656s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [3, 3]. Execution Time: 0.016973495483398438s Agents have converged to Goal 3 after 16 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [0, 0, 0]. Execution Time: 0.031002283096313477s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2, 2]. Execution Time: 0.032000064849853516s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [3, 3, 3]. Execution Time: 0.03499913215637207s Agents have converged to Goal 3 after 13 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [4, 4, 4]. Execution Time: 0.03108954429626465s Agents have converged to Goal 4 after 27 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04891061782836914s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08589816093444824s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.055077552795410156s Agents have converged to Goal 3 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.06098747253417969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07891011238098145s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08190798759460449s Agents have converged to Goal 2 after 48 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.12909579277038574s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.12098383903503418s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.009002685546875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [2, 2]. Execution Time: 0.00800013542175293s Agents have converged to Goal 2 after 31 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.00800013542175293s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [4, 4]. Execution Time: 0.007987022399902344s Agents have converged to Goal 4 after 11 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013910770416259766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013020038604736328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [3, 3, 3]. Execution Time: 0.013994455337524414s Agents have converged to Goal 3 after 17 iterations. Use EP: False\n",
      "Iteration 48: Agents have selected goals [3, 3, 3]. Execution Time: 0.014001131057739258s Agents have converged to Goal 3 after 48 iterations. Use EP: False\n",
      "Iteration 58: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.019002199172973633s Agents have converged to Goal 1 after 58 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2]. Execution Time: 0.018013715744018555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 59: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.021997928619384766s Agents have converged to Goal 3 after 59 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 3, 4, 3]. Execution Time: 0.019089937210083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 0]. Execution Time: 0.027906417846679688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 2, 0]. Execution Time: 0.0370020866394043s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0, 0]. Execution Time: 0.031917572021484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.029079437255859375s Agents have converged to Goal 4 after 29 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  12.0 %-------------------\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.0010066032409667969s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.0010256767272949219s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.0009946823120117188s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.0009949207305908203s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0020132064819335938s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0030019283294677734s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 0, 4]. Execution Time: 0.0019991397857666016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.002998828887939453s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 0, 0]. Execution Time: 0.0029866695404052734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 0, 4, 3]. Execution Time: 0.003087759017944336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.01500082015991211s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [1, 1]. Execution Time: 0.014997720718383789s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.01700115203857422s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [3, 3]. Execution Time: 0.016000032424926758s Agents have converged to Goal 3 after 28 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.03209042549133301s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [1, 1, 1]. Execution Time: 0.03000020980834961s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.031000137329101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 0]. Execution Time: 0.031001806259155273s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04700207710266113s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05399775505065918s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05298280715942383s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05588865280151367s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07608795166015625s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0780031681060791s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.11299777030944824s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 49: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.09708428382873535s Agents have converged to Goal 4 after 49 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.009000778198242188s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [1, 1]. Execution Time: 0.009998083114624023s Agents have converged to Goal 1 after 23 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.007994651794433594s Agents have converged to Goal 1 after 11 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [3, 3]. Execution Time: 0.007999658584594727s Agents have converged to Goal 3 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.015995502471923828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [1, 1, 1]. Execution Time: 0.013094186782836914s Agents have converged to Goal 1 after 23 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [1, 1, 1]. Execution Time: 0.012999773025512695s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 2, 3]. Execution Time: 0.014002561569213867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 85: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.028000354766845703s Agents have converged to Goal 1 after 85 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.022089719772338867s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1]. Execution Time: 0.02009105682373047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 1, 4]. Execution Time: 0.019980192184448242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.024031877517700195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 49: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.023997783660888672s Agents have converged to Goal 1 after 49 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.03390932083129883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 4, 4, 4]. Execution Time: 0.028092384338378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  14.000000000000002 %-------------------\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [3, 3]. Execution Time: 0.0010192394256591797s Agents have converged to Goal 3 after 8 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1]. Execution Time: 0.0009970664978027344s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1, 1]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1]. Execution Time: 0.0010008811950683594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.002999544143676758s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1]. Execution Time: 0.0020885467529296875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 3]. Execution Time: 0.0020143985748291016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 4]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0029990673065185547s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1, 1]. Execution Time: 0.001992464065551758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 3, 0]. Execution Time: 0.0039017200469970703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 4, 2]. Execution Time: 0.002976655960083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1]. Execution Time: 0.017999887466430664s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 89: Agents have selected goals [1, 1]. Execution Time: 0.015091180801391602s Agents have converged to Goal 1 after 89 iterations. Use EP: True\n",
      "Iteration 9: Agents have selected goals [3, 3]. Execution Time: 0.01601099967956543s Agents have converged to Goal 3 after 9 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.016017913818359375s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.028041601181030273s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.02900099754333496s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [3, 3, 3]. Execution Time: 0.03602170944213867s Agents have converged to Goal 3 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 1]. Execution Time: 0.03200221061706543s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04801440238952637s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05099916458129883s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05100059509277344s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.055992841720581055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07799983024597168s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07809114456176758s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 72: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11299800872802734s Agents have converged to Goal 3 after 72 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 2]. Execution Time: 0.09299802780151367s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [1, 1]. Execution Time: 0.00800180435180664s Agents have converged to Goal 1 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.01001739501953125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [3, 3]. Execution Time: 0.006998777389526367s Agents have converged to Goal 3 after 15 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [4, 4]. Execution Time: 0.006998777389526367s Agents have converged to Goal 4 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.012942790985107422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.012979984283447266s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [3, 3, 3]. Execution Time: 0.013010263442993164s Agents have converged to Goal 3 after 31 iterations. Use EP: False\n",
      "Iteration 13: Agents have selected goals [4, 4, 4]. Execution Time: 0.013906240463256836s Agents have converged to Goal 4 after 13 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.024000167846679688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 60: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01900029182434082s Agents have converged to Goal 1 after 60 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 3]. Execution Time: 0.019003868103027344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 4, 4]. Execution Time: 0.018998146057128906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.02510523796081543s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1, 2]. Execution Time: 0.02999114990234375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.030939340591430664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.028000593185424805s Agents have converged to Goal 4 after 20 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  16.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009732246398925781s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0010123252868652344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0010211467742919922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009396076202392578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.0010409355163574219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 0]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 1]. Execution Time: 0.0009992122650146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 3]. Execution Time: 0.0010035037994384766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0]. Execution Time: 0.002998828887939453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 0, 1]. Execution Time: 0.002003908157348633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 1, 3]. Execution Time: 0.002001047134399414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 3, 3]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 1]. Execution Time: 0.003005504608154297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 0, 1, 1]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 1, 3, 3]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 3, 3, 3]. Execution Time: 0.0030159950256347656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.014922380447387695s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [2, 2]. Execution Time: 0.018912553787231445s Agents have converged to Goal 2 after 12 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.024999380111694336s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [1, 1]. Execution Time: 0.016001224517822266s Agents have converged to Goal 1 after 53 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [0, 0, 0]. Execution Time: 0.028969764709472656s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.032901763916015625s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.03107166290283203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [3, 3, 3]. Execution Time: 0.03191733360290527s Agents have converged to Goal 3 after 35 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.049100399017333984s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.049016714096069336s Agents have converged to Goal 1 after 47 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.052997589111328125s Agents have converged to Goal 3 after 31 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.06000375747680664s Agents have converged to Goal 3 after 35 iterations. Use EP: True\n",
      "Iteration 46: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07609248161315918s Agents have converged to Goal 1 after 46 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0790860652923584s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 1]. Execution Time: 0.11298274993896484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 3, 3]. Execution Time: 0.0969991683959961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [1, 1]. Execution Time: 0.007039546966552734s Agents have converged to Goal 1 after 23 iterations. Use EP: False\n",
      "Iteration 13: Agents have selected goals [2, 2]. Execution Time: 0.007969379425048828s Agents have converged to Goal 2 after 13 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [0, 0]. Execution Time: 0.007915258407592773s Agents have converged to Goal 0 after 29 iterations. Use EP: False\n",
      "Iteration 41: Agents have selected goals [3, 3]. Execution Time: 0.00798940658569336s Agents have converged to Goal 3 after 41 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.014001846313476562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [2, 2, 2]. Execution Time: 0.013000249862670898s Agents have converged to Goal 2 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013035058975219727s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [3, 3, 3]. Execution Time: 0.012904882431030273s Agents have converged to Goal 3 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018881559371948242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.019900083541870117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.01900005340576172s Agents have converged to Goal 3 after 33 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.02008652687072754s Agents have converged to Goal 3 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.026997804641723633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.02491021156311035s Agents have converged to Goal 1 after 48 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.031078577041625977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 2, 2, 4]. Execution Time: 0.02900409698486328s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  18.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0009987354278564453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3]. Execution Time: 0.001991748809814453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1]. Execution Time: 0.0009989738464355469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.0010361671447753906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2]. Execution Time: 0.0019881725311279297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 1]. Execution Time: 0.003013134002685547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 1, 2]. Execution Time: 0.004004955291748047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 2, 1]. Execution Time: 0.0039997100830078125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.017000675201416016s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [2, 2]. Execution Time: 0.016908884048461914s Agents have converged to Goal 2 after 27 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.01608753204345703s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3]. Execution Time: 0.016002655029296875s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [1, 1, 1]. Execution Time: 0.03104424476623535s Agents have converged to Goal 1 after 41 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.0299985408782959s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [3, 3, 3]. Execution Time: 0.03108692169189453s Agents have converged to Goal 3 after 28 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1]. Execution Time: 0.031001567840576172s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05009913444519043s Agents have converged to Goal 1 after 39 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.055997610092163086s Agents have converged to Goal 2 after 36 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.055001020431518555s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 63: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05509233474731445s Agents have converged to Goal 1 after 63 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07709407806396484s Agents have converged to Goal 1 after 39 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08199834823608398s Agents have converged to Goal 1 after 47 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1130208969116211s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09600210189819336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.008002519607543945s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 39: Agents have selected goals [2, 2]. Execution Time: 0.008000373840332031s Agents have converged to Goal 2 after 39 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.008090734481811523s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [3, 3]. Execution Time: 0.008000373840332031s Agents have converged to Goal 3 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.016000032424926758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [2, 2, 2]. Execution Time: 0.01397705078125s Agents have converged to Goal 2 after 37 iterations. Use EP: False\n",
      "Iteration 64: Agents have selected goals [3, 3, 3]. Execution Time: 0.013900518417358398s Agents have converged to Goal 3 after 64 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [1, 1, 1]. Execution Time: 0.013021707534790039s Agents have converged to Goal 1 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.018798351287841797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2]. Execution Time: 0.01900005340576172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.01909351348876953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1]. Execution Time: 0.020087480545043945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.023906946182250977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 2, 2]. Execution Time: 0.02797698974609375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1, 1]. Execution Time: 0.03190755844116211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 1, 2]. Execution Time: 0.028994321823120117s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  20.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0008900165557861328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 3]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.0019979476928710938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 3]. Execution Time: 0.0010006427764892578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 3, 0]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 1]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1, 2]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 3, 0]. Execution Time: 0.0040018558502197266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 3, 0, 0]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 48: Agents have selected goals [0, 0]. Execution Time: 0.01999950408935547s Agents have converged to Goal 0 after 48 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1]. Execution Time: 0.015001058578491211s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [2, 2]. Execution Time: 0.013998031616210938s Agents have converged to Goal 2 after 26 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [4, 4]. Execution Time: 0.018997907638549805s Agents have converged to Goal 4 after 35 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.03499770164489746s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [2, 2, 2]. Execution Time: 0.03209662437438965s  Agents have converged to Goal 2 after 31 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1]. Execution Time: 0.030000925064086914s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 4, 3]. Execution Time: 0.034996747970581055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.052097320556640625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.06200003623962402s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.07407951354980469s Agents have converged to Goal 1 after 36 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.059999942779541016s Agents have converged to Goal 2 after 32 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07899689674377441s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.07700228691101074s Agents have converged to Goal 2 after 38 iterations. Use EP: True\n",
      "Iteration 67: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.17110037803649902s Agents have converged to Goal 2 after 67 iterations. Use EP: True\n",
      "Iteration 52: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.1079869270324707s Agents have converged to Goal 2 after 52 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.008996248245239258s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [1, 1]. Execution Time: 0.00897836685180664s Agents have converged to Goal 1 after 25 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [2, 2]. Execution Time: 0.012000083923339844s Agents have converged to Goal 2 after 33 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [4, 4]. Execution Time: 0.00701904296875s Agents have converged to Goal 4 after 35 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.013887405395507812s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [2, 2, 2]. Execution Time: 0.01491093635559082s Agents have converged to Goal 2 after 33 iterations. Use EP: False\n",
      "Iteration 38: Agents have selected goals [2, 2, 2]. Execution Time: 0.014101743698120117s Agents have converged to Goal 2 after 38 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [2, 2, 2]. Execution Time: 0.014000177383422852s Agents have converged to Goal 2 after 33 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0670013427734375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 70: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.023087501525878906s Agents have converged to Goal 2 after 70 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.018993616104125977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.020093679428100586s Agents have converged to Goal 2 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.028097152709960938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.028007030487060547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 3]. Execution Time: 0.03506040573120117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.027976036071777344s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  22.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1]. Execution Time: 0.0010001659393310547s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 1, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 0]. Execution Time: 0.0019979476928710938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.002887725830078125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0019989013671875s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 0]. Execution Time: 0.002034425735473633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 0, 1]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.001990079879760742s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.003002643585205078s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 0, 1]. Execution Time: 0.0040013790130615234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 0, 1, 3]. Execution Time: 0.004999637603759766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1]. Execution Time: 0.01699995994567871s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.017998933792114258s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.015981435775756836s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.015995264053344727s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1]. Execution Time: 0.029018402099609375s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [1, 1, 1]. Execution Time: 0.03499913215637207s Agents have converged to Goal 1 after 55 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.03200101852416992s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.03400158882141113s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 65: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05501294136047363s Agents have converged to Goal 1 after 65 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04909658432006836s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.057099342346191406s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05499863624572754s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07608294486999512s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08098196983337402s Agents have converged to Goal 1 after 38 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.11300039291381836s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 3]. Execution Time: 0.09291338920593262s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [1, 1]. Execution Time: 0.007989168167114258s Agents have converged to Goal 1 after 38 iterations. Use EP: False\n",
      "Iteration 54: Agents have selected goals [1, 1]. Execution Time: 0.0069997310638427734s Agents have converged to Goal 1 after 54 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.007984638214111328s Agents have converged to Goal 1 after 31 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.008020162582397461s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.014899253845214844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [0, 0, 0]. Execution Time: 0.01299738883972168s Agents have converged to Goal 0 after 42 iterations. Use EP: False\n",
      "Iteration 38: Agents have selected goals [1, 1, 1]. Execution Time: 0.013048410415649414s Agents have converged to Goal 1 after 38 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [1, 1, 1]. Execution Time: 0.013000249862670898s Agents have converged to Goal 1 after 36 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.020000457763671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 68: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018032073974609375s Agents have converged to Goal 0 after 68 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.019999980926513672s Agents have converged to Goal 1 after 36 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.02091526985168457s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0, 1]. Execution Time: 0.0279998779296875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.025011777877807617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.03200507164001465s Agents have converged to Goal 1 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 4, 4]. Execution Time: 0.031955718994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  24.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.0010013580322265625s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.002002716064453125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3]. Execution Time: 0.0009870529174804688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 3]. Execution Time: 0.0010101795196533203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.003006458282470703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3, 3]. Execution Time: 0.004083395004272461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 3, 0]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.003999233245849609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3, 3, 0]. Execution Time: 0.0040874481201171875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 3, 0, 4]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1]. Execution Time: 0.015991926193237305s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [2, 2]. Execution Time: 0.014908313751220703s Agents have converged to Goal 2 after 41 iterations. Use EP: True\n",
      "Iteration 51: Agents have selected goals [0, 0]. Execution Time: 0.015036582946777344s Agents have converged to Goal 0 after 51 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [4, 4]. Execution Time: 0.017012596130371094s Agents have converged to Goal 4 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.02910923957824707s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.035999298095703125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 49: Agents have selected goals [3, 3, 3]. Execution Time: 0.03799843788146973s Agents have converged to Goal 3 after 49 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [3, 3, 3]. Execution Time: 0.03198695182800293s Agents have converged to Goal 3 after 37 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.04897022247314453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 72: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05000185966491699s Agents have converged to Goal 1 after 72 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.058882951736450195s Agents have converged to Goal 3 after 31 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05599570274353027s Agents have converged to Goal 3 after 33 iterations. Use EP: True\n",
      "Iteration 56: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07689666748046875s Agents have converged to Goal 1 after 56 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07709789276123047s Agents have converged to Goal 1 after 55 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11490750312805176s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.09509038925170898s Agents have converged to Goal 3 after 32 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [1, 1]. Execution Time: 0.00800180435180664s Agents have converged to Goal 1 after 42 iterations. Use EP: False\n",
      "Iteration 80: Agents have selected goals [2, 2]. Execution Time: 0.008907318115234375s Agents have converged to Goal 2 after 80 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [3, 3]. Execution Time: 0.007019996643066406s Agents have converged to Goal 3 after 33 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [4, 4]. Execution Time: 0.008090496063232422s Agents have converged to Goal 4 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.013002157211303711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013000249862670898s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.013009071350097656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [4, 4, 4]. Execution Time: 0.012999296188354492s Agents have converged to Goal 4 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.020008563995361328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.020915985107421875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 49: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.018091201782226562s Agents have converged to Goal 3 after 49 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.01999974250793457s Agents have converged to Goal 3 after 33 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.024025917053222656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1, 2]. Execution Time: 0.027004718780517578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.05008959770202637s Agents have converged to Goal 3 after 42 iterations. Use EP: False\n",
      "Iteration 41: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.027998685836791992s Agents have converged to Goal 4 after 41 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  26.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.0s Agents have converged to Goal 3 after 12 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [4, 4]. Execution Time: 0.0s Agents have converged to Goal 4 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0019979476928710938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.0010044574737548828s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1]. Execution Time: 0.000997781753540039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 11: Agents have selected goals [4, 4, 4]. Execution Time: 0.00099945068359375s Agents have converged to Goal 4 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0020008087158203125s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 3]. Execution Time: 0.002002239227294922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 1]. Execution Time: 0.0020911693572998047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.004033327102661133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0030007362365722656s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 3, 1]. Execution Time: 0.004013538360595703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 1, 0]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [0, 0]. Execution Time: 0.017000675201416016s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [1, 1]. Execution Time: 0.01698756217956543s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.0169985294342041s Agents have converged to Goal 3 after 12 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.01809239387512207s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.028888225555419922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.03007960319519043s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 56: Agents have selected goals [3, 3, 3]. Execution Time: 0.030092716217041016s Agents have converged to Goal 3 after 56 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1]. Execution Time: 0.031002044677734375s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05190253257751465s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.05788087844848633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05301189422607422s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05405998229980469s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08598041534423828s Agents have converged to Goal 1 after 40 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08099961280822754s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.11588716506958008s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 1, 1, 4]. Execution Time: 0.09388852119445801s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [0, 0]. Execution Time: 0.011015892028808594s Agents have converged to Goal 0 after 43 iterations. Use EP: False\n",
      "Iteration 34: Agents have selected goals [1, 1]. Execution Time: 0.008000373840332031s Agents have converged to Goal 1 after 34 iterations. Use EP: False\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.008001089096069336s Agents have converged to Goal 3 after 12 iterations. Use EP: False\n",
      "Iteration 24: Agents have selected goals [3, 3]. Execution Time: 0.00899958610534668s Agents have converged to Goal 3 after 24 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.013000011444091797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.01204681396484375s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [3, 3, 3]. Execution Time: 0.014013290405273438s Agents have converged to Goal 3 after 27 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [3, 3, 3]. Execution Time: 0.014000177383422852s Agents have converged to Goal 3 after 22 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018018722534179688s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018016338348388672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3, 0]. Execution Time: 0.018908262252807617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.024001121520996094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 1]. Execution Time: 0.02488541603088379s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 2]. Execution Time: 0.03198671340942383s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.03200244903564453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.03199934959411621s Agents have converged to Goal 3 after 100 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  28.000000000000004 %-------------------\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.001010894775390625s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0009992122650146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0010905265808105469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 10: Agents have selected goals [1, 1, 1]. Execution Time: 0.001085519790649414s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1, 0]. Execution Time: 0.0009987354278564453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 2]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.002000570297241211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 2]. Execution Time: 0.0020008087158203125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 2, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 4]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.0030035972595214844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 2, 0]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 2, 0, 3]. Execution Time: 0.005003452301025391s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 4, 4]. Execution Time: 0.0039055347442626953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.013911247253417969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.015900850296020508s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0]. Execution Time: 0.01589179039001465s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0]. Execution Time: 0.016994476318359375s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [1, 1, 1]. Execution Time: 0.0280001163482666s Agents have converged to Goal 1 after 12 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0300295352935791s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.030013084411621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [0, 0, 0]. Execution Time: 0.03200030326843262s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 46: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05099964141845703s Agents have converged to Goal 1 after 46 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.049001455307006836s Agents have converged to Goal 0 after 47 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05200028419494629s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.05801868438720703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 86: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07599973678588867s Agents have converged to Goal 1 after 86 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09208250045776367s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 0, 0]. Execution Time: 0.11309361457824707s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09499287605285645s Agents have converged to Goal 0 after 42 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.008025646209716797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.008002042770385742s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 92: Agents have selected goals [3, 3]. Execution Time: 0.007987022399902344s Agents have converged to Goal 3 after 92 iterations. Use EP: False\n",
      "Iteration 45: Agents have selected goals [0, 0]. Execution Time: 0.0080108642578125s Agents have converged to Goal 0 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013086795806884766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.015999794006347656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 84: Agents have selected goals [3, 3, 3]. Execution Time: 0.012008905410766602s Agents have converged to Goal 3 after 84 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01307225227355957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.01890110969543457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.02299785614013672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019110918045043945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 3]. Execution Time: 0.020000696182250977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.024994373321533203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 0, 2]. Execution Time: 0.023999452590942383s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 2, 3, 2]. Execution Time: 0.030997037887573242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3, 0]. Execution Time: 0.029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  30.0 %-------------------\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0010676383972167969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0010063648223876953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 3]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2]. Execution Time: 0.0020029544830322266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.001953125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.001998424530029297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 3, 2]. Execution Time: 0.0019974708557128906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 3]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.0028760433197021484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 2]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 3, 2, 3]. Execution Time: 0.004997730255126953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 3, 0]. Execution Time: 0.004079103469848633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.013903617858886719s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 57: Agents have selected goals [0, 0]. Execution Time: 0.015006065368652344s Agents have converged to Goal 0 after 57 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.018910646438598633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [3, 3]. Execution Time: 0.015994787216186523s Agents have converged to Goal 3 after 8 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.027897119522094727s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.032077789306640625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.030115842819213867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.030912399291992188s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.05200052261352539s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.048996925354003906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 2]. Execution Time: 0.05301332473754883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05900287628173828s Agents have converged to Goal 3 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.08099913597106934s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08091044425964355s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 69: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11594510078430176s Agents have converged to Goal 3 after 69 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 0]. Execution Time: 0.09799981117248535s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.007999658584594727s Agents have converged to Goal 1 after 10 iterations. Use EP: False\n",
      "Iteration 46: Agents have selected goals [2, 2]. Execution Time: 0.00799560546875s Agents have converged to Goal 2 after 46 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.008000373840332031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 9: Agents have selected goals [3, 3]. Execution Time: 0.008008718490600586s Agents have converged to Goal 3 after 9 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.013068675994873047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.013000249862670898s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 74: Agents have selected goals [3, 3, 3]. Execution Time: 0.013102531433105469s Agents have converged to Goal 3 after 74 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.012967109680175781s Agents have converged to Goal 1 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.042999982833862305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 1]. Execution Time: 0.01900005340576172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 2, 3]. Execution Time: 0.019999980926513672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2]. Execution Time: 0.019941329956054688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.03499794006347656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2, 1]. Execution Time: 0.027002573013305664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 1, 3]. Execution Time: 0.03299880027770996s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.0289309024810791s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  32.0 %-------------------\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.0s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2]. Execution Time: 0.002000570297241211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2]. Execution Time: 0.0019991397857666016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 0]. Execution Time: 0.001001119613647461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 2]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 0, 3]. Execution Time: 0.0030024051666259766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.002910614013671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 2, 0]. Execution Time: 0.003997802734375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 0, 3]. Execution Time: 0.0029990673065185547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 0, 3, 0]. Execution Time: 0.004999399185180664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [0, 0]. Execution Time: 0.01399993896484375s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.014995813369750977s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [2, 2]. Execution Time: 0.015000343322753906s Agents have converged to Goal 2 after 64 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [2, 2]. Execution Time: 0.01592278480529785s Agents have converged to Goal 2 after 33 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.033002614974975586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.029999971389770508s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [3, 3, 3]. Execution Time: 0.03201031684875488s Agents have converged to Goal 3 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 4]. Execution Time: 0.031996965408325195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 1]. Execution Time: 0.047890424728393555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05093240737915039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05600404739379883s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05599784851074219s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 69: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07800078392028809s Agents have converged to Goal 0 after 69 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09008955955505371s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11199831962585449s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 0]. Execution Time: 0.09689998626708984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 77: Agents have selected goals [0, 0]. Execution Time: 0.00806570053100586s Agents have converged to Goal 0 after 77 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.008092164993286133s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.009997367858886719s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [3, 3]. Execution Time: 0.00798940658569336s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01299905776977539s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.012949228286743164s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [3, 3, 3]. Execution Time: 0.012967109680175781s Agents have converged to Goal 3 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.012900352478027344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.017019987106323242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.022000551223754883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 3, 3]. Execution Time: 0.020002126693725586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.01800704002380371s Agents have converged to Goal 3 after 34 iterations. Use EP: False\n",
      "Iteration 70: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.023888826370239258s Agents have converged to Goal 0 after 70 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.024999618530273438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.030996322631835938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.037099599838256836s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  34.0 %-------------------\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.0s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.001005411148071289s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.0010619163513183594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0, 0]. Execution Time: 0.0018982887268066406s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0, 2]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1]. Execution Time: 0.0019979476928710938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 4]. Execution Time: 0.000911712646484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.002020120620727539s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1, 0]. Execution Time: 0.003001689910888672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 4, 3]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.0030031204223632812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 1, 0]. Execution Time: 0.0029637813568115234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1, 0, 3]. Execution Time: 0.0030019283294677734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 4, 3, 0]. Execution Time: 0.004000425338745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.01499176025390625s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0]. Execution Time: 0.015999555587768555s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [0, 0]. Execution Time: 0.019005537033081055s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1]. Execution Time: 0.015999555587768555s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0]. Execution Time: 0.028992652893066406s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 86: Agents have selected goals [2, 2, 2]. Execution Time: 0.029001235961914062s Agents have converged to Goal 2 after 86 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [0, 0, 0]. Execution Time: 0.030999183654785156s Agents have converged to Goal 0 after 35 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0, 0]. Execution Time: 0.032001495361328125s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.051909446716308594s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.048905372619628906s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.051906585693359375s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 3]. Execution Time: 0.058104515075683594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07711458206176758s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08099913597106934s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 3]. Execution Time: 0.11188530921936035s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 46: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09390926361083984s Agents have converged to Goal 0 after 46 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.01009368896484375s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.007907629013061523s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [0, 0]. Execution Time: 0.007997512817382812s Agents have converged to Goal 0 after 22 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.008094072341918945s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.011991739273071289s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 89: Agents have selected goals [2, 2, 2]. Execution Time: 0.013992071151733398s Agents have converged to Goal 2 after 89 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.013985157012939453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [0, 0, 0]. Execution Time: 0.014989137649536133s Agents have converged to Goal 0 after 26 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018887996673583984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.025997400283813477s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 0]. Execution Time: 0.019012928009033203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019021272659301758s Agents have converged to Goal 0 after 38 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 0]. Execution Time: 0.02408289909362793s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.025970458984375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 57: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07100152969360352s Agents have converged to Goal 0 after 57 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.027998924255371094s Agents have converged to Goal 0 after 27 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  36.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0]. Execution Time: 0.0009865760803222656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 2]. Execution Time: 0.002002239227294922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.0030045509338378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 2, 0]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 0]. Execution Time: 0.002001047134399414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 1]. Execution Time: 0.0039997100830078125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2, 0]. Execution Time: 0.004000425338745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 2, 0, 0]. Execution Time: 0.003998517990112305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 0, 0]. Execution Time: 0.003995656967163086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 39: Agents have selected goals [1, 1]. Execution Time: 0.013997077941894531s Agents have converged to Goal 1 after 39 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.016001462936401367s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [3, 3]. Execution Time: 0.016013622283935547s Agents have converged to Goal 3 after 19 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2]. Execution Time: 0.01600193977355957s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.030033111572265625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.03201723098754883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 67: Agents have selected goals [2, 2, 2]. Execution Time: 0.03096771240234375s Agents have converged to Goal 2 after 67 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0, 0]. Execution Time: 0.03108835220336914s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.06300234794616699s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2]. Execution Time: 0.054000139236450195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 40: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05500030517578125s Agents have converged to Goal 2 after 40 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 1]. Execution Time: 0.05491280555725098s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07696533203125s Agents have converged to Goal 1 after 43 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08097457885742188s Agents have converged to Goal 0 after 42 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11288237571716309s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09588766098022461s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [1, 1]. Execution Time: 0.011002302169799805s Agents have converged to Goal 1 after 39 iterations. Use EP: False\n",
      "Iteration 83: Agents have selected goals [1, 1]. Execution Time: 0.009999275207519531s Agents have converged to Goal 1 after 83 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.006982088088989258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.00889730453491211s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.018996715545654297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.0170133113861084s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2]. Execution Time: 0.014079093933105469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.013000011444091797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.019112348556518555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01789546012878418s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01798534393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.022016048431396484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.028104305267333984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 1]. Execution Time: 0.026002168655395508s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.03199887275695801s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 3, 3, 0]. Execution Time: 0.028087139129638672s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  38.0 %-------------------\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.0s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2]. Execution Time: 0.0010068416595458984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.0010042190551757812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 1]. Execution Time: 0.0020012855529785156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 4]. Execution Time: 0.000988006591796875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0]. Execution Time: 0.002001047134399414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.002979755401611328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 1, 3]. Execution Time: 0.0009992122650146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 4, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0, 1]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1, 1]. Execution Time: 0.003002166748046875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 1, 3, 2]. Execution Time: 0.00402069091796875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 4, 2, 3]. Execution Time: 0.0030858516693115234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.016995668411254883s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [1, 1]. Execution Time: 0.015999317169189453s Agents have converged to Goal 1 after 36 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [3, 3]. Execution Time: 0.015101909637451172s Agents have converged to Goal 3 after 18 iterations. Use EP: True\n",
      "Iteration 83: Agents have selected goals [1, 1]. Execution Time: 0.015976428985595703s Agents have converged to Goal 1 after 83 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [0, 0, 0]. Execution Time: 0.027907609939575195s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [2, 2, 2]. Execution Time: 0.03408527374267578s Agents have converged to Goal 2 after 36 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1]. Execution Time: 0.031097412109375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 4]. Execution Time: 0.031000137329101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.053015947341918945s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 72: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0511019229888916s Agents have converged to Goal 2 after 72 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05700182914733887s Agents have converged to Goal 3 after 29 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05601906776428223s Agents have converged to Goal 3 after 29 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08000349998474121s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08001303672790527s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 2]. Execution Time: 0.11088299751281738s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.09700155258178711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.007007598876953125s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [0, 0]. Execution Time: 0.008995294570922852s Agents have converged to Goal 0 after 32 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [3, 3]. Execution Time: 0.008000612258911133s Agents have converged to Goal 3 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3]. Execution Time: 0.007997274398803711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.012996435165405273s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.014000415802001953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013096332550048828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [0, 0, 0]. Execution Time: 0.012992382049560547s Agents have converged to Goal 0 after 37 iterations. Use EP: False\n",
      "Iteration 98: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01792144775390625s Agents have converged to Goal 0 after 98 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018000125885009766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 3]. Execution Time: 0.018990516662597656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 0, 0]. Execution Time: 0.01999807357788086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 0]. Execution Time: 0.02508258819580078s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.025907039642333984s Agents have converged to Goal 0 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3, 0]. Execution Time: 0.0319828987121582s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.027076244354248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  40.0 %-------------------\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.0010001659393310547s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.0009920597076416016s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [3, 3]. Execution Time: 0.0009968280792236328s Agents have converged to Goal 3 after 13 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 2]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [0, 0, 0]. Execution Time: 0.0010097026824951172s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 2]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0029888153076171875s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2]. Execution Time: 0.0019919872283935547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 3]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 3]. Execution Time: 0.0030183792114257812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.002000093460083008s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 3, 3]. Execution Time: 0.006096363067626953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 3, 1]. Execution Time: 0.003904104232788086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.013988018035888672s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [0, 0]. Execution Time: 0.016000032424926758s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [3, 3]. Execution Time: 0.017986774444580078s Agents have converged to Goal 3 after 15 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.018987655639648438s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.03000020980834961s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0, 0]. Execution Time: 0.030110597610473633s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1]. Execution Time: 0.03492379188537598s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [3, 3, 3]. Execution Time: 0.030998945236206055s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.051895856857299805s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.052994728088378906s Agents have converged to Goal 0 after 25 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.056090593338012695s Agents have converged to Goal 3 after 19 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05501866340637207s Agents have converged to Goal 3 after 27 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07996869087219238s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.10100126266479492s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11199760437011719s Agents have converged to Goal 3 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 1]. Execution Time: 0.09790658950805664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.007091045379638672s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 26: Agents have selected goals [0, 0]. Execution Time: 0.009996175765991211s Agents have converged to Goal 0 after 26 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [3, 3]. Execution Time: 0.008000612258911133s Agents have converged to Goal 3 after 15 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [0, 0]. Execution Time: 0.007999897003173828s Agents have converged to Goal 0 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000011444091797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000249862670898s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 2, 3]. Execution Time: 0.013092756271362305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 4]. Execution Time: 0.01399993896484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.024001359939575195s Agents have converged to Goal 0 after 24 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2]. Execution Time: 0.022001028060913086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3]. Execution Time: 0.019999980926513672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 3, 3]. Execution Time: 0.020015239715576172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 0]. Execution Time: 0.02498459815979004s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.028974294662475586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.03099370002746582s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 4]. Execution Time: 0.028020381927490234s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  42.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 9: Agents have selected goals [1, 1]. Execution Time: 0.0009126663208007812s Agents have converged to Goal 1 after 9 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0020012855529785156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 2]. Execution Time: 0.0019991397857666016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 1, 2]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 2, 1]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 2]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 1, 2, 1]. Execution Time: 0.00500035285949707s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 2, 1, 0]. Execution Time: 0.004101753234863281s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.013998746871948242s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.015001773834228516s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [3, 3]. Execution Time: 0.014963388442993164s Agents have converged to Goal 3 after 15 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [3, 3]. Execution Time: 0.01601243019104004s Agents have converged to Goal 3 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.030000925064086914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [0, 0, 0]. Execution Time: 0.031999826431274414s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [3, 3, 3]. Execution Time: 0.03190922737121582s Agents have converged to Goal 3 after 22 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [2, 2, 2]. Execution Time: 0.031999826431274414s Agents have converged to Goal 2 after 44 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.051999807357788086s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05101323127746582s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 2]. Execution Time: 0.060899972915649414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2]. Execution Time: 0.05501532554626465s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 39: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07709360122680664s Agents have converged to Goal 0 after 39 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 2]. Execution Time: 0.0800933837890625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 84: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11600041389465332s Agents have converged to Goal 3 after 84 iterations. Use EP: True\n",
      "Iteration 50: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09599995613098145s Agents have converged to Goal 0 after 50 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.0070154666900634766s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [1, 1]. Execution Time: 0.006999969482421875s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [3, 3]. Execution Time: 0.010001420974731445s Agents have converged to Goal 3 after 15 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [3, 3]. Execution Time: 0.010002613067626953s Agents have converged to Goal 3 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013906717300415039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [0, 0, 0]. Execution Time: 0.013997316360473633s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [3, 3, 3]. Execution Time: 0.014022588729858398s Agents have converged to Goal 3 after 20 iterations. Use EP: False\n",
      "Iteration 88: Agents have selected goals [2, 2, 2]. Execution Time: 0.012881994247436523s Agents have converged to Goal 2 after 88 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.01797175407409668s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 58: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01900172233581543s Agents have converged to Goal 0 after 58 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01900768280029297s Agents have converged to Goal 0 after 40 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 3, 3, 3]. Execution Time: 0.019980669021606445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 0]. Execution Time: 0.024999380111694336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.025870800018310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.03210091590881348s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.029957294464111328s Agents have converged to Goal 3 after 100 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  44.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009834766387939453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009813308715820312s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0009822845458984375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0020008087158203125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2]. Execution Time: 0.0010013580322265625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0]. Execution Time: 0.0010094642639160156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.0020160675048828125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.0019989013671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 1]. Execution Time: 0.001997709274291992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1, 0]. Execution Time: 0.003995180130004883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 0, 1]. Execution Time: 0.004037380218505859s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 1, 3]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [0, 0]. Execution Time: 0.015000581741333008s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1]. Execution Time: 0.015106916427612305s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.04896068572998047s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4]. Execution Time: 0.016089916229248047s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.029000043869018555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [2, 2, 2]. Execution Time: 0.02999138832092285s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.033997297286987305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0]. Execution Time: 0.032022953033447266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04996776580810547s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 98: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04997444152832031s Agents have converged to Goal 1 after 98 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05500173568725586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 88: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05812430381774902s Agents have converged to Goal 0 after 88 iterations. Use EP: True\n",
      "Iteration 60: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0791025161743164s Agents have converged to Goal 1 after 60 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0, 0]. Execution Time: 0.08404803276062012s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 1, 1]. Execution Time: 0.12299990653991699s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1, 3]. Execution Time: 0.10001754760742188s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 56: Agents have selected goals [0, 0]. Execution Time: 0.007987260818481445s Agents have converged to Goal 0 after 56 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.008095026016235352s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [2, 2]. Execution Time: 0.00899958610534668s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [4, 4]. Execution Time: 0.007999658584594727s Agents have converged to Goal 4 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.013001441955566406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 46: Agents have selected goals [2, 2, 2]. Execution Time: 0.014000654220581055s Agents have converged to Goal 2 after 46 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.01299428939819336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.015913009643554688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01988959312438965s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 0]. Execution Time: 0.01898336410522461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 0]. Execution Time: 0.03600120544433594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 3]. Execution Time: 0.018998384475708008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.03600168228149414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0, 2]. Execution Time: 0.02600407600402832s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 1, 1, 2]. Execution Time: 0.03410220146179199s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 4, 4]. Execution Time: 0.0299832820892334s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  46.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0010075569152832031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.0s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0019903182983398438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2]. Execution Time: 0.002023458480834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 0, 4]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.001909494400024414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 0]. Execution Time: 0.002007722854614258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 1]. Execution Time: 0.004001140594482422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 0, 4, 0]. Execution Time: 0.0019960403442382812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 0]. Execution Time: 0.003025054931640625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 0, 1]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 1, 0]. Execution Time: 0.003998279571533203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 0, 4, 0, 2]. Execution Time: 0.003999233245849609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1]. Execution Time: 0.0159146785736084s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [1, 1]. Execution Time: 0.016089677810668945s Agents have converged to Goal 1 after 49 iterations. Use EP: True\n",
      "Iteration 58: Agents have selected goals [0, 0]. Execution Time: 0.019013404846191406s Agents have converged to Goal 0 after 58 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.01891613006591797s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 45: Agents have selected goals [1, 1, 1]. Execution Time: 0.02809309959411621s Agents have converged to Goal 1 after 45 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [2, 2, 2]. Execution Time: 0.0429987907409668s Agents have converged to Goal 2 after 49 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2]. Execution Time: 0.028993606567382812s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 1, 1]. Execution Time: 0.03499889373779297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.06502175331115723s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05399727821350098s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 78: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05489826202392578s Agents have converged to Goal 2 after 78 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05800271034240723s Agents have converged to Goal 0 after 40 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07608628273010254s Agents have converged to Goal 0 after 44 iterations. Use EP: True\n",
      "Iteration 72: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08498454093933105s Agents have converged to Goal 2 after 72 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11400222778320312s Agents have converged to Goal 2 after 34 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.09502315521240234s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.00790858268737793s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [1, 1]. Execution Time: 0.00701141357421875s Agents have converged to Goal 1 after 45 iterations. Use EP: False\n",
      "Iteration 76: Agents have selected goals [3, 3]. Execution Time: 0.00798177719116211s Agents have converged to Goal 3 after 76 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.006999969482421875s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01299428939819336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.012964010238647461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [2, 2, 2]. Execution Time: 0.012996196746826172s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.014975786209106445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.01900768280029297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01900005340576172s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3]. Execution Time: 0.0189208984375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 1]. Execution Time: 0.024998903274536133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.02499866485595703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 1]. Execution Time: 0.026012182235717773s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 73: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.03299903869628906s Agents have converged to Goal 3 after 73 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 4]. Execution Time: 0.03099989891052246s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  48.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0008943080902099609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0010006427764892578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2]. Execution Time: 0.0010056495666503906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3]. Execution Time: 0.0019986629486083984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 1]. Execution Time: 0.002000570297241211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 0]. Execution Time: 0.001998424530029297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 1]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 1, 4]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 0]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 0, 1]. Execution Time: 0.0039768218994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 1, 3]. Execution Time: 0.004022121429443359s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 1, 4, 4]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.013987302780151367s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 61: Agents have selected goals [0, 0]. Execution Time: 0.014998197555541992s Agents have converged to Goal 0 after 61 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [2, 2]. Execution Time: 0.019002437591552734s Agents have converged to Goal 2 after 11 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.0160062313079834s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 54: Agents have selected goals [1, 1, 1]. Execution Time: 0.029000043869018555s Agents have converged to Goal 1 after 54 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2, 2]. Execution Time: 0.04399871826171875s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1]. Execution Time: 0.03798246383666992s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.03299999237060547s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.048093557357788086s Agents have converged to Goal 0 after 39 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05690360069274902s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05400371551513672s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.058002471923828125s Agents have converged to Goal 4 after 24 iterations. Use EP: True\n",
      "Iteration 89: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09299969673156738s Agents have converged to Goal 1 after 89 iterations. Use EP: True\n",
      "Iteration 62: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.0860128402709961s Agents have converged to Goal 2 after 62 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.12999558448791504s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 51: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.09800267219543457s Agents have converged to Goal 4 after 51 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [1, 1]. Execution Time: 0.008089780807495117s Agents have converged to Goal 1 after 23 iterations. Use EP: False\n",
      "Iteration 59: Agents have selected goals [2, 2]. Execution Time: 0.008012533187866211s Agents have converged to Goal 2 after 59 iterations. Use EP: False\n",
      "Iteration 12: Agents have selected goals [2, 2]. Execution Time: 0.007996082305908203s Agents have converged to Goal 2 after 12 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.00899958610534668s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.013905525207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 76: Agents have selected goals [2, 2, 2]. Execution Time: 0.013089179992675781s Agents have converged to Goal 2 after 76 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [3, 3, 3]. Execution Time: 0.013090133666992188s Agents have converged to Goal 3 after 17 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [4, 4, 4]. Execution Time: 0.014000654220581055s Agents have converged to Goal 4 after 40 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018997907638549805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2]. Execution Time: 0.017986059188842773s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01990675926208496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.019913911819458008s Agents have converged to Goal 4 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 0]. Execution Time: 0.024988651275634766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 2, 1]. Execution Time: 0.025000572204589844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.03399944305419922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.032113075256347656s Agents have converged to Goal 4 after 23 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  50.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0010073184967041016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0010006427764892578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0]. Execution Time: 0.0019867420196533203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0]. Execution Time: 0.0019876956939697266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 0, 3]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3, 1]. Execution Time: 0.0029985904693603516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 0]. Execution Time: 0.002985239028930664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 0, 0]. Execution Time: 0.003000974655151367s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 0, 3, 1]. Execution Time: 0.0040051937103271484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 3, 1, 0]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.017117977142333984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.014999866485595703s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.01599574089050293s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 66: Agents have selected goals [1, 1]. Execution Time: 0.016115188598632812s Agents have converged to Goal 1 after 66 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0]. Execution Time: 0.031119823455810547s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [0, 0, 0]. Execution Time: 0.030001163482666016s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.032000064849853516s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0, 0]. Execution Time: 0.03209424018859863s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.050096988677978516s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05091142654418945s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 61: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05209064483642578s Agents have converged to Goal 0 after 61 iterations. Use EP: True\n",
      "Iteration 54: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.058098793029785156s Agents have converged to Goal 3 after 54 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07699942588806152s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08009600639343262s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11201620101928711s Agents have converged to Goal 3 after 64 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09591794013977051s Agents have converged to Goal 0 after 42 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.008002281188964844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.00800013542175293s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.009013891220092773s Agents have converged to Goal 3 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.007999897003173828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01399993896484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 87: Agents have selected goals [0, 0, 0]. Execution Time: 0.015010356903076172s Agents have converged to Goal 0 after 87 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000011444091797s Agents have converged to Goal 0 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.012918710708618164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01798844337463379s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.019001483917236328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019000768661499023s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 49: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.02000117301940918s Agents have converged to Goal 3 after 49 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.025015830993652344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2, 0]. Execution Time: 0.02599787712097168s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 59: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.0320737361907959s Agents have converged to Goal 3 after 59 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.028000831604003906s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  52.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [1, 1]. Execution Time: 0.0010023117065429688s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 8: Agents have selected goals [1, 1]. Execution Time: 0.0010061264038085938s Agents have converged to Goal 1 after 8 iterations. Use EP: True\n",
      "Iteration 8: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 8 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [1, 1, 1]. Execution Time: 0.0018994808197021484s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 8: Agents have selected goals [1, 1, 1]. Execution Time: 0.0019996166229248047s Agents have converged to Goal 1 after 8 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0020003318786621094s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.003018617630004883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.0019991397857666016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.003979921340942383s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0, 0]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 46: Agents have selected goals [0, 0]. Execution Time: 0.015110015869140625s Agents have converged to Goal 0 after 46 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.01399993896484375s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [1, 1]. Execution Time: 0.01509547233581543s Agents have converged to Goal 1 after 12 iterations. Use EP: True\n",
      "Iteration 9: Agents have selected goals [1, 1]. Execution Time: 0.016093730926513672s Agents have converged to Goal 1 after 9 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1]. Execution Time: 0.028897523880004883s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.030980825424194336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 9: Agents have selected goals [1, 1, 1]. Execution Time: 0.03100109100341797s Agents have converged to Goal 1 after 9 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1]. Execution Time: 0.03211212158203125s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04899311065673828s Agents have converged to Goal 0 after 64 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.056000709533691406s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05300021171569824s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.057000160217285156s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0969996452331543s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 50: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08012270927429199s Agents have converged to Goal 1 after 50 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1450808048248291s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09599733352661133s Agents have converged to Goal 0 after 29 iterations. Use EP: True\n",
      "Iteration 46: Agents have selected goals [0, 0]. Execution Time: 0.009999752044677734s Agents have converged to Goal 0 after 46 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.007999181747436523s Agents have converged to Goal 1 after 31 iterations. Use EP: False\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.007997751235961914s Agents have converged to Goal 1 after 10 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.007999420166015625s Agents have converged to Goal 1 after 11 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.014000415802001953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000011444091797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.012999773025512695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.014101028442382812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.017998218536376953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.01999831199645996s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.020999908447265625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.020084857940673828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 49: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.02591419219970703s Agents have converged to Goal 1 after 49 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 1]. Execution Time: 0.026005983352661133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.03299832344055176s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.037000417709350586s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  54.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009961128234863281s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0009870529174804688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3]. Execution Time: 0.001009225845336914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.0010879039764404297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.001997232437133789s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1]. Execution Time: 0.002003192901611328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 4]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.0009989738464355469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1, 0]. Execution Time: 0.0029706954956054688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 4, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 1]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 0]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1, 0, 1]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 4, 1, 1]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [0, 0]. Execution Time: 0.01909017562866211s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [0, 0]. Execution Time: 0.015000104904174805s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [3, 3]. Execution Time: 0.020013093948364258s Agents have converged to Goal 3 after 39 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.018004417419433594s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0, 0]. Execution Time: 0.027988672256469727s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.059911251068115234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 51: Agents have selected goals [3, 3, 3]. Execution Time: 0.030092954635620117s Agents have converged to Goal 3 after 51 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [3, 3, 3]. Execution Time: 0.03290820121765137s Agents have converged to Goal 3 after 35 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04900336265563965s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 74: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.051000118255615234s Agents have converged to Goal 1 after 74 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05306744575500488s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05488848686218262s Agents have converged to Goal 1 after 44 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07809162139892578s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08006715774536133s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11600303649902344s Agents have converged to Goal 2 after 42 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0970005989074707s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0]. Execution Time: 0.00798797607421875s Agents have converged to Goal 0 after 30 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [0, 0]. Execution Time: 0.00899815559387207s Agents have converged to Goal 0 after 27 iterations. Use EP: False\n",
      "Iteration 39: Agents have selected goals [3, 3]. Execution Time: 0.0089111328125s Agents have converged to Goal 3 after 39 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [1, 1]. Execution Time: 0.009000062942504883s Agents have converged to Goal 1 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.014000415802001953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [0, 0, 0]. Execution Time: 0.01290750503540039s Agents have converged to Goal 0 after 30 iterations. Use EP: False\n",
      "Iteration 66: Agents have selected goals [3, 3, 3]. Execution Time: 0.011999845504760742s Agents have converged to Goal 3 after 66 iterations. Use EP: False\n",
      "Iteration 52: Agents have selected goals [3, 3, 3]. Execution Time: 0.013000965118408203s Agents have converged to Goal 3 after 52 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.017999649047851562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.018985509872436523s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 91: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01999521255493164s Agents have converged to Goal 2 after 91 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.021000385284423828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.025983810424804688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.027004003524780273s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 59: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.039055824279785156s Agents have converged to Goal 0 after 59 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.028896570205688477s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  56.00000000000001 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.0s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 13: Agents have selected goals [1, 1]. Execution Time: 0.0009996891021728516s Agents have converged to Goal 1 after 13 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.0029799938201904297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 0]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.0019905567169189453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1, 0]. Execution Time: 0.0029990673065185547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 0, 1]. Execution Time: 0.0030028820037841797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 4]. Execution Time: 0.004000425338745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.014089345932006836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.016000032424926758s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3]. Execution Time: 0.01587820053100586s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [2, 2]. Execution Time: 0.021999359130859375s Agents have converged to Goal 2 after 36 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [0, 0, 0]. Execution Time: 0.0279998779296875s Agents have converged to Goal 0 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.029908180236816406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [2, 2, 2]. Execution Time: 0.031000375747680664s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.033910512924194336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05299973487854004s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08801889419555664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05890059471130371s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.059017181396484375s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0740208625793457s Agents have converged to Goal 1 after 35 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 0]. Execution Time: 0.08312273025512695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14299893379211426s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 3]. Execution Time: 0.09608268737792969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.007993936538696289s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.008000373840332031s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [3, 3]. Execution Time: 0.008999109268188477s Agents have converged to Goal 3 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4]. Execution Time: 0.007999897003173828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01299905776977539s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [2, 2, 2]. Execution Time: 0.013000011444091797s Agents have converged to Goal 2 after 26 iterations. Use EP: False\n",
      "Iteration 95: Agents have selected goals [2, 2, 2]. Execution Time: 0.014887571334838867s Agents have converged to Goal 2 after 95 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.015103578567504883s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.020094871520996094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.021003246307373047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.022992610931396484s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2]. Execution Time: 0.01999974250793457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 1]. Execution Time: 0.032001495361328125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 64: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.02799820899963379s Agents have converged to Goal 2 after 64 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.03108978271484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 2, 3]. Execution Time: 0.03100132942199707s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  57.99999999999999 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009937286376953125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.0010066032409667969s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [4, 4]. Execution Time: 0.0s Agents have converged to Goal 4 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [0, 0, 0]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 3]. Execution Time: 0.0010592937469482422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0]. Execution Time: 0.0029942989349365234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 0]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 3]. Execution Time: 0.0030019283294677734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 3, 4]. Execution Time: 0.0020732879638671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 0]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 0, 2]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 3, 0]. Execution Time: 0.004006147384643555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 3, 4, 4]. Execution Time: 0.003988504409790039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 46: Agents have selected goals [1, 1]. Execution Time: 0.014909744262695312s Agents have converged to Goal 1 after 46 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.014999866485595703s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.015997648239135742s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [4, 4]. Execution Time: 0.016988515853881836s Agents have converged to Goal 4 after 18 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0]. Execution Time: 0.028012990951538086s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0, 0]. Execution Time: 0.0348968505859375s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.032000064849853516s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [0, 0, 0]. Execution Time: 0.03201007843017578s Agents have converged to Goal 0 after 49 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.049010515213012695s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05109000205993652s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 56: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05192995071411133s Agents have converged to Goal 0 after 56 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 4, 4]. Execution Time: 0.055998802185058594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07699966430664062s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08090496063232422s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 61: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11200261116027832s Agents have converged to Goal 0 after 61 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.09709024429321289s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.009999990463256836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.007999658584594727s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.007016420364379883s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [4, 4]. Execution Time: 0.009999990463256836s Agents have converged to Goal 4 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01308584213256836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0, 0]. Execution Time: 0.012990474700927734s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000249862670898s Agents have converged to Goal 0 after 30 iterations. Use EP: False\n",
      "Iteration 85: Agents have selected goals [4, 4, 4]. Execution Time: 0.013901233673095703s Agents have converged to Goal 4 after 85 iterations. Use EP: False\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018999814987182617s Agents have converged to Goal 0 after 26 iterations. Use EP: False\n",
      "Iteration 42: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.02091050148010254s Agents have converged to Goal 0 after 42 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01801300048828125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019000530242919922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0, 1]. Execution Time: 0.02502298355102539s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2, 2]. Execution Time: 0.027109146118164062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 2, 3]. Execution Time: 0.03408312797546387s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 1, 2]. Execution Time: 0.03199410438537598s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  60.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.0010025501251220703s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.0009996891021728516s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 3]. Execution Time: 0.0010211467742919922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.0010135173797607422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.002000093460083008s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 2]. Execution Time: 0.0009989738464355469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.002000093460083008s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 2]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 2, 2]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 1]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.004946470260620117s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 2, 2]. Execution Time: 0.00499272346496582s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 2, 2, 0]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 64: Agents have selected goals [0, 0]. Execution Time: 0.014998912811279297s Agents have converged to Goal 0 after 64 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [2, 2]. Execution Time: 0.014999866485595703s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2]. Execution Time: 0.017901897430419922s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [4, 4]. Execution Time: 0.017001628875732422s Agents have converged to Goal 4 after 21 iterations. Use EP: True\n",
      "Iteration 62: Agents have selected goals [0, 0, 0]. Execution Time: 0.02900075912475586s Agents have converged to Goal 0 after 62 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.030009746551513672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.03200054168701172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [2, 2, 2]. Execution Time: 0.03800320625305176s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04906511306762695s Agents have converged to Goal 0 after 64 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.050106048583984375s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0540003776550293s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0639641284942627s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.0930933952331543s Agents have converged to Goal 0 after 64 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.0840003490447998s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11408662796020508s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 60: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.0959007740020752s Agents have converged to Goal 2 after 60 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [0, 0]. Execution Time: 0.008999824523925781s Agents have converged to Goal 0 after 64 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [2, 2]. Execution Time: 0.008911848068237305s Agents have converged to Goal 2 after 32 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [2, 2]. Execution Time: 0.007999897003173828s Agents have converged to Goal 2 after 25 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [4, 4]. Execution Time: 0.009904623031616211s Agents have converged to Goal 4 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.015980243682861328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.01409149169921875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [2, 2, 2]. Execution Time: 0.013019084930419922s Agents have converged to Goal 2 after 34 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 3, 3]. Execution Time: 0.030083417892456055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.017999649047851562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.019002199172973633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.020012617111206055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2]. Execution Time: 0.02090597152709961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.027000904083251953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2, 2]. Execution Time: 0.024909019470214844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 2, 3]. Execution Time: 0.0360107421875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 1]. Execution Time: 0.03189873695373535s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  62.0 %-------------------\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 0]. Execution Time: 0.001001119613647461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 4]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 0, 2]. Execution Time: 0.00400090217590332s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 0]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 0]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 0, 2]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 0, 2, 0]. Execution Time: 0.005088090896606445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 0, 1]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.018018245697021484s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [1, 1]. Execution Time: 0.016083955764770508s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.016000747680664062s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [4, 4]. Execution Time: 0.017000198364257812s Agents have converged to Goal 4 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.02991461753845215s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [1, 1, 1]. Execution Time: 0.03000020980834961s Agents have converged to Goal 1 after 38 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.03200197219848633s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [4, 4, 4]. Execution Time: 0.035996437072753906s Agents have converged to Goal 4 after 32 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05099964141845703s Agents have converged to Goal 1 after 36 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.05400276184082031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.05199146270751953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.0559229850769043s Agents have converged to Goal 4 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.07809066772460938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 56: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08298850059509277s Agents have converged to Goal 1 after 56 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11700010299682617s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.0969996452331543s Agents have converged to Goal 4 after 21 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [1, 1]. Execution Time: 0.00999760627746582s Agents have converged to Goal 1 after 43 iterations. Use EP: False\n",
      "Iteration 34: Agents have selected goals [1, 1]. Execution Time: 0.009000539779663086s Agents have converged to Goal 1 after 34 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.007999897003173828s Agents have converged to Goal 2 after 30 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [4, 4]. Execution Time: 0.007998228073120117s Agents have converged to Goal 4 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.013917684555053711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [1, 1, 1]. Execution Time: 0.01309347152709961s Agents have converged to Goal 1 after 38 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.013907909393310547s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.012999534606933594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.018889904022216797s Agents have converged to Goal 1 after 36 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.018009424209594727s Agents have converged to Goal 2 after 33 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 2]. Execution Time: 0.020000219345092773s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.02009129524230957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.025002241134643555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.025109529495239258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0, 0]. Execution Time: 0.03800249099731445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.029000043869018555s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  64.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 13: Agents have selected goals [2, 2]. Execution Time: 0.0s Agents have converged to Goal 2 after 13 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2]. Execution Time: 0.0010006427764892578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 3]. Execution Time: 0.0020225048065185547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.0020058155059814453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 0]. Execution Time: 0.0020008087158203125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 3]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 3, 4]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 0]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 0, 0]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 3, 2]. Execution Time: 0.00400233268737793s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 3, 4, 0]. Execution Time: 0.003999233245849609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.014894247055053711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 96: Agents have selected goals [2, 2]. Execution Time: 0.014988183975219727s Agents have converged to Goal 2 after 96 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.015996694564819336s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0]. Execution Time: 0.017999887466430664s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 82: Agents have selected goals [1, 1, 1]. Execution Time: 0.03199648857116699s Agents have converged to Goal 1 after 82 iterations. Use EP: True\n",
      "Iteration 94: Agents have selected goals [2, 2, 2]. Execution Time: 0.031000852584838867s Agents have converged to Goal 2 after 94 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.03199958801269531s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 3]. Execution Time: 0.04300117492675781s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.050029754638671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05102276802062988s Agents have converged to Goal 0 after 43 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 3]. Execution Time: 0.05300164222717285s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 4, 4]. Execution Time: 0.05891776084899902s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09601449966430664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08091449737548828s Agents have converged to Goal 0 after 44 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11299967765808105s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.0970003604888916s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.007903575897216797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.008000612258911133s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.008987903594970703s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 34: Agents have selected goals [0, 0]. Execution Time: 0.009000062942504883s Agents have converged to Goal 0 after 34 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.01302337646484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 94: Agents have selected goals [2, 2, 2]. Execution Time: 0.012982606887817383s Agents have converged to Goal 2 after 94 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.01609325408935547s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 38: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000965118408203s Agents have converged to Goal 0 after 38 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.019002914428710938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019887208938598633s Agents have converged to Goal 0 after 40 iterations. Use EP: False\n",
      "Iteration 56: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019088268280029297s Agents have converged to Goal 0 after 56 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 4, 4]. Execution Time: 0.01992321014404297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.024005651473999023s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.026000261306762695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0, 1]. Execution Time: 0.03299736976623535s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.04200148582458496s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  66.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 9: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 9 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.0010514259338378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.0030014514923095703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0020012855529785156s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 3]. Execution Time: 0.002001523971557617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 0]. Execution Time: 0.004001617431640625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.003008604049682617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.003000020980834961s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 3, 0]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 0, 3]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.021999597549438477s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.015015602111816406s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.01809382438659668s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3]. Execution Time: 0.020000696182250977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 39: Agents have selected goals [1, 1, 1]. Execution Time: 0.028002023696899414s Agents have converged to Goal 1 after 39 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.031000137329101562s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 3]. Execution Time: 0.03698468208312988s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.03400063514709473s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 39: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04999732971191406s Agents have converged to Goal 1 after 39 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.051001787185668945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05399799346923828s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05800223350524902s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07700109481811523s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0830082893371582s Agents have converged to Goal 1 after 38 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.11300182342529297s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 3]. Execution Time: 0.11401033401489258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.009995698928833008s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.008049964904785156s Agents have converged to Goal 1 after 19 iterations. Use EP: False\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.006997823715209961s Agents have converged to Goal 1 after 10 iterations. Use EP: False\n",
      "Iteration 42: Agents have selected goals [1, 1]. Execution Time: 0.010924816131591797s Agents have converged to Goal 1 after 42 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.013986587524414062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.013999700546264648s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.01399087905883789s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [1, 1, 1]. Execution Time: 0.016004323959350586s Agents have converged to Goal 1 after 33 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.019010305404663086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 55: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018977880477905273s Agents have converged to Goal 0 after 55 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01999831199645996s Agents have converged to Goal 1 after 32 iterations. Use EP: False\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.020083904266357422s Agents have converged to Goal 1 after 34 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 0]. Execution Time: 0.024990081787109375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 0]. Execution Time: 0.0260007381439209s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.03590750694274902s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 49: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.028094768524169922s Agents have converged to Goal 1 after 49 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  68.0 %-------------------\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.0009741783142089844s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.001012563705444336s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 2]. Execution Time: 0.0009849071502685547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 7: Agents have selected goals [2, 2]. Execution Time: 0.0010037422180175781s Agents have converged to Goal 2 after 7 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0, 0]. Execution Time: 0.0010051727294921875s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.0010044574737548828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2]. Execution Time: 0.001024007797241211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 4]. Execution Time: 0.0009980201721191406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0019996166229248047s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 0]. Execution Time: 0.0040836334228515625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.003000020980834961s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2, 0]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 0, 1]. Execution Time: 0.005003929138183594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4, 2]. Execution Time: 0.003966331481933594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.014999628067016602s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.016089200973510742s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [2, 2]. Execution Time: 0.01810455322265625s Agents have converged to Goal 2 after 32 iterations. Use EP: True\n",
      "Iteration 7: Agents have selected goals [2, 2]. Execution Time: 0.016000032424926758s Agents have converged to Goal 2 after 7 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0, 0]. Execution Time: 0.02899789810180664s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [2, 2, 2]. Execution Time: 0.031968116760253906s Agents have converged to Goal 2 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.030952930450439453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2]. Execution Time: 0.03195691108703613s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.049016475677490234s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2]. Execution Time: 0.05100655555725098s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2]. Execution Time: 0.053002357482910156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 4, 4]. Execution Time: 0.06408429145812988s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.07899117469787598s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2, 2]. Execution Time: 0.08600091934204102s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11310720443725586s Agents have converged to Goal 3 after 42 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 4, 2]. Execution Time: 0.09798693656921387s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.007992982864379883s Agents have converged to Goal 0 after 18 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.007998943328857422s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [2, 2]. Execution Time: 0.008013248443603516s Agents have converged to Goal 2 after 33 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [3, 3]. Execution Time: 0.007898569107055664s Agents have converged to Goal 3 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.012012720108032227s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013907194137573242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013999700546264648s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 60: Agents have selected goals [0, 0, 0]. Execution Time: 0.014000654220581055s Agents have converged to Goal 0 after 60 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.023000478744506836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018901586532592773s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01900029182434082s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 3, 4]. Execution Time: 0.0390012264251709s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 0]. Execution Time: 0.024958372116088867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.028998136520385742s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.03200483322143555s Agents have converged to Goal 3 after 43 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 4, 2]. Execution Time: 0.02899956703186035s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  70.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4]. Execution Time: 0.0009992122650146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0]. Execution Time: 0.000997781753540039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 2]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 3]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 2, 3]. Execution Time: 0.002000570297241211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 3, 3]. Execution Time: 0.0020008087158203125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 1]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 2, 2]. Execution Time: 0.002999544143676758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 2, 3, 3]. Execution Time: 0.00600123405456543s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 3, 3, 3]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [0, 0]. Execution Time: 0.01808452606201172s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.019997358322143555s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.016022205352783203s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.017101049423217773s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 96: Agents have selected goals [0, 0, 0]. Execution Time: 0.03199362754821777s Agents have converged to Goal 0 after 96 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2, 2]. Execution Time: 0.036997318267822266s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [2, 2, 2]. Execution Time: 0.03200697898864746s Agents have converged to Goal 2 after 36 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.031995296478271484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05108380317687988s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05299997329711914s Agents have converged to Goal 2 after 29 iterations. Use EP: True\n",
      "Iteration 56: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.053018808364868164s Agents have converged to Goal 2 after 56 iterations. Use EP: True\n",
      "Iteration 60: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.055997371673583984s Agents have converged to Goal 3 after 60 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07901334762573242s Agents have converged to Goal 0 after 55 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08091211318969727s Agents have converged to Goal 2 after 53 iterations. Use EP: True\n",
      "Iteration 65: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.1130058765411377s Agents have converged to Goal 3 after 65 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.1009073257446289s Agents have converged to Goal 3 after 44 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0]. Execution Time: 0.009000062942504883s Agents have converged to Goal 0 after 30 iterations. Use EP: False\n",
      "Iteration 60: Agents have selected goals [2, 2]. Execution Time: 0.007915258407592773s Agents have converged to Goal 2 after 60 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.007999658584594727s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.007903575897216797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.011962652206420898s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.012091398239135742s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 99: Agents have selected goals [2, 2, 2]. Execution Time: 0.015002727508544922s Agents have converged to Goal 2 after 99 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013999223709106445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01906752586364746s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.019001483917236328s Agents have converged to Goal 2 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 3]. Execution Time: 0.01900005340576172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.01999974250793457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.029906034469604492s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.028004169464111328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 2, 2]. Execution Time: 0.032016754150390625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 2, 2]. Execution Time: 0.028101205825805664s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  72.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 9: Agents have selected goals [1, 1]. Execution Time: 0.001001119613647461s Agents have converged to Goal 1 after 9 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 2]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4]. Execution Time: 0.0010018348693847656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0009992122650146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 2]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2]. Execution Time: 0.0010030269622802734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 0]. Execution Time: 0.0020112991333007812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 2, 2]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 0]. Execution Time: 0.0030012130737304688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 0, 2]. Execution Time: 0.0020873546600341797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 2, 2, 0]. Execution Time: 0.0029990673065185547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 0, 2]. Execution Time: 0.00398564338684082s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 0, 2, 2]. Execution Time: 0.0030007362365722656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1]. Execution Time: 0.01999950408935547s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [1, 1]. Execution Time: 0.02500009536743164s Agents have converged to Goal 1 after 15 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.016000032424926758s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.019999265670776367s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.028998374938964844s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.03000020980834961s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2, 2]. Execution Time: 0.03100109100341797s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [2, 2, 2]. Execution Time: 0.031002044677734375s Agents have converged to Goal 2 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.05589771270751953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.07199788093566895s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.053002357482910156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05601310729980469s Agents have converged to Goal 2 after 21 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08101344108581543s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08099937438964844s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11400461196899414s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11292099952697754s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [1, 1]. Execution Time: 0.008086681365966797s Agents have converged to Goal 1 after 49 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.00799870491027832s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.010999917984008789s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.00799417495727539s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.011998414993286133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [1, 1, 1]. Execution Time: 0.013000249862670898s Agents have converged to Goal 1 after 24 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [2, 2, 2]. Execution Time: 0.013000011444091797s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [2, 2, 2]. Execution Time: 0.012018680572509766s Agents have converged to Goal 2 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01900005340576172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01800370216369629s Agents have converged to Goal 2 after 44 iterations. Use EP: False\n",
      "Iteration 89: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.02299976348876953s Agents have converged to Goal 2 after 89 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.019979238510131836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.024922609329223633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.02590155601501465s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.04599905014038086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.029102563858032227s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  74.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [2, 2]. Execution Time: 0.0010824203491210938s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [3, 3]. Execution Time: 0.0010046958923339844s Agents have converged to Goal 3 after 13 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [2, 2, 2]. Execution Time: 0.002000093460083008s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 2]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0]. Execution Time: 0.003002166748046875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 2]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 2, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 0]. Execution Time: 0.0029799938201904297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0, 2]. Execution Time: 0.003907442092895508s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 2, 0]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 2, 0, 0]. Execution Time: 0.004000425338745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.016007423400878906s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [2, 2]. Execution Time: 0.014999866485595703s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.01489877700805664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.015093088150024414s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [0, 0, 0]. Execution Time: 0.029999494552612305s Agents have converged to Goal 0 after 64 iterations. Use EP: True\n",
      "Iteration 69: Agents have selected goals [0, 0, 0]. Execution Time: 0.030007600784301758s Agents have converged to Goal 0 after 69 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.030086040496826172s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [2, 2, 2]. Execution Time: 0.03300309181213379s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.049997568130493164s Agents have converged to Goal 0 after 42 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0520014762878418s Agents have converged to Goal 0 after 44 iterations. Use EP: True\n",
      "Iteration 94: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0540003776550293s Agents have converged to Goal 3 after 94 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05608415603637695s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07690787315368652s Agents have converged to Goal 0 after 36 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08008718490600586s Agents have converged to Goal 2 after 37 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11499929428100586s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.09790349006652832s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [0, 0]. Execution Time: 0.007905244827270508s Agents have converged to Goal 0 after 44 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [2, 2]. Execution Time: 0.007999897003173828s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 75: Agents have selected goals [2, 2]. Execution Time: 0.008000373840332031s Agents have converged to Goal 2 after 75 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.007999897003173828s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.013000726699829102s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013997793197631836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013009786605834961s Agents have converged to Goal 2 after 100 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 2, 2]. Execution Time: 0.013123035430908203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0]. Execution Time: 0.02000284194946289s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 0]. Execution Time: 0.01899862289428711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.019000768661499023s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.020995378494262695s Agents have converged to Goal 2 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.024998903274536133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.025087356567382812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.03198814392089844s Agents have converged to Goal 2 after 36 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 3, 4, 0, 3]. Execution Time: 0.028086423873901367s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  76.0 %-------------------\n",
      "Iteration 12: Agents have selected goals [0, 0]. Execution Time: 0.0s Agents have converged to Goal 0 after 12 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0010333061218261719s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 12: Agents have selected goals [0, 0]. Execution Time: 0.0s Agents have converged to Goal 0 after 12 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 12: Agents have selected goals [0, 0, 0]. Execution Time: 0.0009992122650146484s Agents have converged to Goal 0 after 12 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0, 0]. Execution Time: 0.0010013580322265625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4]. Execution Time: 0.002001047134399414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 12: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0019991397857666016s Agents have converged to Goal 0 after 12 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 1]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.003000974655151367s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 1, 0]. Execution Time: 0.003999233245849609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0, 1]. Execution Time: 0.003998756408691406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 1, 4]. Execution Time: 0.0029976367950439453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 13: Agents have selected goals [0, 0]. Execution Time: 0.015017032623291016s Agents have converged to Goal 0 after 13 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.018972158432006836s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.018002748489379883s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 58: Agents have selected goals [1, 1]. Execution Time: 0.019999980926513672s Agents have converged to Goal 1 after 58 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.033087968826293945s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0, 0]. Execution Time: 0.03099679946899414s  Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.029878854751586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 61: Agents have selected goals [4, 4, 4]. Execution Time: 0.0320127010345459s Agents have converged to Goal 4 after 61 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05699491500854492s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.04999995231628418s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 56: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0769968032836914s Agents have converged to Goal 0 after 56 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 1]. Execution Time: 0.055001258850097656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.12099957466125488s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07900071144104004s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.11299490928649902s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09598970413208008s Agents have converged to Goal 1 after 42 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [0, 0]. Execution Time: 0.007999897003173828s Agents have converged to Goal 0 after 13 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.007944822311401367s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.009002923965454102s Agents have converged to Goal 0 after 15 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [2, 2]. Execution Time: 0.00799870491027832s Agents have converged to Goal 2 after 37 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.016999244689941406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [0, 0, 0]. Execution Time: 0.012999534606933594s Agents have converged to Goal 0 after 16 iterations. Use EP: False\n",
      "Iteration 56: Agents have selected goals [2, 2, 2]. Execution Time: 0.012999773025512695s Agents have converged to Goal 2 after 56 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 2, 3]. Execution Time: 0.013084650039672852s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018909215927124023s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 88: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.020013093948364258s Agents have converged to Goal 2 after 88 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 0, 3, 0]. Execution Time: 0.019884586334228516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.019884824752807617s Agents have converged to Goal 2 after 42 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 1]. Execution Time: 0.027904748916625977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0, 0]. Execution Time: 0.025896310806274414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.032094717025756836s Agents have converged to Goal 3 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 2, 2]. Execution Time: 0.030886411666870117s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  78.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.001001119613647461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 10: Agents have selected goals [4, 4]. Execution Time: 0.0010256767272949219s Agents have converged to Goal 4 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.0010116100311279297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1]. Execution Time: 0.0009808540344238281s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 3]. Execution Time: 0.0010144710540771484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 3]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 3, 3]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 3, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 1]. Execution Time: 0.0030062198638916016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1, 2]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 3, 3, 0]. Execution Time: 0.004999876022338867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 3, 0, 1]. Execution Time: 0.005000114440917969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 66: Agents have selected goals [1, 1]. Execution Time: 0.0181121826171875s Agents have converged to Goal 1 after 66 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [1, 1]. Execution Time: 0.021004199981689453s Agents have converged to Goal 1 after 40 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.015001773834228516s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [4, 4]. Execution Time: 0.0150909423828125s Agents have converged to Goal 4 after 12 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.03300046920776367s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.029004335403442383s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [3, 3, 3]. Execution Time: 0.03200173377990723s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 3]. Execution Time: 0.033093929290771484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04899907112121582s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05901217460632324s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.05290961265563965s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 3]. Execution Time: 0.05809593200683594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07899928092956543s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 2]. Execution Time: 0.08088874816894531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11399722099304199s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 4, 1, 1]. Execution Time: 0.1010274887084961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.008000612258911133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.007999897003173828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.008094310760498047s Agents have converged to Goal 3 after 23 iterations. Use EP: False\n",
      "Iteration 12: Agents have selected goals [4, 4]. Execution Time: 0.010000467300415039s Agents have converged to Goal 4 after 12 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.017000913619995117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 96: Agents have selected goals [1, 1, 1]. Execution Time: 0.013012170791625977s Agents have converged to Goal 1 after 96 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [3, 3, 3]. Execution Time: 0.01399993896484375s Agents have converged to Goal 3 after 23 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [4, 4, 4]. Execution Time: 0.013000249862670898s Agents have converged to Goal 4 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.017992258071899414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.018999099731445312s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2]. Execution Time: 0.024000167846679688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 2, 2]. Execution Time: 0.020002365112304688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.025002479553222656s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.026999711990356445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.03399944305419922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 3, 2, 1]. Execution Time: 0.029109716415405273s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  80.0 %-------------------\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.0s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 10: Agents have selected goals [0, 0]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 0 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.002001523971557617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 0]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.002981901168823242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 4]. Execution Time: 0.0029973983764648438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0, 0]. Execution Time: 0.0030014514923095703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 0, 1]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.0039975643157958984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 4, 4]. Execution Time: 0.0040018558502197266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.02000117301940918s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [1, 1]. Execution Time: 0.015981435775756836s Agents have converged to Goal 1 after 47 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.015002012252807617s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [0, 0]. Execution Time: 0.018091440200805664s Agents have converged to Goal 0 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.029000043869018555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.030028104782104492s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.03296971321105957s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.03090977668762207s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05100297927856445s Agents have converged to Goal 0 after 55 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.07008957862854004s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05800151824951172s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 4]. Execution Time: 0.05609631538391113s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 52: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.10011434555053711s Agents have converged to Goal 0 after 52 iterations. Use EP: True\n",
      "Iteration 62: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08700037002563477s Agents have converged to Goal 0 after 62 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.11500787734985352s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09608888626098633s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.007999658584594727s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 48: Agents have selected goals [2, 2]. Execution Time: 0.00900125503540039s Agents have converged to Goal 2 after 48 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.008916378021240234s Agents have converged to Goal 1 after 19 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.008997917175292969s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.014087438583374023s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.013035774230957031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 48: Agents have selected goals [0, 0, 0]. Execution Time: 0.01299142837524414s Agents have converged to Goal 0 after 48 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.014082670211791992s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019093990325927734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0]. Execution Time: 0.018084049224853516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.025001049041748047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 3, 0]. Execution Time: 0.020017623901367188s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 0]. Execution Time: 0.026001453399658203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.02409076690673828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 3, 2]. Execution Time: 0.031980276107788086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.028909683227539062s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  82.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0010023117065429688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.0009989738464355469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0010008811950683594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 2]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.0018925666809082031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 2]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 2, 4]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 1]. Execution Time: 0.00500178337097168s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 2]. Execution Time: 0.003998756408691406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 2, 2]. Execution Time: 0.004003763198852539s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 2, 4, 2]. Execution Time: 0.003999471664428711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.015999794006347656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.014999866485595703s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.017000675201416016s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [1, 1]. Execution Time: 0.016000032424926758s Agents have converged to Goal 1 after 53 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.03699779510498047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [0, 0, 0]. Execution Time: 0.030001163482666016s Agents have converged to Goal 0 after 37 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1, 1]. Execution Time: 0.032896995544433594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.031992197036743164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 78: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05090498924255371s Agents have converged to Goal 0 after 78 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.052908897399902344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.0990145206451416s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.07299947738647461s Agents have converged to Goal 2 after 33 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07699775695800781s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 1, 1]. Execution Time: 0.08498239517211914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 54: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1159977912902832s Agents have converged to Goal 1 after 54 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.09609365463256836s Agents have converged to Goal 2 after 41 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.007998228073120117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.00800013542175293s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.008012771606445312s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4]. Execution Time: 0.007999897003173828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013000726699829102s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013002872467041016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.014999866485595703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.01294565200805664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.019000768661499023s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.020001888275146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.020003795623779297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.022975921630859375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.02500009536743164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1, 2]. Execution Time: 0.02606797218322754s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.030991554260253906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 3, 0, 3]. Execution Time: 0.02899909019470215s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  84.0 %-------------------\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.0009996891021728516s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [0, 0, 0]. Execution Time: 0.0010001659393310547s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0, 2]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3]. Execution Time: 0.0010018348693847656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0019989013671875s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 1, 3]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 1]. Execution Time: 0.0019991397857666016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.0030007362365722656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 1, 1]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 1, 3, 1]. Execution Time: 0.004003286361694336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 1, 4]. Execution Time: 0.003999471664428711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.014987468719482422s Agents have converged to Goal 1 after 100 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [2, 2]. Execution Time: 0.016898393630981445s Agents have converged to Goal 2 after 21 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.0179903507232666s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.016910314559936523s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.03599977493286133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.028920888900756836s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [0, 0, 0]. Execution Time: 0.03189563751220703s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [3, 3, 3]. Execution Time: 0.03699994087219238s Agents have converged to Goal 3 after 34 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04898428916931152s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 57: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05199885368347168s Agents have converged to Goal 2 after 57 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05499744415283203s Agents have converged to Goal 0 after 40 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0709984302520752s Agents have converged to Goal 3 after 32 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07690715789794922s Agents have converged to Goal 0 after 40 iterations. Use EP: True\n",
      "Iteration 86: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08100032806396484s Agents have converged to Goal 2 after 86 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11592817306518555s Agents have converged to Goal 0 after 40 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09800934791564941s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.009000062942504883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [0, 0]. Execution Time: 0.007999897003173828s Agents have converged to Goal 0 after 37 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.008997440338134766s Agents have converged to Goal 2 after 17 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.008009910583496094s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.012899637222290039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 78: Agents have selected goals [2, 2, 2]. Execution Time: 0.017001628875732422s Agents have converged to Goal 2 after 78 iterations. Use EP: False\n",
      "Iteration 44: Agents have selected goals [0, 0, 0]. Execution Time: 0.014020442962646484s Agents have converged to Goal 0 after 44 iterations. Use EP: False\n",
      "Iteration 89: Agents have selected goals [3, 3, 3]. Execution Time: 0.013999700546264648s Agents have converged to Goal 3 after 89 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.017993927001953125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.022997617721557617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01799941062927246s Agents have converged to Goal 0 after 44 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.030996084213256836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 0, 1]. Execution Time: 0.02499985694885254s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 2, 0]. Execution Time: 0.026081562042236328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 60: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.031949520111083984s Agents have converged to Goal 0 after 60 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.029080867767333984s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  86.0 %-------------------\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.0009062290191650391s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 9: Agents have selected goals [2, 2]. Execution Time: 0.0010352134704589844s Agents have converged to Goal 2 after 9 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.0019137859344482422s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.0019991397857666016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2]. Execution Time: 0.001003265380859375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0019998550415039062s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 0]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 2]. Execution Time: 0.0019996166229248047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 4]. Execution Time: 0.001998424530029297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 0, 2]. Execution Time: 0.003000020980834961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 3, 2, 1]. Execution Time: 0.003998517990112305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 2, 4, 1]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [1, 1]. Execution Time: 0.014999151229858398s Agents have converged to Goal 1 after 36 iterations. Use EP: True\n",
      "Iteration 9: Agents have selected goals [2, 2]. Execution Time: 0.0149993896484375s Agents have converged to Goal 2 after 9 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1]. Execution Time: 0.017019033432006836s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.01700139045715332s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.029999732971191406s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1]. Execution Time: 0.035013675689697266s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.030890941619873047s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [3, 3, 3]. Execution Time: 0.031999826431274414s Agents have converged to Goal 3 after 49 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.051001548767089844s Agents have converged to Goal 1 after 35 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.07610678672790527s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 50: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05300021171569824s Agents have converged to Goal 2 after 50 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.056997060775756836s Agents have converged to Goal 1 after 41 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.08211159706115723s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08311152458190918s Agents have converged to Goal 2 after 34 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.11191844940185547s Agents have converged to Goal 2 after 34 iterations. Use EP: True\n",
      "Iteration 64: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0969998836517334s Agents have converged to Goal 1 after 64 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.008991479873657227s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [2, 2]. Execution Time: 0.00800013542175293s Agents have converged to Goal 2 after 34 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3]. Execution Time: 0.008000373840332031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.009000062942504883s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013000249862670898s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013094186782836914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.017985105514526367s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 1, 3]. Execution Time: 0.014000654220581055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0]. Execution Time: 0.018999814987182617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.020000219345092773s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.021002769470214844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.020999908447265625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 1]. Execution Time: 0.0260012149810791s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 2, 2, 2]. Execution Time: 0.031998634338378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 2, 2]. Execution Time: 0.031996726989746094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.027012348175048828s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  88.0 %-------------------\n",
      "Iteration 15: Agents have selected goals [1, 1]. Execution Time: 0.00099945068359375s Agents have converged to Goal 1 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 7: Agents have selected goals [0, 0]. Execution Time: 0.00099945068359375s Agents have converged to Goal 0 after 7 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.0010004043579101562s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 2, 0]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0]. Execution Time: 0.001001119613647461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.0030045509338378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 0, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.003999471664428711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 0, 0, 2]. Execution Time: 0.003000497817993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2, 0]. Execution Time: 0.004995584487915039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 0, 2]. Execution Time: 0.003999948501586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.018106460571289062s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.018000125885009766s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.018000364303588867s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [0, 0]. Execution Time: 0.01798415184020996s Agents have converged to Goal 0 after 13 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1, 1]. Execution Time: 0.02899789810180664s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2, 2]. Execution Time: 0.03098440170288086s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [0, 0, 0]. Execution Time: 0.03099822998046875s Agents have converged to Goal 0 after 35 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.039997100830078125s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.049001455307006836s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.057914018630981445s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 46: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05600094795227051s Agents have converged to Goal 0 after 46 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.06301355361938477s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 63: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.07891082763671875s Agents have converged to Goal 0 after 63 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08800077438354492s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.11588644981384277s Agents have converged to Goal 0 after 48 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 2]. Execution Time: 0.09999990463256836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.008099555969238281s Agents have converged to Goal 1 after 19 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.007999897003173828s Agents have converged to Goal 1 after 28 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.010000228881835938s Agents have converged to Goal 2 after 18 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.009000539779663086s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.012999773025512695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [2, 2, 2]. Execution Time: 0.013017892837524414s Agents have converged to Goal 2 after 24 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.013909101486206055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.015000343322753906s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.018913745880126953s Agents have converged to Goal 1 after 33 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.01900029182434082s Agents have converged to Goal 2 after 40 iterations. Use EP: False\n",
      "Iteration 45: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.018999338150024414s Agents have converged to Goal 0 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04109025001525879s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.026000261306762695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.02601146697998047s Agents have converged to Goal 2 after 24 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.03200221061706543s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.04600214958190918s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  90.0 %-------------------\n",
      "Iteration 14: Agents have selected goals [1, 1]. Execution Time: 0.0009999275207519531s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.0010228157043457031s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1]. Execution Time: 0.002002239227294922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4]. Execution Time: 0.0010001659393310547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1, 0]. Execution Time: 0.001998424530029297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 1]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0, 1]. Execution Time: 0.003999233245849609s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 0]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 1, 0, 1]. Execution Time: 0.005000114440917969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 1, 1]. Execution Time: 0.0039975643157958984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [1, 1]. Execution Time: 0.01699972152709961s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [0, 0]. Execution Time: 0.017998695373535156s Agents have converged to Goal 0 after 30 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.0189974308013916s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.01699066162109375s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [1, 1, 1]. Execution Time: 0.03209352493286133s Agents have converged to Goal 1 after 55 iterations. Use EP: True\n",
      "Iteration 45: Agents have selected goals [0, 0, 0]. Execution Time: 0.02908635139465332s Agents have converged to Goal 0 after 45 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.0309751033782959s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [4, 4, 4]. Execution Time: 0.0330815315246582s Agents have converged to Goal 4 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.05100107192993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.053896427154541016s Agents have converged to Goal 0 after 44 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.05900001525878906s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.057997703552246094s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 51: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09190177917480469s Agents have converged to Goal 1 after 51 iterations. Use EP: True\n",
      "Iteration 45: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.08999824523925781s Agents have converged to Goal 0 after 45 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.1609947681427002s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09409761428833008s Agents have converged to Goal 1 after 43 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.007999897003173828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.008999824523925781s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.008059263229370117s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.00800180435180664s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.013916730880737305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [0, 0, 0]. Execution Time: 0.013000011444091797s Agents have converged to Goal 0 after 45 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.013015270233154297s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [0, 0, 0]. Execution Time: 0.01308894157409668s Agents have converged to Goal 0 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0190887451171875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.019012928009033203s Agents have converged to Goal 0 after 44 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.018993616104125977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01990818977355957s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 51: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.02609419822692871s Agents have converged to Goal 1 after 51 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.026109933853149414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.03201460838317871s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.02901172637939453s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  92.0 %-------------------\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.0010001659393310547s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 6: Agents have selected goals [1, 1]. Execution Time: 0.001004934310913086s Agents have converged to Goal 1 after 6 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.0019102096557617188s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1]. Execution Time: 0.0019996166229248047s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3, 3]. Execution Time: 0.0009989738464355469s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 4]. Execution Time: 0.0009999275207519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0019986629486083984s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.002000093460083008s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1]. Execution Time: 0.002001047134399414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 4, 0]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0029997825622558594s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.003000020980834961s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1, 0]. Execution Time: 0.003992557525634766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 3, 4, 0, 3]. Execution Time: 0.004000663757324219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.015000104904174805s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.01909184455871582s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.01700115203857422s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4]. Execution Time: 0.017000198364257812s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.03200125694274902s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [1, 1, 1]. Execution Time: 0.030908584594726562s Agents have converged to Goal 1 after 38 iterations. Use EP: True\n",
      "Iteration 78: Agents have selected goals [1, 1, 1]. Execution Time: 0.03099536895751953s Agents have converged to Goal 1 after 78 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [4, 4, 4]. Execution Time: 0.03210949897766113s Agents have converged to Goal 4 after 30 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04991006851196289s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.051000356674194336s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.12099862098693848s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.06013846397399902s Agents have converged to Goal 3 after 33 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07800006866455078s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07990694046020508s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.11299514770507812s Agents have converged to Goal 3 after 32 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.09591007232666016s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.009000062942504883s Agents have converged to Goal 1 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.007999420166015625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1]. Execution Time: 0.008078575134277344s Agents have converged to Goal 1 after 32 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [4, 4]. Execution Time: 0.006999492645263672s Agents have converged to Goal 4 after 33 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.013000249862670898s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.012999296188354492s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 58: Agents have selected goals [2, 2, 2]. Execution Time: 0.014000177383422852s Agents have converged to Goal 2 after 58 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [4, 4, 4]. Execution Time: 0.012909173965454102s Agents have converged to Goal 4 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0]. Execution Time: 0.019121170043945312s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.022020816802978516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.030999422073364258s Agents have converged to Goal 1 after 33 iterations. Use EP: False\n",
      "Iteration 59: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.023000001907348633s Agents have converged to Goal 3 after 59 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 1]. Execution Time: 0.023981809616088867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.027012348175048828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.03209042549133301s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 99: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.029000043869018555s Agents have converged to Goal 3 after 99 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  94.0 %-------------------\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.0s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [2, 2]. Execution Time: 0.0s Agents have converged to Goal 2 after 10 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4]. Execution Time: 0.0010004043579101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [1, 1, 1]. Execution Time: 0.0009922981262207031s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.001997232437133789s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 4]. Execution Time: 0.0009996891021728516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.002000093460083008s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 0]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 1]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 4, 1]. Execution Time: 0.0019979476928710938s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 0, 1]. Execution Time: 0.004011869430541992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 0, 1, 1]. Execution Time: 0.0029981136322021484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 4, 1, 1]. Execution Time: 0.0030002593994140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.016000032424926758s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [2, 2]. Execution Time: 0.01599860191345215s Agents have converged to Goal 2 after 10 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [1, 1]. Execution Time: 0.01591348648071289s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.01700139045715332s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1]. Execution Time: 0.034996747970581055s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [2, 2, 2]. Execution Time: 0.037999868392944336s Agents have converged to Goal 2 after 40 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1]. Execution Time: 0.031000137329101562s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1, 1]. Execution Time: 0.030995607376098633s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05000138282775879s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05190896987915039s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05299019813537598s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05901217460632324s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.07890725135803223s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08101844787597656s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.11399722099304199s Agents have converged to Goal 1 after 49 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.09799909591674805s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [1, 1]. Execution Time: 0.0070002079010009766s Agents have converged to Goal 1 after 53 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [2, 2]. Execution Time: 0.009000062942504883s Agents have converged to Goal 2 after 20 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [1, 1]. Execution Time: 0.012000799179077148s Agents have converged to Goal 1 after 15 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.009000778198242188s Agents have converged to Goal 1 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.013001680374145508s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.012904167175292969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 69: Agents have selected goals [1, 1, 1]. Execution Time: 0.014906167984008789s Agents have converged to Goal 1 after 69 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.013997554779052734s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.01999688148498535s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.018999814987182617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 51: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.020089149475097656s Agents have converged to Goal 1 after 51 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 3]. Execution Time: 0.020029067993164062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 96: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0260007381439209s Agents have converged to Goal 1 after 96 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.04902362823486328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 3, 2]. Execution Time: 0.034002065658569336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.03000617027282715s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  96.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [1, 0]. Execution Time: 0.0s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.0010073184967041016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2]. Execution Time: 0.0008900165557861328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4]. Execution Time: 0.0009195804595947266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0019998550415039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 2]. Execution Time: 0.002000093460083008s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2]. Execution Time: 0.00099945068359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 3]. Execution Time: 0.001999378204345703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.001998424530029297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 2, 2]. Execution Time: 0.0029997825622558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 3]. Execution Time: 0.0020003318786621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 3, 3]. Execution Time: 0.0029993057250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 1]. Execution Time: 0.0039980411529541016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 2, 2, 2]. Execution Time: 0.0050029754638671875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 3, 3]. Execution Time: 0.004999637603759766s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 3, 3, 0]. Execution Time: 0.004000186920166016s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.01699090003967285s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [1, 1]. Execution Time: 0.016999483108520508s Agents have converged to Goal 1 after 36 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.015990495681762695s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [4, 4]. Execution Time: 0.015999555587768555s Agents have converged to Goal 4 after 23 iterations. Use EP: True\n",
      "Iteration 52: Agents have selected goals [1, 1, 1]. Execution Time: 0.03400135040283203s Agents have converged to Goal 1 after 52 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2]. Execution Time: 0.03200078010559082s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2, 2]. Execution Time: 0.03099966049194336s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.03399467468261719s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.05500483512878418s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05608248710632324s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.05499696731567383s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.055921316146850586s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.08099722862243652s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.08299970626831055s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 3]. Execution Time: 0.11409664154052734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.10010695457458496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.008002042770385742s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.007996797561645508s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.008104324340820312s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.009000062942504883s Agents have converged to Goal 2 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.01201486587524414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [2, 2, 2]. Execution Time: 0.011981964111328125s Agents have converged to Goal 2 after 27 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2, 2]. Execution Time: 0.013969659805297852s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 24: Agents have selected goals [2, 2, 2]. Execution Time: 0.020000696182250977s Agents have converged to Goal 2 after 24 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.01800084114074707s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.02091383934020996s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.018999814987182617s Agents have converged to Goal 2 after 34 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.02000117301940918s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 1]. Execution Time: 0.04401278495788574s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 54: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.02699589729309082s Agents have converged to Goal 2 after 54 iterations. Use EP: False\n",
      "Iteration 26: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05100274085998535s Agents have converged to Goal 2 after 26 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.02811431884765625s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  98.0 %-------------------\n"
     ]
    }
   ],
   "source": [
    "# Re-define the environment and simulation parameters here\n",
    "interactive = True  # Set to True to display the animation in the notebook\n",
    "args = {}\n",
    "count = 0; flag_converged = True\n",
    "draft_results = []\n",
    "max_iterations = 50\n",
    "convergence_type = 'converge'\n",
    "list_types = ['A','B']\n",
    "number_of_heading_options = 8; number_of_velocity_options = 4\n",
    "env_size = 30  # Environment size\n",
    "iterations_per_episode = 100  # Number of iterations per episode\n",
    "\n",
    "while flag_converged and count < max_iterations:\n",
    "    for use_ep in [True, False]:\n",
    "        for greedy in [True, False]:\n",
    "            if greedy and not use_ep:\n",
    "                continue\n",
    "            for num_agents in np.arange(2, 6, 1):\n",
    "                for num_goals in np.arange(2, 6, 1):\n",
    "                    random_seed = count  # Random seed \n",
    "                    np.random.seed(random_seed)  # Set random seed\n",
    "                    goals = np.random.uniform(1,env_size-1,size=(num_goals, 2))  # Goal positions\n",
    "                    agent_positions = np.hstack((np.random.uniform(0,env_size,size=(num_agents, 2)),np.zeros((num_agents,1))))  # Initial agent positions\n",
    "                    # Set random goals\n",
    "                    args = dict({\n",
    "                    'goals': goals, # Goal positions\n",
    "                    'agent_types': np.random.choice(list_types,num_agents), # Agent types\n",
    "                    'home_base': np.array([0,0]), # Home base position\n",
    "                    'agent_positions': agent_positions, # Initial agent positions\n",
    "                    'velocity_options': np.linspace(0,1,number_of_velocity_options,endpoint=True), # Velocity options\n",
    "                    'num_heading_options': number_of_heading_options, # Number of heading options\n",
    "                    'heading_options': np.linspace(-np.pi,np.pi,number_of_heading_options,endpoint=True),\n",
    "                    'observation_error_std': 0.5, # Observation error standard deviation\n",
    "                    'num_actions': number_of_heading_options*number_of_velocity_options, # Number of actions\n",
    "                    'env_size': env_size, # Environment size\n",
    "                    'max_distance_measure': env_size + 20,\n",
    "                    'max_heading_measure': np.pi, # Maximum heading measure\n",
    "                    'prior': np.ones(goals.shape[0]) / goals.shape[0], # Prior belief\n",
    "                    'use_ep': use_ep, # Use epistemic planning (2nd order reasoning)\n",
    "                    'greedy': greedy, # Use greedy actions\n",
    "                    'horizon': 5, # Horizon for free energy checking\n",
    "                    'mcts_iterations': 100, # Number of MCTS iterations\n",
    "                    'use_mcts': False,\n",
    "                    'use_rhc': False, # Use receding horizon control\n",
    "                    'use_threading': False, #TODO: Implement threading\n",
    "                    'convergence_type': convergence_type, # Convergence type\n",
    "                    'dt': 1.0, # Time step\n",
    "                    })\n",
    "\n",
    "                    # Check convergence for different types of conergence criterion\n",
    "                    if args['convergence_type'] == 'exclusive':\n",
    "                        tuple_elements = [i for i in range(goals.shape[0])]\n",
    "                        configurations = list(itertools.permutations(tuple_elements))\n",
    "                        args['reward_configs'] = configurations # Reward configurations if different goals\n",
    "                    else:\n",
    "                        args['reward_configs'] = [tuple(np.repeat(i, num_agents)) for i in range(num_goals)]\n",
    "                    \n",
    "\n",
    "                    # print(\"Initial Prior: \", args['prior'])\n",
    "\n",
    "                    # Run the simulation\n",
    "                    results = aif.run_simulation(args, iterations_per_episode)\n",
    "                    # print(\"Final Prior: \", prior)\n",
    "                    # print(\"Agent Types: \", args['agent_types'])\n",
    "\n",
    "                    # energy_results, ending_energy = aif.parse_free_energy_scores(avg_nrg_over_time, num_frames)\n",
    "                    draft_results.append([random_seed, results['converged'], num_goals, num_agents, args['agent_types'], \n",
    "                                        use_ep , greedy, results['iteration']])\n",
    "    print(\"-------------------\")\n",
    "    print(\"\\rPercentage Complete: \", count/max_iterations*100, \"%\", end=\"\")\n",
    "    print(\"-------------------\")\n",
    "    count += 1\n",
    "\n",
    "# Save the results\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "df = pd.DataFrame(draft_results, columns=['seed','converged','num_goals','num_agents','agent_types','use_ep','greedy','num_iters'])    \n",
    "df.to_csv(pwd + 'data/results_isobeliefs_envSize30_2-5Agents_numGoals2-5_WithUncertainty_Convergent{}.csv'.format(current_time), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "energy_results, ending_energy = aif.parse_free_energy_scores(avg_nrg_over_time, num_frames)\n",
    "aif.plot_energy(energy_results, num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final distances:  [[0.02488646 9.98047395]\n",
      " [0.03748569 9.97078675]\n",
      " [0.09155599 9.99940493]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate distance to final goals\n",
    "final_distances = np.zeros((num_agents, goals.shape[0]))\n",
    "for i in range(num_agents):\n",
    "    for j in range(goals.shape[0]):\n",
    "        final_distances[i,j] = np.linalg.norm(final_positions[i,:2] - goals[j,:])\n",
    "print(\"Final distances: \", final_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Azimuth:  [-2.40692159 -2.9485224 ]\n",
      "Relative Azimuth:  [0.1201765  0.10942825]\n",
      "Observed Azimuth:  -2.5305504167886905\n",
      "Salience:  [0.1201765  0.10942825]\n",
      "1.2900073408606396\n"
     ]
    }
   ],
   "source": [
    "# Scratch code for testing\n",
    "\n",
    "goals = np.array([[0,0],[0.,10.]])\n",
    "my_pose = np.array([14.12709979, 12.76192634,  0.])\n",
    "other_pose = np.array([6.30305407,  7.28140647,  0.])\n",
    "saliences = np.zeros(goals.shape[0])\n",
    "goal_azimuths = np.arctan2(goals[:, 1] - my_pose[1], goals[:, 0] - my_pose[0])\n",
    "observed_azimuth = np.arctan2(other_pose[1] - my_pose[1], other_pose[0] - my_pose[0])\n",
    "relative_azimuths = np.abs((goal_azimuths - observed_azimuth + np.pi) % (2 * np.pi) - np.pi)\n",
    "azimuth_salience = 1./8 * np.exp(- relative_azimuths / np.pi)  # normalize and invert to make smaller angles more salient\n",
    "saliences += azimuth_salience\n",
    "# Compute if observed robot is heading towards the goal\n",
    "# heading_to_goal = (np.arctan2(goals[:, 1] - observation['position'][1], goals[:, 0] - observation['position'][0]) - observation['heading'] + np.pi) % (2 * np.pi) - np.pi\n",
    "# heading_salience = 1./8 * np.exp(- np.abs(heading_to_goal) / np.pi)\n",
    "# saliences += heading_salience\n",
    "\n",
    "\n",
    "print(\"Goal Azimuth: \", goal_azimuths)\n",
    "print(\"Relative Azimuth: \", azimuth_salience)\n",
    "print(\"Observed Azimuth: \", observed_azimuth)\n",
    "print(\"Salience: \", saliences)\n",
    "# print(\"Heading Salience: \", heading_salience)\n",
    "print(np.exp(0.8/np.pi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
