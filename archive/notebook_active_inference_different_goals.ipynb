{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 23,
>>>>>>> laurens_work
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "c:\\Users\\Jonathan.Reasoner\\Documents\\active_inference_playground\\aif_multi_robot\\archive/\n"
=======
      "c:\\Users\\jonat\\OneDrive\\Documents\\Active_Inference\\active_inference_playground\\aif_multi_robot\\archive/\n"
>>>>>>> laurens_work
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "%matplotlib inline\n",
>>>>>>> laurens_work
    "import numpy as np, matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from palettable.colorbrewer.qualitative import Set1_9\n",
    "import os\n",
    "from datetime import datetime\n",
<<<<<<< HEAD
    "from IPython.display import HTML\n",
=======
    "from IPython.display import HTML, display\n",
>>>>>>> laurens_work
    "import itertools\n",
    "\n",
    "\n",
    "pwd = os.path.abspath('') + \"/\"\n",
    "print(pwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  0 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (2, 1, 0)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (2, 0, 1)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  1 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  0 , therefore I should go to  1\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 0, 2)\n",
      "I am agent  1 , therefore I should go to  0\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  2 , therefore I should go to  2\n",
      "The best permutation is  (0, 1, 2)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  2 , therefore I should go to  1\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  0 , therefore I should go to  0\n",
      "The best permutation is  (0, 2, 1)\n",
      "I am agent  1 , therefore I should go to  2\n",
      "The best permutation is  (1, 2, 0)\n",
      "I am agent  2 , therefore I should go to  0\n",
      "Agents did not converge to the same goal within the maximum iterations.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< HEAD
    "cmap = Set1_9.mpl_colors\n",
    "# Re-define the environment and simulation parameters here\n",
    "goals = np.array([[2, 6], [5, 6], [9, 6]], dtype=float)  # Goal positions\n",
    "agent_positions = np.array([[2, 1], [5, 1], [9,1]], dtype=float)  # Initial agent positions\n",
    "num_agents = agent_positions.shape[0]  # Number of agents\n",
    "velocity_options = [0, 0.1, 0.5, 1.0]  # Velocity options for the agents\n",
    "heading_options = np.linspace(-np.pi,np.pi,12)  # Heading options (radians)\n",
=======
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.colors import to_rgba_array\n",
    "import itertools\n",
    "\n",
    "# Environment and simulation parameters\n",
    "cmap = to_rgba_array(['tab:blue', 'tab:orange', 'tab:green'])\n",
    "goals = np.array([[5, 1], [5, 5], [5, 9]], dtype=float)  # Goal positions\n",
    "agent_positions = np.array([[1, 1], [1, 5], [1, 9]], dtype=float)  # Initial agent positions\n",
    "num_agents = agent_positions.shape[0]  # Number of agents\n",
    "velocity_options = [0, 0.1, 0.5, 1.0]  # Velocity options for the agents\n",
    "heading_options = np.linspace(-np.pi, np.pi, 12)  # Heading options (radians)\n",
>>>>>>> laurens_work
    "observation_error_std = 3.0  # Observation noise standard deviation\n",
    "max_iterations = 100  # Maximum number of iterations\n",
    "\n",
    "# Initialize figure for plotting\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim(-5, 15)\n",
    "plt.ylim(-5, 15)\n",
<<<<<<< HEAD
=======
    "\n",
>>>>>>> laurens_work
    "# Paths (with smaller line width)\n",
    "agent_paths = [ax.plot([], [], 'o-', markersize=3, linewidth=1, alpha=0.5, color=cmap[i])[0] for i in range(num_agents)]\n",
    "# Current positions (with larger markers)\n",
    "agent_markers = [ax.plot([], [], 'o', markersize=10, color=cmap[i])[0] for i in range(num_agents)]\n",
    "goal_plots = [ax.plot(goal[0], goal[1], 'x', markersize=10, color='purple')[0] for goal in goals]  # Plot goals\n",
    "\n",
    "def init():\n",
    "    \"\"\"Initialize the background of the plot.\"\"\"\n",
    "    for agent_path, agent_marker in zip(agent_paths, agent_markers):\n",
    "        agent_path.set_data([], [])\n",
    "        agent_marker.set_data([], [])\n",
    "    return agent_paths + agent_markers\n",
    "\n",
<<<<<<< HEAD
    "def update(frame):\n",
    "    \"\"\"Update the plot for each frame.\"\"\"    \n",
    "    decisions = [make_decision(agent_id, agent_positions) for agent_id in range(num_agents)]\n",
    "    \n",
    "    # Update positions based on decisions\n",
    "    for agent_id, (velocity, heading) in enumerate(decisions):\n",
    "        dx = velocity * np.cos(heading)\n",
    "        dy = velocity * np.sin(heading)\n",
    "        agent_positions[agent_id] += np.array([dx, dy])\n",
    "    \n",
    "    # Update plot data\n",
    "    for agent_id, (agent_path, agent_marker) in enumerate(zip(agent_paths, agent_markers)):\n",
    "        xdata, ydata = agent_path.get_data()\n",
    "        xnew, ynew = agent_positions[agent_id]\n",
    "        xdata = np.append(xdata, xnew)\n",
    "        ydata = np.append(ydata, ynew)\n",
    "        agent_path.set_data(xdata, ydata)\n",
    "        agent_marker.set_data(xnew, ynew)\n",
    "    \n",
    "    return agent_paths + agent_markers\n",
    "\n",
    "\n",
=======
>>>>>>> laurens_work
    "def simulate_observation(true_position):\n",
    "    \"\"\"Simulate noisy observation of another agent's position.\"\"\"\n",
    "    observed_position = true_position + np.random.normal(0, observation_error_std, true_position.shape)\n",
    "    return observed_position\n",
    "\n",
<<<<<<< HEAD
    "def calculate_kl_divergence(p, q):\n",
    "    \"\"\"Calculate KL divergence between two probability distributions.\"\"\"\n",
    "    return np.sum(p * np.log(p / q + np.exp(-16)))\n",
    "\n",
    "def calculate_shannon_entropy(p):\n",
    "    \"\"\"Calculate Shannon entropy of a probability distribution.\"\"\"\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
=======
>>>>>>> laurens_work
    "def predict_agent_position(agent_position, velocity, heading):\n",
    "    \"\"\"Predict agent's next position based on chosen velocity and heading.\"\"\"\n",
    "    dx = velocity * np.cos(heading)\n",
    "    dy = velocity * np.sin(heading)\n",
    "    return agent_position + np.array([dx, dy])\n",
    "\n",
    "def make_decision(agent_id, agent_positions):\n",
    "    \"\"\"Agent decision-making based on active inference to encourage convergence on a shared goal.\"\"\"\n",
    "    best_action = None\n",
    "    best_score = np.inf\n",
    "\n",
    "    observed_positions_array = np.zeros((num_agents, 2))\n",
    "    for i in range(num_agents):\n",
    "        observed_positions_array[i] = simulate_observation(agent_positions[i])\n",
    "    #other_agent_ids = range(0,num_agents)\n",
    "    #other_agent_ids = np.delete(other_agent_ids, agent_id)\n",
    "    #other_agent_observed_position = np.zeros((other_agent_ids.shape[0],2))\n",
    "    #for count, other_agent_id in enumerate(other_agent_ids):\n",
    "    #    other_agent_observed_position[count] = simulate_observation(agent_positions[other_agent_id])\n",
    "\n",
    "    # TODO create empty array to collect all measurements\n",
    "    distance_measurement_array = np.zeros((num_agents,len(goals)))\n",
    "    # TODO populate the array with all of the measurements\n",
    "    for i in range(num_agents):\n",
    "        for j in range(len(goals)):\n",
    "            distance_measurement_array[i, j] = np.linalg.norm(observed_positions_array[i] - goals[j])\n",
    "    # TODO find total distance of all permutations\n",
=======
    "    observed_positions_array = np.zeros((num_agents, 2))\n",
    "    for i in range(num_agents):\n",
    "        observed_positions_array[i] = simulate_observation(agent_positions[i])\n",
    "    \n",
    "    distance_measurement_array = np.zeros((num_agents, len(goals)))\n",
    "    for i in range(num_agents):\n",
    "        for j in range(len(goals)):\n",
    "            distance_measurement_array[i, j] = np.linalg.norm(observed_positions_array[i] - goals[j])\n",
    "    \n",
>>>>>>> laurens_work
    "    permutations = itertools.permutations(range(len(goals)))\n",
    "    min_total_distance = float('inf')\n",
    "    best_permutation = None\n",
    "\n",
    "    for perm in permutations:\n",
    "        total_distance = sum(distance_measurement_array[i, perm[i]] for i in range(num_agents))\n",
    "        if total_distance < min_total_distance:\n",
    "            min_total_distance = total_distance\n",
    "            best_permutation = perm\n",
    "\n",
<<<<<<< HEAD
    "    print('The best permutation is ', best_permutation)\n",
    "    print('I am agent ', agent_id, ', therefore I should go to ', best_permutation[agent_id])\n",
    "\n",
    "    # TODO find the best action based on this minimum distance\n",
    "\n",
    "    goal = best_permutation[agent_id]\n",
    "    \n",
=======
    "    goal = best_permutation[agent_id]\n",
>>>>>>> laurens_work
    "    goal_location = goals[goal]\n",
    "  \n",
    "    goal_scores = []\n",
    "\n",
    "    for velocity in velocity_options:\n",
    "        for heading in heading_options:\n",
    "            predicted_position = predict_agent_position(agent_positions[agent_id], velocity, heading)\n",
<<<<<<< HEAD
    "            \n",
    "            # Estimate how both agents are aligned with reaching the current goal\n",
    "            distance_to_goal = np.linalg.norm(predicted_position - goal_location)\n",
    "\n",
    "            # Use the sum of both distances as a simple score for this action's alignment with the goal\n",
    "            goal_alignment_score = distance_to_goal\n",
    "            \n",
    "            goal_scores.append((goal_alignment_score, velocity, heading))\n",
    "\n",
    "    # Choose the action (for the current goal) that minimizes the combined distance\n",
    "    best_action_for_goal = min(goal_scores, key=lambda x: x[0])\n",
    "\n",
    "    # Update best action if this goal is more attainable than previous best\n",
=======
    "            distance_to_goal = np.linalg.norm(predicted_position - goal_location)\n",
    "            goal_alignment_score = distance_to_goal\n",
    "            goal_scores.append((goal_alignment_score, velocity, heading))\n",
    "\n",
    "    best_action_for_goal = min(goal_scores, key=lambda x: x[0])\n",
    "\n",
>>>>>>> laurens_work
    "    if best_action_for_goal[0] < best_score:\n",
    "        best_score = best_action_for_goal[0]\n",
    "        best_action = best_action_for_goal[1], best_action_for_goal[2]\n",
    "\n",
    "    return best_action\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "def run_simulation(max_iterations=100):\n",
    "    \"\"\"Run the simulation until both agents converge to the same goal or max iterations reached.\"\"\"\n",
    "    current_positions = np.copy(agent_positions)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        decisions = [make_decision(agent_id, current_positions) for agent_id in range(num_agents)]\n",
    "        \n",
    "        # Update agent positions based on their decisions\n",
    "        for agent_id, (velocity, heading) in enumerate(decisions):\n",
    "            dx = velocity * np.cos(heading)\n",
    "            dy = velocity * np.sin(heading)\n",
    "            current_positions[agent_id] += np.array([dx, dy])\n",
    "        decided_velocities = [decision[0] for decision in decisions]\n",
    "        \n",
    "        # Check if agents have converged to the same goal\n",
    "        distances_to_goals = [np.linalg.norm(goals - pos, axis=1) for pos in current_positions]\n",
    "        goal_reached_by_agents = [np.argmin(distances) for distances in distances_to_goals]\n",
    "        distances_to_selected_goal = [np.min(distances) for distances in distances_to_goals]\n",
    "        \n",
    "        if (np.array(distances_to_selected_goal)<0.2).all() and decided_velocities == [0]*num_agents:\n",
    "            print(distances_to_selected_goal)\n",
    "            print(f\"Agent 0 converged to Goal {goal_reached_by_agents[0]} after {iteration + 1} iterations.\")\n",
    "            print(f'Agent 1 converged to Goal {goal_reached_by_agents[1]} after {iteration +1} iterations')\n",
    "            print(f'Agent 2 converged to Goal {goal_reached_by_agents[2]} after {iteration +1} iterations')\n",
    "\n",
    "            return current_positions, goal_reached_by_agents[0], iteration\n",
    "\n",
    "    print(\"Agents did not converge to the same goal within the maximum iterations.\")\n",
    "    return current_positions, None, iteration\n",
    "\n",
    "# Run the simulation\n",
    "final_positions, goal_converged, num_frames = run_simulation()\n",
    "# Create animation\n",
    "#ani = FuncAnimation(fig, update, frames=range(num_frames), init_func=init, blit=True, repeat=True)\n",
    "\n",
    "# Save the animation as a video\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#HTML(ani.to_html5_video()) # Use an interactive backend for animation\n",
    "\n",
    "# ani.save(pwd + \"videos/two_goals_choice\" + current_time + \".mp4\", writer='ffmpeg', fps=3, dpi=300)\n",
    "# print(\"Image saved as: \", pwd + \"videos/two_goals_choice\" + current_time + \".mp4\")\n"
=======
    "# Global variable to keep track of agent positions during animation\n",
    "current_positions = np.copy(agent_positions)\n",
    "\n",
    "def update(frame):\n",
    "    \"\"\"Update the plot for each frame.\"\"\"\n",
    "    global current_positions\n",
    "    decisions = [make_decision(agent_id, current_positions) for agent_id in range(num_agents)]\n",
    "    \n",
    "    # Update positions based on decisions\n",
    "    for agent_id, (velocity, heading) in enumerate(decisions):\n",
    "        dx = velocity * np.cos(heading)\n",
    "        dy = velocity * np.sin(heading)\n",
    "        current_positions[agent_id] += np.array([dx, dy])\n",
    "    \n",
    "    # Update plot data\n",
    "    for agent_id, (agent_path, agent_marker) in enumerate(zip(agent_paths, agent_markers)):\n",
    "        xdata, ydata = agent_path.get_data()\n",
    "        xnew, ynew = current_positions[agent_id]\n",
    "        xdata = np.append(xdata, xnew)\n",
    "        ydata = np.append(ydata, ynew)\n",
    "        agent_path.set_data(xdata, ydata)\n",
    "        agent_marker.set_data(xnew, ynew)\n",
    "    \n",
    "    return agent_paths + agent_markers\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update, frames=max_iterations, init_func=init, blit=True, repeat=True)\n",
    "display(HTML(ani.to_jshtml())) \n",
    "print('program has finsihed')"
>>>>>>> laurens_work
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the environment and simulation parameters here\n",
    "goals = np.array([[1, 1], [10, 10],[1,12]], dtype=float)  # Goal positions\n",
    "agent_positions = np.array([[9, 1], [1, 9],[4,4]], dtype=float)  # Initial agent positions\n",
    "num_agents = agent_positions.shape[0]  # Number of agents\n",
    "velocity_options = [0, 0.1, 0.5, 1.0]  # Velocity options for the agents\n",
    "heading_options = np.linspace(-np.pi,np.pi,12)  # Heading options (radians)\n",
    "observation_error_std = 3.0  # Observation noise standard deviation\n",
    "max_iterations = 100  # Maximum number of iterations\n",
    "\n",
    "# Initialize figure for plotting\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim(-5, 15)\n",
    "plt.ylim(-5, 15)\n",
    "# Paths (with smaller line width)\n",
    "agent_paths = [ax.plot([], [], 'o-', markersize=3, linewidth=1, alpha=0.5, color=cmap[i])[0] for i in range(num_agents)]\n",
    "# Current positions (with larger markers)\n",
    "agent_markers = [ax.plot([], [], 'o', markersize=10, color=cmap[i])[0] for i in range(num_agents)]\n",
    "goal_plots = [ax.plot(goal[0], goal[1], 'x', markersize=10, color='purple')[0] for goal in goals]  # Plot goals\n",
    "\n",
    "# Run the simulation\n",
    "final_positions, goal_converged, num_frames = run_simulation()\n",
    "# Create animation\n",
    "#ani = FuncAnimation(fig, update, frames=range(num_frames), init_func=init, blit=True, repeat=True)\n",
    "\n",
    "# Save the animation as a video\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#HTML(ani.to_html5_video()) # Use an interactive backend for animation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
