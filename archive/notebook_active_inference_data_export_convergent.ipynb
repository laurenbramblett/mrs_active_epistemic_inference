{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'aif_functions_isobeliefs_convergent' from 'c:\\\\Users\\\\qbr5kx\\\\OneDrive - University of Virginia\\\\Desktop\\\\UVA\\\\PhD Scratch\\\\Active_Epistemic_Inference\\\\aif_multi_robot//aif_catkin_ws/aif_gazebo/scripts\\\\aif_functions_isobeliefs_convergent.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os, sys, importlib, itertools\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Import the aif module\n",
    "pwd = os.path.abspath('') + \"/\"\n",
    "sys.path.insert(1,pwd + '/aif_catkin_ws/aif_gazebo/scripts/')\n",
    "import aif_functions_isobeliefs_convergent as aif\n",
    "\n",
    "importlib.reload(aif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.026872873306274414s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.024996280670166016s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [0, 0]. Execution Time: 0.03460979461669922s Agents have converged to Goal 0 after 13 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [1, 1, 1]. Execution Time: 0.05609488487243652s Agents have converged to Goal 1 after 36 iterations. Use EP: True\n",
      "Iteration 63: Agents have selected goals [1, 1, 1]. Execution Time: 0.05901074409484863s Agents have converged to Goal 1 after 63 iterations. Use EP: True\n",
      "Iteration 52: Agents have selected goals [1, 1, 1]. Execution Time: 0.06188464164733887s Agents have converged to Goal 1 after 52 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.08498835563659668s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08401155471801758s Agents have converged to Goal 1 after 44 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08991479873657227s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.12906765937805176s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 57: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13490891456604004s Agents have converged to Goal 1 after 57 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14890670776367188s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.025001049041748047s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.014045953750610352s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 13: Agents have selected goals [0, 0]. Execution Time: 0.012985944747924805s Agents have converged to Goal 0 after 13 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 1, 1]. Execution Time: 0.02500772476196289s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [2, 2, 2]. Execution Time: 0.024007558822631836s Agents have converged to Goal 2 after 45 iterations. Use EP: False\n",
      "Iteration 43: Agents have selected goals [2, 2, 2]. Execution Time: 0.02499699592590332s Agents have converged to Goal 2 after 43 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0]. Execution Time: 0.03591465950012207s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 42: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.035901784896850586s Agents have converged to Goal 0 after 42 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.038002967834472656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 2]. Execution Time: 0.045074462890625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 1]. Execution Time: 0.05000042915344238s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.06303691864013672s Agents have converged to Goal 0 after 100 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  0.0 %-------------------\n",
      "Iteration 22: Agents have selected goals [0, 0]. Execution Time: 0.024907350540161133s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 8: Agents have selected goals [0, 0]. Execution Time: 0.029000043869018555s Agents have converged to Goal 0 after 8 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.027009010314941406s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.050009965896606445s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0, 0]. Execution Time: 0.05107855796813965s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 0, 0]. Execution Time: 0.060079097747802734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.08400082588195801s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.10200047492980957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.10700154304504395s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.12705016136169434s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13788223266601562s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 4, 4, 4]. Execution Time: 0.14808440208435059s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.014002799987792969s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 9: Agents have selected goals [0, 0]. Execution Time: 0.01800084114074707s Agents have converged to Goal 0 after 9 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.013116598129272461s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.024907588958740234s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [0, 0, 0]. Execution Time: 0.02398681640625s Agents have converged to Goal 0 after 16 iterations. Use EP: False\n",
      "Iteration 38: Agents have selected goals [3, 3, 3]. Execution Time: 0.02498006820678711s Agents have converged to Goal 3 after 38 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03611040115356445s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 3]. Execution Time: 0.0379030704498291s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.033905982971191406s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 1, 2]. Execution Time: 0.04991579055786133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 0, 3]. Execution Time: 0.05300092697143555s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 1, 4, 3]. Execution Time: 0.05404782295227051s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  2.0 %-------------------\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.0260012149810791s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [2, 2]. Execution Time: 0.029006481170654297s Agents have converged to Goal 2 after 11 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.026972055435180664s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2]. Execution Time: 0.056088924407958984s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1]. Execution Time: 0.05611276626586914s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3, 3]. Execution Time: 0.06091046333312988s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.07990527153015137s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0860896110534668s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09209632873535156s Agents have converged to Goal 3 after 47 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 1]. Execution Time: 0.13608956336975098s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1, 1]. Execution Time: 0.16288995742797852s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.15120410919189453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.014902591705322266s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [2, 2]. Execution Time: 0.012999773025512695s Agents have converged to Goal 2 after 11 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.012010812759399414s Agents have converged to Goal 2 after 17 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2, 2]. Execution Time: 0.025985002517700195s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [2, 2, 2]. Execution Time: 0.02299785614013672s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [3, 3, 3]. Execution Time: 0.02291274070739746s Agents have converged to Goal 3 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.03300023078918457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.039000749588012695s Agents have converged to Goal 3 after 18 iterations. Use EP: False\n",
      "Iteration 71: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.03490424156188965s Agents have converged to Goal 4 after 71 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 2, 0]. Execution Time: 0.04899430274963379s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2, 2]. Execution Time: 0.055115461349487305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 2, 2]. Execution Time: 0.0520017147064209s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  4.0 %-------------------\n",
      "Iteration 14: Agents have selected goals [1, 1]. Execution Time: 0.026091814041137695s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.02800154685974121s Agents have converged to Goal 3 after 12 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [4, 4]. Execution Time: 0.026000261306762695s Agents have converged to Goal 4 after 25 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [1, 1, 1]. Execution Time: 0.05300140380859375s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.0588986873626709s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.05290842056274414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08899712562561035s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08495163917541504s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0941324234008789s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.154099702835083s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13509058952331543s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.15399694442749023s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.013917207717895508s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.013959884643554688s Agents have converged to Goal 3 after 12 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [4, 4]. Execution Time: 0.016001462936401367s Agents have converged to Goal 4 after 25 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.023011445999145508s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.02308201789855957s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 44: Agents have selected goals [1, 1, 1]. Execution Time: 0.025986909866333008s Agents have converged to Goal 1 after 44 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03296828269958496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03500056266784668s Agents have converged to Goal 1 after 18 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.039025068283081055s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.049001216888427734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 2, 2]. Execution Time: 0.04800271987915039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 1]. Execution Time: 0.05007457733154297s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  6.0 %-------------------\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.026998519897460938s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2]. Execution Time: 0.025011539459228516s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1]. Execution Time: 0.026995420455932617s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.05401110649108887s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.05107378959655762s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [2, 2, 2]. Execution Time: 0.0579988956451416s Agents have converged to Goal 2 after 41 iterations. Use EP: True\n",
      "Iteration 68: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08409309387207031s Agents have converged to Goal 2 after 68 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08600044250488281s Agents have converged to Goal 2 after 47 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.09500265121459961s Agents have converged to Goal 4 after 37 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13301634788513184s Agents have converged to Goal 2 after 53 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.1559596061706543s Agents have converged to Goal 2 after 47 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.15001320838928223s Agents have converged to Goal 4 after 37 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2]. Execution Time: 0.016919612884521484s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [2, 2]. Execution Time: 0.014036417007446289s Agents have converged to Goal 2 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.013905763626098633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.026001453399658203s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 73: Agents have selected goals [0, 0, 0]. Execution Time: 0.02400827407836914s Agents have converged to Goal 0 after 73 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [2, 2, 2]. Execution Time: 0.022012948989868164s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.03799796104431152s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 47: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.034090280532836914s Agents have converged to Goal 2 after 47 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.038079261779785156s Agents have converged to Goal 4 after 37 iterations. Use EP: False\n",
      "Iteration 53: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.04705691337585449s Agents have converged to Goal 2 after 53 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.04914045333862305s Agents have converged to Goal 2 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 0, 4, 4, 0]. Execution Time: 0.05200314521789551s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  8.0 %-------------------\n",
      "Iteration 19: Agents have selected goals [2, 2]. Execution Time: 0.02502155303955078s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [1, 1]. Execution Time: 0.025915861129760742s Agents have converged to Goal 1 after 40 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [4, 4]. Execution Time: 0.02899789810180664s Agents have converged to Goal 4 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.049410104751586914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [2, 2, 2]. Execution Time: 0.053999900817871094s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [4, 4, 4]. Execution Time: 0.05300021171569824s Agents have converged to Goal 4 after 27 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08900094032287598s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 54: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08900594711303711s Agents have converged to Goal 2 after 54 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.14688777923583984s Agents have converged to Goal 3 after 34 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13188600540161133s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 52: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.1409895420074463s Agents have converged to Goal 2 after 52 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.15491819381713867s Agents have converged to Goal 4 after 28 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [0, 0]. Execution Time: 0.013996124267578125s Agents have converged to Goal 0 after 39 iterations. Use EP: False\n",
      "Iteration 34: Agents have selected goals [0, 0]. Execution Time: 0.013996601104736328s Agents have converged to Goal 0 after 34 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [4, 4]. Execution Time: 0.015119791030883789s Agents have converged to Goal 4 after 23 iterations. Use EP: False\n",
      "Iteration 48: Agents have selected goals [0, 0, 0]. Execution Time: 0.029001235961914062s Agents have converged to Goal 0 after 48 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [2, 2, 2]. Execution Time: 0.02600407600402832s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [4, 4, 4]. Execution Time: 0.02288961410522461s Agents have converged to Goal 4 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03311276435852051s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 89: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03798055648803711s Agents have converged to Goal 0 after 89 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2]. Execution Time: 0.03408098220825195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 43: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.04999566078186035s Agents have converged to Goal 0 after 43 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 2, 2]. Execution Time: 0.0509946346282959s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 2, 4]. Execution Time: 0.05108284950256348s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  10.0 %-------------------\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.027993440628051758s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.030091047286987305s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [3, 3]. Execution Time: 0.03099822998046875s Agents have converged to Goal 3 after 17 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2, 2]. Execution Time: 0.05200338363647461s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [3, 3, 3]. Execution Time: 0.05608177185058594s Agents have converged to Goal 3 after 13 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [4, 4, 4]. Execution Time: 0.05299687385559082s Agents have converged to Goal 4 after 22 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08790397644042969s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.08594441413879395s Agents have converged to Goal 3 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 0]. Execution Time: 0.0939788818359375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13491296768188477s Agents have converged to Goal 2 after 38 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14000463485717773s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.15007495880126953s Agents have converged to Goal 4 after 25 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2]. Execution Time: 0.01399993896484375s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.012902498245239258s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [4, 4]. Execution Time: 0.013973236083984375s Agents have converged to Goal 4 after 11 iterations. Use EP: False\n",
      "Iteration 28: Agents have selected goals [2, 2, 2]. Execution Time: 0.02400350570678711s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [3, 3, 3]. Execution Time: 0.023978471755981445s Agents have converged to Goal 3 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 4]. Execution Time: 0.028934001922607422s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2]. Execution Time: 0.03306865692138672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 3]. Execution Time: 0.035909414291381836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 1, 1]. Execution Time: 0.03500056266784668s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 2, 1]. Execution Time: 0.04999995231628418s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 0, 1]. Execution Time: 0.048023223876953125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.04896283149719238s Agents have converged to Goal 4 after 25 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  12.0 %-------------------\n",
      "Iteration 24: Agents have selected goals [1, 1]. Execution Time: 0.025986671447753906s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [1, 1]. Execution Time: 0.03190755844116211s Agents have converged to Goal 1 after 12 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [3, 3]. Execution Time: 0.028997182846069336s Agents have converged to Goal 3 after 27 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1, 1]. Execution Time: 0.05809283256530762s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.05494284629821777s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 0]. Execution Time: 0.05090808868408203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08209943771362305s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08317279815673828s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.08910918235778809s Agents have converged to Goal 4 after 21 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1290431022644043s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 0]. Execution Time: 0.13698625564575195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.15200591087341309s Agents have converged to Goal 4 after 35 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1]. Execution Time: 0.013001203536987305s Agents have converged to Goal 1 after 24 iterations. Use EP: False\n",
      "Iteration 12: Agents have selected goals [1, 1]. Execution Time: 0.013998746871948242s Agents have converged to Goal 1 after 12 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [3, 3]. Execution Time: 0.015003442764282227s Agents have converged to Goal 3 after 27 iterations. Use EP: False\n",
      "Iteration 24: Agents have selected goals [1, 1, 1]. Execution Time: 0.02291131019592285s Agents have converged to Goal 1 after 24 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [1, 1, 1]. Execution Time: 0.02499842643737793s Agents have converged to Goal 1 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 3, 3]. Execution Time: 0.025046825408935547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03591799736022949s Agents have converged to Goal 1 after 24 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.04008841514587402s Agents have converged to Goal 1 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1]. Execution Time: 0.04700493812561035s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.044992685317993164s Agents have converged to Goal 1 after 26 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.05309176445007324s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4, 4]. Execution Time: 0.10500168800354004s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  14.000000000000002 %-------------------\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.02608633041381836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [3, 3]. Execution Time: 0.028905630111694336s Agents have converged to Goal 3 after 8 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.029001474380493164s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1]. Execution Time: 0.058998823165893555s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [3, 3, 3]. Execution Time: 0.05500054359436035s Agents have converged to Goal 3 after 17 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [4, 4, 4]. Execution Time: 0.05709052085876465s Agents have converged to Goal 4 after 36 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08509302139282227s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08609771728515625s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.09208965301513672s Agents have converged to Goal 4 after 35 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13098931312561035s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 45: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14307069778442383s Agents have converged to Goal 3 after 45 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4, 2]. Execution Time: 0.14999103546142578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.014057397842407227s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 11: Agents have selected goals [3, 3]. Execution Time: 0.013047933578491211s Agents have converged to Goal 3 after 11 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [4, 4]. Execution Time: 0.014000177383422852s Agents have converged to Goal 4 after 15 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1, 1]. Execution Time: 0.025907039642333984s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [3, 3, 3]. Execution Time: 0.024995803833007812s Agents have converged to Goal 3 after 20 iterations. Use EP: False\n",
      "Iteration 13: Agents have selected goals [4, 4, 4]. Execution Time: 0.025015830993652344s Agents have converged to Goal 4 after 13 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.037000179290771484s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03490495681762695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 4, 4]. Execution Time: 0.036995887756347656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1, 0]. Execution Time: 0.052080631256103516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1, 3]. Execution Time: 0.04909658432006836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.056000709533691406s Agents have converged to Goal 4 after 21 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  16.0 %-------------------\n",
      "Iteration 12: Agents have selected goals [2, 2]. Execution Time: 0.026000022888183594s Agents have converged to Goal 2 after 12 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.026906251907348633s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [1, 1]. Execution Time: 0.02901625633239746s Agents have converged to Goal 1 after 55 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [2, 2, 2]. Execution Time: 0.054113149642944336s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.053900718688964844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [3, 3, 3]. Execution Time: 0.054901123046875s Agents have converged to Goal 3 after 34 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08618783950805664s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09000277519226074s Agents have converged to Goal 3 after 32 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.08909821510314941s Agents have converged to Goal 3 after 33 iterations. Use EP: True\n",
      "Iteration 50: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.12909269332885742s Agents have converged to Goal 1 after 50 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 1]. Execution Time: 0.14101219177246094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 0, 0, 4]. Execution Time: 0.14690542221069336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 12: Agents have selected goals [2, 2]. Execution Time: 0.015001296997070312s Agents have converged to Goal 2 after 12 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.018114089965820312s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 43: Agents have selected goals [3, 3]. Execution Time: 0.014004230499267578s Agents have converged to Goal 3 after 43 iterations. Use EP: False\n",
      "Iteration 39: Agents have selected goals [2, 2, 2]. Execution Time: 0.025113821029663086s Agents have converged to Goal 2 after 39 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.029018878936767578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [3, 3, 3]. Execution Time: 0.024406909942626953s Agents have converged to Goal 3 after 36 iterations. Use EP: False\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03609442710876465s Agents have converged to Goal 1 after 48 iterations. Use EP: False\n",
      "Iteration 33: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0381159782409668s Agents have converged to Goal 3 after 33 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.034993886947631836s Agents have converged to Goal 3 after 36 iterations. Use EP: False\n",
      "Iteration 50: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.04912209510803223s Agents have converged to Goal 1 after 50 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 3, 2]. Execution Time: 0.05000019073486328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 2, 3, 2]. Execution Time: 0.05202817916870117s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  18.0 %-------------------\n",
      "Iteration 27: Agents have selected goals [2, 2]. Execution Time: 0.029008865356445312s Agents have converged to Goal 2 after 27 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.031002044677734375s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [3, 3]. Execution Time: 0.033007144927978516s Agents have converged to Goal 3 after 22 iterations. Use EP: True\n",
      "Iteration 96: Agents have selected goals [2, 2, 2]. Execution Time: 0.04999995231628418s Agents have converged to Goal 2 after 96 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [3, 3, 3]. Execution Time: 0.05993032455444336s Agents have converged to Goal 3 after 24 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1]. Execution Time: 0.05198407173156738s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 74: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08741521835327148s Agents have converged to Goal 1 after 74 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08898377418518066s Agents have converged to Goal 1 after 40 iterations. Use EP: True\n",
      "Iteration 51: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09307599067687988s Agents have converged to Goal 1 after 51 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13097357749938965s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13889217376708984s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1494147777557373s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [2, 2]. Execution Time: 0.012996196746826172s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.015987157821655273s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [3, 3]. Execution Time: 0.01450657844543457s Agents have converged to Goal 3 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.02399754524230957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [3, 3, 3]. Execution Time: 0.025012731552124023s Agents have converged to Goal 3 after 26 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [1, 1, 1]. Execution Time: 0.025066375732421875s Agents have converged to Goal 1 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0]. Execution Time: 0.037987709045410156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03490877151489258s Agents have converged to Goal 3 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 1]. Execution Time: 0.03899812698364258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 2, 2]. Execution Time: 0.04897880554199219s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1, 1]. Execution Time: 0.0519864559173584s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 1, 2, 1]. Execution Time: 0.05401468276977539s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  20.0 %-------------------\n",
      "Iteration 25: Agents have selected goals [1, 1]. Execution Time: 0.02799844741821289s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2]. Execution Time: 0.028905868530273438s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [4, 4]. Execution Time: 0.026914358139038086s Agents have converged to Goal 4 after 35 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [2, 2, 2]. Execution Time: 0.05427360534667969s Agents have converged to Goal 2 after 32 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [1, 1, 1]. Execution Time: 0.05398201942443848s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 4, 3]. Execution Time: 0.05099964141845703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08690690994262695s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0900123119354248s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09292912483215332s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 2]. Execution Time: 0.1369783878326416s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 50: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14201593399047852s Agents have converged to Goal 2 after 50 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.15190339088439941s Agents have converged to Goal 2 after 32 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1]. Execution Time: 0.014987468719482422s Agents have converged to Goal 1 after 25 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [2, 2]. Execution Time: 0.013999223709106445s Agents have converged to Goal 2 after 25 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [4, 4]. Execution Time: 0.04499936103820801s Agents have converged to Goal 4 after 35 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [2, 2, 2]. Execution Time: 0.023905515670776367s Agents have converged to Goal 2 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.02500176429748535s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [2, 2, 2]. Execution Time: 0.022992372512817383s Agents have converged to Goal 2 after 26 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03508925437927246s Agents have converged to Goal 2 after 40 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1]. Execution Time: 0.03792691230773926s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.038902997970581055s Agents have converged to Goal 2 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2, 0]. Execution Time: 0.05909466743469238s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 2, 3]. Execution Time: 0.049883365631103516s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05009150505065918s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  22.0 %-------------------\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.022986173629760742s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.029000043869018555s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.027100801467895508s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [1, 1, 1]. Execution Time: 0.0510716438293457s Agents have converged to Goal 1 after 42 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.05200600624084473s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.055902719497680664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0860128402709961s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08899950981140137s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09609127044677734s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.16747593879699707s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1371138095855713s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 3]. Execution Time: 0.15400004386901855s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [1, 1]. Execution Time: 0.01396489143371582s Agents have converged to Goal 1 after 31 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.012905597686767578s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.013998031616210938s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 41: Agents have selected goals [0, 0, 0]. Execution Time: 0.0370326042175293s Agents have converged to Goal 0 after 41 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.023999691009521484s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1, 1]. Execution Time: 0.02300286293029785s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03499913215637207s Agents have converged to Goal 0 after 37 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 1]. Execution Time: 0.03400421142578125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03608870506286621s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 1]. Execution Time: 0.047087669372558594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.04900026321411133s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.050756216049194336s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  24.0 %-------------------\n",
      "Iteration 59: Agents have selected goals [1, 1]. Execution Time: 0.02697610855102539s Agents have converged to Goal 1 after 59 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [0, 0]. Execution Time: 0.029092788696289062s Agents have converged to Goal 0 after 48 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [4, 4]. Execution Time: 0.026894092559814453s Agents have converged to Goal 4 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.051900386810302734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [3, 3, 3]. Execution Time: 0.05299949645996094s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [3, 3, 3]. Execution Time: 0.056995391845703125s Agents have converged to Goal 3 after 28 iterations. Use EP: True\n",
      "Iteration 66: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08900332450866699s Agents have converged to Goal 1 after 66 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.08809304237365723s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.11408138275146484s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 55: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.12891793251037598s Agents have converged to Goal 1 after 55 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14108872413635254s Agents have converged to Goal 3 after 29 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14799928665161133s Agents have converged to Goal 3 after 31 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.015000104904174805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [3, 3]. Execution Time: 0.015088319778442383s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [4, 4]. Execution Time: 0.014001131057739258s Agents have converged to Goal 4 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.024084091186523438s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0]. Execution Time: 0.02501702308654785s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [3, 3, 3]. Execution Time: 0.02708268165588379s Agents have converged to Goal 3 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.03600120544433594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03604698181152344s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.037999629974365234s Agents have converged to Goal 3 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1, 2]. Execution Time: 0.054999589920043945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.04798460006713867s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "Iteration 85: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.05387687683105469s Agents have converged to Goal 3 after 85 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  26.0 %-------------------\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.02499675750732422s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.03399515151977539s Agents have converged to Goal 3 after 12 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.025994300842285156s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.05494046211242676s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [3, 3, 3]. Execution Time: 0.05602073669433594s Agents have converged to Goal 3 after 34 iterations. Use EP: True\n",
      "Iteration 52: Agents have selected goals [4, 4, 4]. Execution Time: 0.05799698829650879s Agents have converged to Goal 4 after 52 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.08410978317260742s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08499836921691895s Agents have converged to Goal 1 after 23 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0919950008392334s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13235735893249512s Agents have converged to Goal 1 after 17 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13989782333374023s Agents have converged to Goal 1 after 16 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.15892553329467773s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.016022920608520508s Agents have converged to Goal 1 after 18 iterations. Use EP: False\n",
      "Iteration 12: Agents have selected goals [3, 3]. Execution Time: 0.014000415802001953s Agents have converged to Goal 3 after 12 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [3, 3]. Execution Time: 0.01699995994567871s Agents have converged to Goal 3 after 18 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.02809000015258789s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.025877952575683594s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.022999048233032227s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2]. Execution Time: 0.034967660903930664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 3, 0]. Execution Time: 0.03787112236022949s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.037000179290771484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1, 1]. Execution Time: 0.048912763595581055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 3, 0, 0]. Execution Time: 0.053910017013549805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 0, 3, 3]. Execution Time: 0.052994728088378906s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  28.000000000000004 %-------------------\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.025994300842285156s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [0, 0]. Execution Time: 0.024997472763061523s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0]. Execution Time: 0.030912160873413086s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1]. Execution Time: 0.05057716369628906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 97: Agents have selected goals [3, 3, 3]. Execution Time: 0.05301022529602051s Agents have converged to Goal 3 after 97 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0]. Execution Time: 0.05400872230529785s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08490705490112305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09087681770324707s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.09898161888122559s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13107562065124512s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14702606201171875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.1499016284942627s Agents have converged to Goal 0 after 44 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [1, 1]. Execution Time: 0.013002157211303711s Agents have converged to Goal 1 after 13 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [3, 3]. Execution Time: 0.013999462127685547s Agents have converged to Goal 3 after 40 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [0, 0]. Execution Time: 0.013974666595458984s Agents have converged to Goal 0 after 32 iterations. Use EP: False\n",
      "Iteration 67: Agents have selected goals [2, 2, 2]. Execution Time: 0.024999618530273438s Agents have converged to Goal 2 after 67 iterations. Use EP: False\n",
      "Iteration 42: Agents have selected goals [3, 3, 3]. Execution Time: 0.02800130844116211s Agents have converged to Goal 3 after 42 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [0, 0, 0]. Execution Time: 0.02601146697998047s Agents have converged to Goal 0 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2]. Execution Time: 0.03600001335144043s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0370335578918457s Agents have converged to Goal 0 after 41 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.03699755668640137s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 0, 1]. Execution Time: 0.05000615119934082s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 3, 2]. Execution Time: 0.05109977722167969s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3, 0]. Execution Time: 0.050092220306396484s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  30.0 %-------------------\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.02410292625427246s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.03499865531921387s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [3, 3]. Execution Time: 0.03500103950500488s Agents have converged to Goal 3 after 8 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.0509030818939209s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1]. Execution Time: 0.06000518798828125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [1, 1, 1]. Execution Time: 0.05508923530578613s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.08307719230651855s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 2]. Execution Time: 0.0900874137878418s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09390377998352051s Agents have converged to Goal 3 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 1]. Execution Time: 0.13210296630859375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 69: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14104676246643066s Agents have converged to Goal 3 after 69 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 0]. Execution Time: 0.1560966968536377s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [2, 2]. Execution Time: 0.015004873275756836s Agents have converged to Goal 2 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1]. Execution Time: 0.014881134033203125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [3, 3]. Execution Time: 0.013952255249023438s Agents have converged to Goal 3 after 8 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.024871349334716797s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 75: Agents have selected goals [3, 3, 3]. Execution Time: 0.02411794662475586s Agents have converged to Goal 3 after 75 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [1, 1, 1]. Execution Time: 0.024996519088745117s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1]. Execution Time: 0.035002946853637695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 2]. Execution Time: 0.037000417709350586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.03708910942077637s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 1, 1]. Execution Time: 0.0489962100982666s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 1, 1, 3]. Execution Time: 0.05301356315612793s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.051973581314086914s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  32.0 %-------------------\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.029101133346557617s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 67: Agents have selected goals [2, 2]. Execution Time: 0.027073144912719727s Agents have converged to Goal 2 after 67 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [2, 2]. Execution Time: 0.03100109100341797s Agents have converged to Goal 2 after 25 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [0, 0, 0]. Execution Time: 0.05091142654418945s Agents have converged to Goal 0 after 29 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3, 3]. Execution Time: 0.0531160831451416s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 4]. Execution Time: 0.05408740043640137s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2]. Execution Time: 0.0819089412689209s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 33: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.08599972724914551s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0959174633026123s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.18994450569152832s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14611220359802246s Agents have converged to Goal 3 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 0]. Execution Time: 0.1510298252105713s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.017003774642944336s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.013041019439697266s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.014986753463745117s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [0, 0, 0]. Execution Time: 0.023997068405151367s Agents have converged to Goal 0 after 29 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [3, 3, 3]. Execution Time: 0.023094654083251953s Agents have converged to Goal 3 after 27 iterations. Use EP: False\n",
      "Iteration 39: Agents have selected goals [3, 3, 3]. Execution Time: 0.023987293243408203s Agents have converged to Goal 3 after 39 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2]. Execution Time: 0.03590798377990723s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 0, 3]. Execution Time: 0.04000067710876465s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 34: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03899741172790527s Agents have converged to Goal 3 after 34 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.04600071907043457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3, 3]. Execution Time: 0.05452537536621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.05109667778015137s Agents have converged to Goal 3 after 25 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  34.0 %-------------------\n",
      "Iteration 24: Agents have selected goals [0, 0]. Execution Time: 0.025980234146118164s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.02709174156188965s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1]. Execution Time: 0.02800464630126953s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 80: Agents have selected goals [2, 2, 2]. Execution Time: 0.0559995174407959s Agents have converged to Goal 2 after 80 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0]. Execution Time: 0.060996055603027344s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0, 0]. Execution Time: 0.053000450134277344s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0880885124206543s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09000015258789062s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 3]. Execution Time: 0.11300182342529297s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13599944114685059s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 3]. Execution Time: 0.14300036430358887s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14698553085327148s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.01708984375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.014905214309692383s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0]. Execution Time: 0.0140533447265625s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 70: Agents have selected goals [2, 2, 2]. Execution Time: 0.025002717971801758s Agents have converged to Goal 2 after 70 iterations. Use EP: False\n",
      "Iteration 72: Agents have selected goals [0, 0, 0]. Execution Time: 0.025025129318237305s Agents have converged to Goal 0 after 72 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [0, 0, 0]. Execution Time: 0.02391338348388672s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.03688478469848633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2]. Execution Time: 0.036002159118652344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0370173454284668s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 1, 0]. Execution Time: 0.04711031913757324s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.04908871650695801s Agents have converged to Goal 0 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0, 0]. Execution Time: 0.05016136169433594s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  36.0 %-------------------\n",
      "Iteration 77: Agents have selected goals [2, 2]. Execution Time: 0.027996540069580078s Agents have converged to Goal 2 after 77 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [3, 3]. Execution Time: 0.02509021759033203s Agents have converged to Goal 3 after 21 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2]. Execution Time: 0.029103517532348633s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 2]. Execution Time: 0.05409741401672363s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.057088613510131836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0]. Execution Time: 0.05490422248840332s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2]. Execution Time: 0.08509945869445801s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 39: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08699679374694824s Agents have converged to Goal 2 after 39 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0960226058959961s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.18890690803527832s Agents have converged to Goal 0 after 41 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.1410970687866211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14600014686584473s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 74: Agents have selected goals [1, 1]. Execution Time: 0.01400136947631836s Agents have converged to Goal 1 after 74 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.014000177383422852s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.013911724090576172s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.04800248146057129s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0]. Execution Time: 0.026117324829101562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.024524211883544922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03591775894165039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.042034149169921875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.03700900077819824s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.048879384994506836s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.05401015281677246s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2, 0]. Execution Time: 0.05191230773925781s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  38.0 %-------------------\n",
      "Iteration 63: Agents have selected goals [1, 1]. Execution Time: 0.028983116149902344s Agents have converged to Goal 1 after 63 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [3, 3]. Execution Time: 0.030108213424682617s Agents have converged to Goal 3 after 18 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.031001806259155273s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [2, 2, 2]. Execution Time: 0.052104949951171875s Agents have converged to Goal 2 after 35 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 1]. Execution Time: 0.05396604537963867s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 4]. Execution Time: 0.0570831298828125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 64: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0879971981048584s Agents have converged to Goal 2 after 64 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.08891654014587402s Agents have converged to Goal 3 after 28 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09219598770141602s Agents have converged to Goal 3 after 27 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13497018814086914s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 2]. Execution Time: 0.14226961135864258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.15692949295043945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [2, 2]. Execution Time: 0.014002561569213867s Agents have converged to Goal 2 after 31 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [3, 3]. Execution Time: 0.016051292419433594s Agents have converged to Goal 3 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3]. Execution Time: 0.014096498489379883s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [2, 2, 2]. Execution Time: 0.027092933654785156s Agents have converged to Goal 2 after 37 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.02498173713684082s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 4]. Execution Time: 0.023000001907348633s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.034905433654785156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.035050153732299805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 3]. Execution Time: 0.03587603569030762s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.04789614677429199s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 3, 0, 3]. Execution Time: 0.05094146728515625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 4, 4, 0, 4]. Execution Time: 0.05600166320800781s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  40.0 %-------------------\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.0269930362701416s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [3, 3]. Execution Time: 0.03100275993347168s Agents have converged to Goal 3 after 14 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.026085615158081055s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0, 0]. Execution Time: 0.055999755859375s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.05401253700256348s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 25: Agents have selected goals [3, 3, 3]. Execution Time: 0.05688929557800293s Agents have converged to Goal 3 after 25 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.08409357070922852s Agents have converged to Goal 0 after 26 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09100055694580078s Agents have converged to Goal 3 after 19 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09412264823913574s Agents have converged to Goal 3 after 22 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13410258293151855s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.13807439804077148s Agents have converged to Goal 3 after 22 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 1]. Execution Time: 0.1512439250946045s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.014913320541381836s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [3, 3]. Execution Time: 0.014099836349487305s Agents have converged to Goal 3 after 14 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [0, 0]. Execution Time: 0.014002084732055664s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [0, 0, 0]. Execution Time: 0.027120113372802734s Agents have converged to Goal 0 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 2, 3]. Execution Time: 0.023999929428100586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [4, 4, 4]. Execution Time: 0.02500009536743164s Agents have converged to Goal 4 after 23 iterations. Use EP: False\n",
      "Iteration 60: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03800058364868164s Agents have converged to Goal 2 after 60 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2]. Execution Time: 0.03500080108642578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03700828552246094s Agents have converged to Goal 3 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 2, 1]. Execution Time: 0.04798603057861328s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.0489957332611084s Agents have converged to Goal 3 after 22 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.05300116539001465s Agents have converged to Goal 3 after 22 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  42.0 %-------------------\n",
      "Iteration 13: Agents have selected goals [1, 1]. Execution Time: 0.029003620147705078s Agents have converged to Goal 1 after 13 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [3, 3]. Execution Time: 0.02898430824279785s Agents have converged to Goal 3 after 14 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3]. Execution Time: 0.02809309959411621s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0, 0]. Execution Time: 0.05399274826049805s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [3, 3, 3]. Execution Time: 0.05508255958557129s Agents have converged to Goal 3 after 20 iterations. Use EP: True\n",
      "Iteration 45: Agents have selected goals [2, 2, 2]. Execution Time: 0.05553388595581055s Agents have converged to Goal 2 after 45 iterations. Use EP: True\n",
      "Iteration 25: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0838475227355957s Agents have converged to Goal 1 after 25 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 2]. Execution Time: 0.09096097946166992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09200263023376465s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 2]. Execution Time: 0.12990379333496094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.1409015655517578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 37: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.15901827812194824s Agents have converged to Goal 0 after 37 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.016005277633666992s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [3, 3]. Execution Time: 0.016906261444091797s Agents have converged to Goal 3 after 14 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [3, 3]. Execution Time: 0.016068458557128906s Agents have converged to Goal 3 after 20 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [0, 0, 0]. Execution Time: 0.025101661682128906s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [3, 3, 3]. Execution Time: 0.02504563331604004s Agents have converged to Goal 3 after 21 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [2, 2, 2]. Execution Time: 0.025002241134643555s Agents have converged to Goal 2 after 32 iterations. Use EP: False\n",
      "Iteration 63: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03598523139953613s Agents have converged to Goal 0 after 63 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 2, 3, 2]. Execution Time: 0.03609490394592285s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.049012184143066406s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 1, 1]. Execution Time: 0.05045628547668457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0, 0]. Execution Time: 0.055999040603637695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 4, 4, 3]. Execution Time: 0.05400490760803223s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  44.0 %-------------------\n",
      "Iteration 24: Agents have selected goals [1, 1]. Execution Time: 0.025907039642333984s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.02708745002746582s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [4, 4]. Execution Time: 0.029001951217651367s Agents have converged to Goal 4 after 30 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2, 2]. Execution Time: 0.06700325012207031s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 2, 1]. Execution Time: 0.06599974632263184s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.054096221923828125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08909344673156738s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.08990788459777832s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 70: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09401869773864746s Agents have converged to Goal 0 after 70 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0, 0]. Execution Time: 0.13798904418945312s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 1, 1]. Execution Time: 0.13810420036315918s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 1, 3]. Execution Time: 0.15990066528320312s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.01400303840637207s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [2, 2]. Execution Time: 0.013890743255615234s Agents have converged to Goal 2 after 20 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [4, 4]. Execution Time: 0.01599907875061035s Agents have converged to Goal 4 after 30 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [2, 2, 2]. Execution Time: 0.02411484718322754s Agents have converged to Goal 2 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 3, 1]. Execution Time: 0.024884700775146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 4, 4]. Execution Time: 0.025983572006225586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2]. Execution Time: 0.0429987907409668s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 1]. Execution Time: 0.038001298904418945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4, 2, 2]. Execution Time: 0.037992000579833984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 2]. Execution Time: 0.05091404914855957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 1, 1, 1]. Execution Time: 0.05207943916320801s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 4, 4]. Execution Time: 0.05209851264953613s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  46.0 %-------------------\n",
      "Iteration 44: Agents have selected goals [1, 1]. Execution Time: 0.028099536895751953s Agents have converged to Goal 1 after 44 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.026999235153198242s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.02789592742919922s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [2, 2, 2]. Execution Time: 0.05599641799926758s Agents have converged to Goal 2 after 48 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2, 2]. Execution Time: 0.060994863510131836s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [1, 1, 1]. Execution Time: 0.052999258041381836s Agents have converged to Goal 1 after 49 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09088635444641113s Agents have converged to Goal 2 after 29 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09190130233764648s Agents have converged to Goal 2 after 39 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09400224685668945s Agents have converged to Goal 0 after 37 iterations. Use EP: True\n",
      "Iteration 46: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13500237464904785s Agents have converged to Goal 2 after 46 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.15199899673461914s Agents have converged to Goal 2 after 29 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.15100383758544922s Agents have converged to Goal 2 after 19 iterations. Use EP: True\n",
      "Iteration 44: Agents have selected goals [1, 1]. Execution Time: 0.015906810760498047s Agents have converged to Goal 1 after 44 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3]. Execution Time: 0.014899253845214844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.014999866485595703s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.026003122329711914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [2, 2, 2]. Execution Time: 0.025003671646118164s Agents have converged to Goal 2 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 3]. Execution Time: 0.025003671646118164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03590726852416992s Agents have converged to Goal 2 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 1, 3, 3]. Execution Time: 0.0400233268737793s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 0, 3]. Execution Time: 0.035912513732910156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 2, 0]. Execution Time: 0.048001766204833984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 0, 0, 3]. Execution Time: 0.05309891700744629s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2, 1]. Execution Time: 0.05199933052062988s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  48.0 %-------------------\n",
      "Iteration 53: Agents have selected goals [0, 0]. Execution Time: 0.02899932861328125s Agents have converged to Goal 0 after 53 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [2, 2]. Execution Time: 0.026983261108398438s Agents have converged to Goal 2 after 11 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.028088092803955078s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [2, 2, 2]. Execution Time: 0.054012298583984375s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.05300188064575195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.05703592300415039s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08490753173828125s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.11288261413574219s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.09299087524414062s Agents have converged to Goal 4 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1360151767730713s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.14208292961120605s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.157088041305542s Agents have converged to Goal 4 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.015012502670288086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 12: Agents have selected goals [2, 2]. Execution Time: 0.015996932983398438s Agents have converged to Goal 2 after 12 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [1, 1]. Execution Time: 0.013907194137573242s Agents have converged to Goal 1 after 17 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [2, 2, 2]. Execution Time: 0.039010047912597656s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [3, 3, 3]. Execution Time: 0.029032468795776367s Agents have converged to Goal 3 after 21 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [4, 4, 4]. Execution Time: 0.02502751350402832s Agents have converged to Goal 4 after 37 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2]. Execution Time: 0.03500223159790039s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 1]. Execution Time: 0.044998884201049805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.03789377212524414s Agents have converged to Goal 4 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2, 2]. Execution Time: 0.05300021171569824s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 2, 3, 3]. Execution Time: 0.05190443992614746s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.05208635330200195s Agents have converged to Goal 4 after 21 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  50.0 %-------------------\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.02901148796081543s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [3, 3]. Execution Time: 0.027014970779418945s Agents have converged to Goal 3 after 24 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1]. Execution Time: 0.0270998477935791s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0, 0]. Execution Time: 0.059998273849487305s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [3, 3, 3]. Execution Time: 0.05909395217895508s Agents have converged to Goal 3 after 24 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [0, 0, 0]. Execution Time: 0.056001901626586914s Agents have converged to Goal 0 after 18 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.08899664878845215s Agents have converged to Goal 0 after 22 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09115886688232422s Agents have converged to Goal 3 after 38 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09691262245178223s Agents have converged to Goal 3 after 53 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14899444580078125s Agents have converged to Goal 0 after 23 iterations. Use EP: True\n",
      "Iteration 61: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14189982414245605s Agents have converged to Goal 3 after 61 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 3]. Execution Time: 0.15609169006347656s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.015002727508544922s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 24: Agents have selected goals [3, 3]. Execution Time: 0.014999866485595703s Agents have converged to Goal 3 after 24 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [0, 0]. Execution Time: 0.01600027084350586s Agents have converged to Goal 0 after 11 iterations. Use EP: False\n",
      "Iteration 26: Agents have selected goals [0, 0, 0]. Execution Time: 0.027896881103515625s Agents have converged to Goal 0 after 26 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2]. Execution Time: 0.02588963508605957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 4, 4]. Execution Time: 0.027088403701782227s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.03697848320007324s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2]. Execution Time: 0.03690648078918457s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 51: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.07700085639953613s Agents have converged to Goal 3 after 51 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 0, 2]. Execution Time: 0.05610060691833496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 55: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.051889657974243164s Agents have converged to Goal 3 after 55 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 1, 4]. Execution Time: 0.051099300384521484s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  52.0 %-------------------\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.033089399337768555s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.02988290786743164s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 8: Agents have selected goals [1, 1]. Execution Time: 0.03303384780883789s Agents have converged to Goal 1 after 8 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.05599069595336914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 9: Agents have selected goals [1, 1, 1]. Execution Time: 0.05802297592163086s Agents have converged to Goal 1 after 9 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1, 1]. Execution Time: 0.05707240104675293s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09110760688781738s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 68: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09800243377685547s Agents have converged to Goal 1 after 68 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09600448608398438s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13283777236938477s Agents have converged to Goal 1 after 49 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.142106294631958s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.15200304985046387s Agents have converged to Goal 0 after 29 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.015008687973022461s Agents have converged to Goal 1 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.015006542205810547s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 8: Agents have selected goals [1, 1]. Execution Time: 0.014092445373535156s Agents have converged to Goal 1 after 8 iterations. Use EP: False\n",
      "Iteration 52: Agents have selected goals [0, 0, 0]. Execution Time: 0.02401423454284668s Agents have converged to Goal 0 after 52 iterations. Use EP: False\n",
      "Iteration 81: Agents have selected goals [0, 0, 0]. Execution Time: 0.028998374938964844s Agents have converged to Goal 0 after 81 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 4, 1]. Execution Time: 0.023996829986572266s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.038904428482055664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.03899979591369629s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.039000749588012695s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 1]. Execution Time: 0.052909135818481445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0, 1]. Execution Time: 0.05808711051940918s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 0, 0]. Execution Time: 0.05299806594848633s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  54.0 %-------------------\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.02793717384338379s Agents have converged to Goal 0 after 28 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [3, 3]. Execution Time: 0.03499865531921387s Agents have converged to Goal 3 after 38 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.03700423240661621s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1]. Execution Time: 0.06999540328979492s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 53: Agents have selected goals [3, 3, 3]. Execution Time: 0.05400347709655762s Agents have converged to Goal 3 after 53 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [3, 3, 3]. Execution Time: 0.05600237846374512s Agents have converged to Goal 3 after 36 iterations. Use EP: True\n",
      "Iteration 71: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.08299851417541504s Agents have converged to Goal 1 after 71 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0900883674621582s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 69: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09800314903259277s Agents have converged to Goal 1 after 69 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13592743873596191s Agents have converged to Goal 0 after 35 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14099526405334473s Agents have converged to Goal 2 after 41 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1614081859588623s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [0, 0]. Execution Time: 0.012997627258300781s Agents have converged to Goal 0 after 28 iterations. Use EP: False\n",
      "Iteration 39: Agents have selected goals [3, 3]. Execution Time: 0.02308201789855957s Agents have converged to Goal 3 after 39 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.01499795913696289s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [0, 0, 0]. Execution Time: 0.025999784469604492s Agents have converged to Goal 0 after 32 iterations. Use EP: False\n",
      "Iteration 52: Agents have selected goals [3, 3, 3]. Execution Time: 0.027997732162475586s Agents have converged to Goal 3 after 52 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [3, 3, 3]. Execution Time: 0.026012897491455078s Agents have converged to Goal 3 after 35 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.034001827239990234s Agents have converged to Goal 1 after 40 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03498077392578125s Agents have converged to Goal 0 after 37 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 0]. Execution Time: 0.04399991035461426s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 39: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.0540006160736084s Agents have converged to Goal 0 after 39 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1, 0]. Execution Time: 0.05611062049865723s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 35: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.050898075103759766s Agents have converged to Goal 1 after 35 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  56.00000000000001 %-------------------\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.026911020278930664s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [3, 3]. Execution Time: 0.02709054946899414s Agents have converged to Goal 3 after 19 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3]. Execution Time: 0.0280914306640625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1]. Execution Time: 0.05510663986206055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [2, 2, 2]. Execution Time: 0.06101727485656738s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.05900263786315918s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.093902587890625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09002447128295898s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09399986267089844s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 0]. Execution Time: 0.19186949729919434s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.161088228225708s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 3]. Execution Time: 0.1594533920288086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.0149993896484375s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [3, 3]. Execution Time: 0.017007112503051758s Agents have converged to Goal 3 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4]. Execution Time: 0.015077590942382812s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [2, 2, 2]. Execution Time: 0.027115583419799805s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.023997783660888672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [2, 2, 2]. Execution Time: 0.027001142501831055s Agents have converged to Goal 2 after 17 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2]. Execution Time: 0.04000210762023926s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.036092519760131836s Agents have converged to Goal 2 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4]. Execution Time: 0.03800010681152344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05198478698730469s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2, 2]. Execution Time: 0.05008125305175781s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 2, 3]. Execution Time: 0.05598878860473633s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  57.99999999999999 %-------------------\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.02700042724609375s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.029033184051513672s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [4, 4]. Execution Time: 0.027001619338989258s Agents have converged to Goal 4 after 18 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.06399965286254883s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [0, 0, 0]. Execution Time: 0.06508469581604004s Agents have converged to Goal 0 after 19 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [4, 4, 4]. Execution Time: 0.05790567398071289s Agents have converged to Goal 4 after 28 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09200143814086914s Agents have converged to Goal 0 after 20 iterations. Use EP: True\n",
      "Iteration 51: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09098982810974121s Agents have converged to Goal 0 after 51 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.09488177299499512s Agents have converged to Goal 4 after 33 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.1359996795654297s Agents have converged to Goal 0 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14012360572814941s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.1541130542755127s Agents have converged to Goal 4 after 28 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.013999223709106445s Agents have converged to Goal 0 after 16 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.015926599502563477s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [4, 4]. Execution Time: 0.01791238784790039s Agents have converged to Goal 4 after 18 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.023914575576782227s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [0, 0, 0]. Execution Time: 0.026000499725341797s Agents have converged to Goal 0 after 20 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [4, 4, 4]. Execution Time: 0.04800081253051758s Agents have converged to Goal 4 after 27 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03599953651428223s Agents have converged to Goal 0 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 3, 3, 0]. Execution Time: 0.035994768142700195s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.036016225814819336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2, 2]. Execution Time: 0.05490756034851074s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 0, 1]. Execution Time: 0.049027204513549805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 3, 0, 3]. Execution Time: 0.05390667915344238s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  60.0 %-------------------\n",
      "Iteration 28: Agents have selected goals [2, 2]. Execution Time: 0.024904489517211914s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.028903722763061523s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [4, 4]. Execution Time: 0.029018402099609375s Agents have converged to Goal 4 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.05511069297790527s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.05700111389160156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [2, 2, 2]. Execution Time: 0.06299901008605957s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08699989318847656s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0870969295501709s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09801745414733887s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13900256156921387s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14608526229858398s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.16608595848083496s Agents have converged to Goal 2 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.014907598495483398s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [2, 2]. Execution Time: 0.014124393463134766s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [4, 4]. Execution Time: 0.01491403579711914s Agents have converged to Goal 4 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.024091005325317383s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.026988506317138672s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 1, 1]. Execution Time: 0.024000167846679688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.0370023250579834s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2]. Execution Time: 0.03598618507385254s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2]. Execution Time: 0.03691220283508301s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 0, 2, 2]. Execution Time: 0.05498647689819336s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 1, 1]. Execution Time: 0.05600881576538086s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 4, 3, 4]. Execution Time: 0.0540006160736084s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  62.0 %-------------------\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.025957822799682617s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.026624441146850586s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [4, 4]. Execution Time: 0.031017303466796875s Agents have converged to Goal 4 after 22 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [1, 1, 1]. Execution Time: 0.0579221248626709s Agents have converged to Goal 1 after 37 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [0, 0, 0]. Execution Time: 0.055002689361572266s Agents have converged to Goal 0 after 35 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [4, 4, 4]. Execution Time: 0.06104087829589844s Agents have converged to Goal 4 after 28 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.09400033950805664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08900237083435059s Agents have converged to Goal 2 after 36 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [4, 4, 4, 4]. Execution Time: 0.10001850128173828s Agents have converged to Goal 4 after 22 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13700294494628906s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 35: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14201045036315918s Agents have converged to Goal 0 after 35 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [4, 4, 4, 4, 4]. Execution Time: 0.15490436553955078s Agents have converged to Goal 4 after 21 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1]. Execution Time: 0.01800227165222168s Agents have converged to Goal 1 after 26 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.015915393829345703s Agents have converged to Goal 2 after 30 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [4, 4]. Execution Time: 0.014986991882324219s Agents have converged to Goal 4 after 23 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [1, 1, 1]. Execution Time: 0.023905515670776367s Agents have converged to Goal 1 after 37 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [0, 0, 0]. Execution Time: 0.02288675308227539s Agents have converged to Goal 0 after 35 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 1]. Execution Time: 0.03399801254272461s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03807854652404785s Agents have converged to Goal 2 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 3, 2, 3]. Execution Time: 0.03706550598144531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 2]. Execution Time: 0.039006710052490234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0, 2]. Execution Time: 0.050998687744140625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0, 0]. Execution Time: 0.05289626121520996s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 2, 4]. Execution Time: 0.05299687385559082s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  64.0 %-------------------\n",
      "Iteration 89: Agents have selected goals [2, 2]. Execution Time: 0.0270388126373291s Agents have converged to Goal 2 after 89 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.03608250617980957s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0]. Execution Time: 0.03300023078918457s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.05487942695617676s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1]. Execution Time: 0.059004783630371094s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 3]. Execution Time: 0.058890581130981445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09998655319213867s Agents have converged to Goal 0 after 40 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 3]. Execution Time: 0.08908486366271973s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 4, 4]. Execution Time: 0.09389925003051758s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13303017616271973s Agents have converged to Goal 0 after 40 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.1439821720123291s Agents have converged to Goal 0 after 38 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.1569972038269043s Agents have converged to Goal 0 after 33 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [0, 0]. Execution Time: 0.014999866485595703s Agents have converged to Goal 0 after 21 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.014998197555541992s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [0, 0]. Execution Time: 0.014979362487792969s Agents have converged to Goal 0 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.023912668228149414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 21: Agents have selected goals [1, 1, 1]. Execution Time: 0.02590799331665039s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [0, 0, 0]. Execution Time: 0.02407693862915039s Agents have converged to Goal 0 after 31 iterations. Use EP: False\n",
      "Iteration 37: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03600144386291504s Agents have converged to Goal 0 after 37 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03709673881530762s Agents have converged to Goal 0 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 0, 0, 4]. Execution Time: 0.03699636459350586s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 0]. Execution Time: 0.058087825775146484s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 1, 0]. Execution Time: 0.05290699005126953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 1, 4, 4]. Execution Time: 0.07800030708312988s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  66.0 %-------------------\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.028003454208374023s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.029999256134033203s Agents have converged to Goal 1 after 10 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [1, 1]. Execution Time: 0.027999401092529297s Agents have converged to Goal 1 after 33 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1, 1]. Execution Time: 0.0650022029876709s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [1, 1, 1]. Execution Time: 0.054071903228759766s Agents have converged to Goal 1 after 32 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 3]. Execution Time: 0.055891990661621094s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.0889585018157959s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09291338920593262s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09382247924804688s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 38: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13399195671081543s Agents have converged to Goal 1 after 38 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.14400196075439453s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 3]. Execution Time: 0.1580033302307129s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.014004945755004883s Agents have converged to Goal 1 after 18 iterations. Use EP: False\n",
      "Iteration 10: Agents have selected goals [1, 1]. Execution Time: 0.014991521835327148s Agents have converged to Goal 1 after 10 iterations. Use EP: False\n",
      "Iteration 26: Agents have selected goals [1, 1]. Execution Time: 0.013909339904785156s Agents have converged to Goal 1 after 26 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [1, 1, 1]. Execution Time: 0.032100677490234375s Agents have converged to Goal 1 after 18 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.026086807250976562s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1, 1]. Execution Time: 0.024915695190429688s Agents have converged to Goal 1 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1]. Execution Time: 0.03599691390991211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03699994087219238s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03597068786621094s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 0, 1, 0]. Execution Time: 0.04788684844970703s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0540928840637207s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.05501723289489746s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  68.0 %-------------------\n",
      "Iteration 17: Agents have selected goals [0, 0]. Execution Time: 0.028086423873901367s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [2, 2]. Execution Time: 0.027013778686523438s Agents have converged to Goal 2 after 31 iterations. Use EP: True\n",
      "Iteration 10: Agents have selected goals [2, 2]. Execution Time: 0.026906490325927734s Agents have converged to Goal 2 after 10 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [2, 2, 2]. Execution Time: 0.06200003623962402s Agents have converged to Goal 2 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 2, 2]. Execution Time: 0.05409574508666992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2]. Execution Time: 0.056030988693237305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09909296035766602s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 85: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09141302108764648s Agents have converged to Goal 0 after 85 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4]. Execution Time: 0.09298944473266602s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 2, 2]. Execution Time: 0.13699722290039062s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 44: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14490914344787598s Agents have converged to Goal 3 after 44 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4, 2]. Execution Time: 0.15508604049682617s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.015004158020019531s Agents have converged to Goal 2 after 30 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.015956640243530273s Agents have converged to Goal 2 after 30 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [3, 3]. Execution Time: 0.0149993896484375s Agents have converged to Goal 3 after 16 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [2, 2, 2]. Execution Time: 0.025049448013305664s Agents have converged to Goal 2 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 0]. Execution Time: 0.028995990753173828s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 50: Agents have selected goals [0, 0, 0]. Execution Time: 0.02700185775756836s Agents have converged to Goal 0 after 50 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 2]. Execution Time: 0.03600025177001953s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03497672080993652s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4]. Execution Time: 0.03605937957763672s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 2, 1, 0, 2]. Execution Time: 0.05100202560424805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 3, 3, 3]. Execution Time: 0.05091094970703125s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 4, 4, 2]. Execution Time: 0.054097890853881836s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  70.0 %-------------------\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.02807784080505371s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [2, 2]. Execution Time: 0.02809429168701172s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 58: Agents have selected goals [1, 1]. Execution Time: 0.031000614166259766s Agents have converged to Goal 1 after 58 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.11900115013122559s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [2, 2, 2]. Execution Time: 0.060997962951660156s Agents have converged to Goal 2 after 26 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.05800056457519531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09200000762939453s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0888979434967041s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 64: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.1020047664642334s Agents have converged to Goal 3 after 64 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14089274406433105s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 67: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.1439979076385498s Agents have converged to Goal 3 after 67 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.15989279747009277s Agents have converged to Goal 3 after 43 iterations. Use EP: True\n",
      "Iteration 40: Agents have selected goals [2, 2]. Execution Time: 0.014977693557739258s Agents have converged to Goal 2 after 40 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2]. Execution Time: 0.015105247497558594s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.014079809188842773s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.028995037078857422s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 54: Agents have selected goals [2, 2, 2]. Execution Time: 0.025000333786010742s Agents have converged to Goal 2 after 54 iterations. Use EP: False\n",
      "Iteration 79: Agents have selected goals [2, 2, 2]. Execution Time: 0.02509164810180664s Agents have converged to Goal 2 after 79 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 2]. Execution Time: 0.035013437271118164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 0, 3]. Execution Time: 0.03800010681152344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 62: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03908872604370117s Agents have converged to Goal 3 after 62 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1, 0, 2]. Execution Time: 0.049002647399902344s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 3, 2, 2]. Execution Time: 0.05207705497741699s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 2, 4, 2, 4]. Execution Time: 0.05291461944580078s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  72.0 %-------------------\n",
      "Iteration 14: Agents have selected goals [1, 1]. Execution Time: 0.03309988975524902s Agents have converged to Goal 1 after 14 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.029964208602905273s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.02899956703186035s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [1, 1, 1]. Execution Time: 0.06202960014343262s Agents have converged to Goal 1 after 21 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2]. Execution Time: 0.058014631271362305s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2]. Execution Time: 0.05799984931945801s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08898401260375977s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.10590219497680664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.1679975986480713s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14400053024291992s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14399456977844238s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.15795016288757324s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 13: Agents have selected goals [1, 1]. Execution Time: 0.01691126823425293s Agents have converged to Goal 1 after 13 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.015001773834228516s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.01589345932006836s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [1, 1, 1]. Execution Time: 0.028989791870117188s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [2, 2, 2]. Execution Time: 0.02801036834716797s Agents have converged to Goal 2 after 25 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [2, 2, 2]. Execution Time: 0.024999141693115234s Agents have converged to Goal 2 after 20 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.037015438079833984s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03800392150878906s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03808283805847168s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.0520024299621582s Agents have converged to Goal 2 after 25 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1, 2]. Execution Time: 0.0511014461517334s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 2, 2]. Execution Time: 0.058001041412353516s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  74.0 %-------------------\n",
      "Iteration 24: Agents have selected goals [2, 2]. Execution Time: 0.031000852584838867s Agents have converged to Goal 2 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 1]. Execution Time: 0.03309154510498047s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.029018878936767578s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 53: Agents have selected goals [0, 0, 0]. Execution Time: 0.0550537109375s Agents have converged to Goal 0 after 53 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 3, 0]. Execution Time: 0.054039955139160156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 17: Agents have selected goals [2, 2, 2]. Execution Time: 0.06300044059753418s Agents have converged to Goal 2 after 17 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09900093078613281s Agents have converged to Goal 0 after 39 iterations. Use EP: True\n",
      "Iteration 36: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0940847396850586s Agents have converged to Goal 3 after 36 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09208083152770996s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.15401172637939453s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.1443467140197754s Agents have converged to Goal 2 after 28 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.17199945449829102s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [2, 2]. Execution Time: 0.015002965927124023s Agents have converged to Goal 2 after 24 iterations. Use EP: False\n",
      "Iteration 64: Agents have selected goals [2, 2]. Execution Time: 0.014903545379638672s Agents have converged to Goal 2 after 64 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [0, 0]. Execution Time: 0.015003681182861328s Agents have converged to Goal 0 after 18 iterations. Use EP: False\n",
      "Iteration 63: Agents have selected goals [2, 2, 2]. Execution Time: 0.025089025497436523s Agents have converged to Goal 2 after 63 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2]. Execution Time: 0.026097774505615234s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.027001380920410156s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03799796104431152s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2]. Execution Time: 0.036002397537231445s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.10500335693359375s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2, 2]. Execution Time: 0.04991483688354492s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05409717559814453s Agents have converged to Goal 2 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 2, 0]. Execution Time: 0.052100181579589844s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  76.0 %-------------------\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.027001142501831055s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.028012514114379883s Agents have converged to Goal 0 after 15 iterations. Use EP: True\n",
      "Iteration 42: Agents have selected goals [1, 1]. Execution Time: 0.031047344207763672s Agents have converged to Goal 1 after 42 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0, 0]. Execution Time: 0.06001543998718262s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 76: Agents have selected goals [0, 0, 0]. Execution Time: 0.05900096893310547s Agents have converged to Goal 0 after 76 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4]. Execution Time: 0.0548861026763916s Agents have converged to Goal 4 after 100 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.08910250663757324s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 47: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.095001220703125s Agents have converged to Goal 0 after 47 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 4, 1]. Execution Time: 0.09899139404296875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13290166854858398s Agents have converged to Goal 0 after 29 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.14300227165222168s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 41: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.15900468826293945s Agents have converged to Goal 1 after 41 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.01590728759765625s Agents have converged to Goal 0 after 15 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [0, 0]. Execution Time: 0.01710057258605957s Agents have converged to Goal 0 after 15 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [2, 2]. Execution Time: 0.016983509063720703s Agents have converged to Goal 2 after 29 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [0, 0, 0]. Execution Time: 0.02700662612915039s Agents have converged to Goal 0 after 16 iterations. Use EP: False\n",
      "Iteration 43: Agents have selected goals [2, 2, 2]. Execution Time: 0.02699875831604004s Agents have converged to Goal 2 after 43 iterations. Use EP: False\n",
      "Iteration 64: Agents have selected goals [2, 2, 2]. Execution Time: 0.02588796615600586s Agents have converged to Goal 2 after 64 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03852128982543945s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 74: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0370020866394043s Agents have converged to Goal 2 after 74 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 3]. Execution Time: 0.03888511657714844s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 0, 0]. Execution Time: 0.050004005432128906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05502176284790039s Agents have converged to Goal 2 after 45 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 0, 2, 2]. Execution Time: 0.05902290344238281s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  78.0 %-------------------\n",
      "Iteration 30: Agents have selected goals [1, 1]. Execution Time: 0.02707386016845703s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.02608776092529297s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [4, 4]. Execution Time: 0.03491091728210449s Agents have converged to Goal 4 after 11 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.054094791412353516s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [3, 3, 3]. Execution Time: 0.056029319763183594s Agents have converged to Goal 3 after 23 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [4, 4, 3]. Execution Time: 0.05500006675720215s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09492778778076172s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.0930025577545166s Agents have converged to Goal 3 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 3]. Execution Time: 0.09598040580749512s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1, 2]. Execution Time: 0.14802098274230957s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 3, 3, 3]. Execution Time: 0.14704513549804688s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 4, 1, 1]. Execution Time: 0.15989184379577637s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.017014265060424805s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 23: Agents have selected goals [3, 3]. Execution Time: 0.01498723030090332s Agents have converged to Goal 3 after 23 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [4, 4]. Execution Time: 0.014014959335327148s Agents have converged to Goal 4 after 11 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [1, 1, 1]. Execution Time: 0.024919986724853516s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [3, 3, 3]. Execution Time: 0.02500009536743164s Agents have converged to Goal 3 after 23 iterations. Use EP: False\n",
      "Iteration 31: Agents have selected goals [4, 4, 4]. Execution Time: 0.025987625122070312s Agents have converged to Goal 4 after 31 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03999972343444824s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 0, 0]. Execution Time: 0.035085201263427734s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1]. Execution Time: 0.039002180099487305s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 0, 2]. Execution Time: 0.05207705497741699s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 1, 2, 2]. Execution Time: 0.04899740219116211s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 3, 1]. Execution Time: 0.06609296798706055s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  80.0 %-------------------\n",
      "Iteration 46: Agents have selected goals [1, 1]. Execution Time: 0.02910900115966797s Agents have converged to Goal 1 after 46 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.02698802947998047s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [0, 0]. Execution Time: 0.0340120792388916s Agents have converged to Goal 0 after 11 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.05299997329711914s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [0, 0, 0]. Execution Time: 0.05590248107910156s Agents have converged to Goal 0 after 29 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [0, 0, 0]. Execution Time: 0.056326866149902344s Agents have converged to Goal 0 after 14 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 0]. Execution Time: 0.08898401260375977s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09209609031677246s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 4]. Execution Time: 0.09007692337036133s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 1, 0]. Execution Time: 0.1329951286315918s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 19: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.14716434478759766s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1699075698852539s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [2, 2]. Execution Time: 0.013916015625s Agents have converged to Goal 2 after 30 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [1, 1]. Execution Time: 0.018001556396484375s Agents have converged to Goal 1 after 19 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [0, 0]. Execution Time: 0.0489954948425293s Agents have converged to Goal 0 after 14 iterations. Use EP: False\n",
      "Iteration 39: Agents have selected goals [2, 2, 2]. Execution Time: 0.027988910675048828s Agents have converged to Goal 2 after 39 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.02690601348876953s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [0, 0, 0]. Execution Time: 0.029997825622558594s Agents have converged to Goal 0 after 15 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 1, 2, 1]. Execution Time: 0.03568267822265625s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 0, 0, 3]. Execution Time: 0.04391169548034668s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 1, 1]. Execution Time: 0.03790569305419922s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 0, 0, 1, 0]. Execution Time: 0.04710698127746582s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 3, 0, 0, 3]. Execution Time: 0.05200052261352539s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 1, 3, 1, 1]. Execution Time: 0.05499696731567383s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  82.0 %-------------------\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.026999711990356445s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [0, 0]. Execution Time: 0.026913881301879883s Agents have converged to Goal 0 after 16 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 1]. Execution Time: 0.030907869338989258s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 24: Agents have selected goals [0, 0, 0]. Execution Time: 0.05191493034362793s Agents have converged to Goal 0 after 24 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [3, 2, 1]. Execution Time: 0.11800098419189453s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 1, 1]. Execution Time: 0.056912899017333984s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 90: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.1359086036682129s Agents have converged to Goal 0 after 90 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 1, 1]. Execution Time: 0.09309577941894531s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 30: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.11000442504882812s Agents have converged to Goal 2 after 30 iterations. Use EP: True\n",
      "Iteration 50: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13706040382385254s Agents have converged to Goal 2 after 50 iterations. Use EP: True\n",
      "Iteration 54: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.14510583877563477s Agents have converged to Goal 1 after 54 iterations. Use EP: True\n",
      "Iteration 39: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.24100208282470703s Agents have converged to Goal 2 after 39 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.015980958938598633s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0]. Execution Time: 0.015000343322753906s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [4, 4]. Execution Time: 0.01600050926208496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 1, 0]. Execution Time: 0.023088693618774414s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 2, 0]. Execution Time: 0.02509331703186035s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 46: Agents have selected goals [4, 4, 4]. Execution Time: 0.02811741828918457s Agents have converged to Goal 4 after 46 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 0, 0]. Execution Time: 0.04000091552734375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 0, 2, 1]. Execution Time: 0.03899741172790527s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 36: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0401155948638916s Agents have converged to Goal 2 after 36 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0, 1]. Execution Time: 0.05298972129821777s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 51: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.05299997329711914s Agents have converged to Goal 1 after 51 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 4, 3, 3, 3]. Execution Time: 0.05410051345825195s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  84.0 %-------------------\n",
      "Iteration 20: Agents have selected goals [2, 2]. Execution Time: 0.02691650390625s Agents have converged to Goal 2 after 20 iterations. Use EP: True\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.030095815658569336s Agents have converged to Goal 2 after 16 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.031003236770629883s Agents have converged to Goal 1 after 22 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.05399966239929199s Agents have converged to Goal 2 after 23 iterations. Use EP: True\n",
      "Iteration 32: Agents have selected goals [0, 0, 0]. Execution Time: 0.05499386787414551s Agents have converged to Goal 0 after 32 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3]. Execution Time: 0.05708646774291992s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 57: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0899050235748291s Agents have converged to Goal 2 after 57 iterations. Use EP: True\n",
      "Iteration 61: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09398674964904785s Agents have converged to Goal 0 after 61 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.09310102462768555s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 75: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13499879837036133s Agents have converged to Goal 2 after 75 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.15010666847229004s Agents have converged to Goal 0 after 37 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.16099953651428223s Agents have converged to Goal 0 after 34 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [0, 0]. Execution Time: 0.01500391960144043s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 16: Agents have selected goals [2, 2]. Execution Time: 0.021005630493164062s Agents have converged to Goal 2 after 16 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [1, 1]. Execution Time: 0.013896942138671875s Agents have converged to Goal 1 after 22 iterations. Use EP: False\n",
      "Iteration 23: Agents have selected goals [2, 2, 2]. Execution Time: 0.02799820899963379s Agents have converged to Goal 2 after 23 iterations. Use EP: False\n",
      "Iteration 32: Agents have selected goals [0, 0, 0]. Execution Time: 0.026109695434570312s Agents have converged to Goal 0 after 32 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [3, 3, 3]. Execution Time: 0.024989843368530273s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "Iteration 56: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.04600262641906738s Agents have converged to Goal 2 after 56 iterations. Use EP: False\n",
      "Iteration 60: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.036093950271606445s Agents have converged to Goal 0 after 60 iterations. Use EP: False\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.03709292411804199s Agents have converged to Goal 3 after 30 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 2, 2, 2, 0]. Execution Time: 0.04999709129333496s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 60: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.049929141998291016s Agents have converged to Goal 0 after 60 iterations. Use EP: False\n",
      "Iteration 40: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.05700325965881348s Agents have converged to Goal 0 after 40 iterations. Use EP: False\n",
      "-------------------\n",
      "Percentage Complete:  86.0 %-------------------\n",
      "Iteration 10: Agents have selected goals [2, 2]. Execution Time: 0.02499842643737793s Agents have converged to Goal 2 after 10 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.027091264724731445s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [3, 3]. Execution Time: 0.031893014907836914s Agents have converged to Goal 3 after 24 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [1, 1, 1]. Execution Time: 0.05699658393859863s Agents have converged to Goal 1 after 48 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1, 1]. Execution Time: 0.06400299072265625s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [3, 3, 3]. Execution Time: 0.05800318717956543s Agents have converged to Goal 3 after 43 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 0]. Execution Time: 0.08989214897155762s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 45: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09990239143371582s Agents have converged to Goal 2 after 45 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09900236129760742s Agents have converged to Goal 1 after 43 iterations. Use EP: True\n",
      "Iteration 33: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.14000153541564941s Agents have converged to Goal 2 after 33 iterations. Use EP: True\n",
      "Iteration 34: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.21900248527526855s Agents have converged to Goal 2 after 34 iterations. Use EP: True\n",
      "Iteration 65: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.15808892250061035s Agents have converged to Goal 1 after 65 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.014995574951171875s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.01799750328063965s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 16: Agents have selected goals [1, 1]. Execution Time: 0.014002561569213867s Agents have converged to Goal 1 after 16 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1, 1]. Execution Time: 0.027048826217651367s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [1, 1, 1]. Execution Time: 0.024946928024291992s Agents have converged to Goal 1 after 21 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 2]. Execution Time: 0.024912595748901367s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03799915313720703s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.12000131607055664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 32: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03489184379577637s Agents have converged to Goal 1 after 32 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 1, 2, 2, 2]. Execution Time: 0.08995580673217773s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 3, 3, 2, 2]. Execution Time: 0.05209994316101074s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [1, 3, 3, 1, 1]. Execution Time: 0.05399036407470703s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  88.0 %-------------------\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.029003381729125977s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.04299163818359375s Agents have converged to Goal 2 after 18 iterations. Use EP: True\n",
      "Iteration 9: Agents have selected goals [0, 0]. Execution Time: 0.034000396728515625s Agents have converged to Goal 0 after 9 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [2, 2, 2]. Execution Time: 0.05591869354248047s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [0, 0, 0]. Execution Time: 0.06591057777404785s Agents have converged to Goal 0 after 31 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.07199883460998535s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 51: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0879981517791748s Agents have converged to Goal 0 after 51 iterations. Use EP: True\n",
      "Iteration 48: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0910027027130127s Agents have converged to Goal 0 after 48 iterations. Use EP: True\n",
      "Iteration 17: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09800863265991211s Agents have converged to Goal 0 after 17 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.13991332054138184s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 49: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.14900970458984375s Agents have converged to Goal 0 after 49 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 2]. Execution Time: 0.1638932228088379s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [1, 1]. Execution Time: 0.01799941062927246s Agents have converged to Goal 1 after 28 iterations. Use EP: False\n",
      "Iteration 18: Agents have selected goals [2, 2]. Execution Time: 0.015996217727661133s Agents have converged to Goal 2 after 18 iterations. Use EP: False\n",
      "Iteration 10: Agents have selected goals [0, 0]. Execution Time: 0.015999317169189453s Agents have converged to Goal 0 after 10 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2]. Execution Time: 0.02496504783630371s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 36: Agents have selected goals [0, 0, 0]. Execution Time: 0.024088382720947266s Agents have converged to Goal 0 after 36 iterations. Use EP: False\n",
      "Iteration 17: Agents have selected goals [0, 0, 0]. Execution Time: 0.025008678436279297s Agents have converged to Goal 0 after 17 iterations. Use EP: False\n",
      "Iteration 50: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0381014347076416s Agents have converged to Goal 0 after 50 iterations. Use EP: False\n",
      "Iteration 45: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.03799891471862793s Agents have converged to Goal 0 after 45 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.04108023643493652s Agents have converged to Goal 0 after 19 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.050000667572021484s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 47: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.05790138244628906s Agents have converged to Goal 0 after 47 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 4, 2, 4, 2]. Execution Time: 0.056998252868652344s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  90.0 %-------------------\n",
      "Iteration 51: Agents have selected goals [0, 0]. Execution Time: 0.025096416473388672s Agents have converged to Goal 0 after 51 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [0, 0]. Execution Time: 0.028079748153686523s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.02909231185913086s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [0, 0, 0]. Execution Time: 0.05497860908508301s Agents have converged to Goal 0 after 43 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [0, 0, 0]. Execution Time: 0.0580134391784668s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 23: Agents have selected goals [4, 4, 4]. Execution Time: 0.06100058555603027s Agents have converged to Goal 4 after 23 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.09399867057800293s Agents have converged to Goal 0 after 43 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.08899998664855957s Agents have converged to Goal 0 after 27 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09299921989440918s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 43: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.13700485229492188s Agents have converged to Goal 0 after 43 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [0, 0, 0, 0, 1]. Execution Time: 0.14765381813049316s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 38: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.16189217567443848s Agents have converged to Goal 1 after 38 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [1, 1]. Execution Time: 0.018002033233642578s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [0, 0]. Execution Time: 0.015001535415649414s Agents have converged to Goal 0 after 27 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [1, 1]. Execution Time: 0.015151500701904297s Agents have converged to Goal 1 after 27 iterations. Use EP: False\n",
      "Iteration 43: Agents have selected goals [0, 0, 0]. Execution Time: 0.0239865779876709s Agents have converged to Goal 0 after 43 iterations. Use EP: False\n",
      "Iteration 27: Agents have selected goals [0, 0, 0]. Execution Time: 0.025995969772338867s Agents have converged to Goal 0 after 27 iterations. Use EP: False\n",
      "Iteration 25: Agents have selected goals [0, 0, 0]. Execution Time: 0.02501702308654785s Agents have converged to Goal 0 after 25 iterations. Use EP: False\n",
      "Iteration 43: Agents have selected goals [0, 0, 0, 0]. Execution Time: 0.0370173454284668s Agents have converged to Goal 0 after 43 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 3, 3]. Execution Time: 0.03810262680053711s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 31: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.03796267509460449s Agents have converged to Goal 1 after 31 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 0, 2, 1, 0]. Execution Time: 0.05002450942993164s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 27: Agents have selected goals [0, 0, 0, 0, 0]. Execution Time: 0.05821418762207031s Agents have converged to Goal 0 after 27 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [4, 1, 4, 1, 1]. Execution Time: 0.06299471855163574s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  92.0 %-------------------\n",
      "Iteration 7: Agents have selected goals [1, 1]. Execution Time: 0.02799820899963379s Agents have converged to Goal 1 after 7 iterations. Use EP: True\n",
      "Iteration 26: Agents have selected goals [1, 1]. Execution Time: 0.027995824813842773s Agents have converged to Goal 1 after 26 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4]. Execution Time: 0.02800130844116211s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [1, 1, 1]. Execution Time: 0.05599403381347656s Agents have converged to Goal 1 after 30 iterations. Use EP: True\n",
      "Iteration 63: Agents have selected goals [1, 1, 1]. Execution Time: 0.06799912452697754s Agents have converged to Goal 1 after 63 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [4, 4, 4]. Execution Time: 0.06099963188171387s Agents have converged to Goal 4 after 29 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.10688591003417969s Agents have converged to Goal 1 after 28 iterations. Use EP: True\n",
      "Iteration 31: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09309601783752441s Agents have converged to Goal 1 after 31 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [3, 3, 3, 3]. Execution Time: 0.19399285316467285s Agents have converged to Goal 3 after 27 iterations. Use EP: True\n",
      "Iteration 27: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13998031616210938s Agents have converged to Goal 1 after 27 iterations. Use EP: True\n",
      "Iteration 28: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.14309310913085938s Agents have converged to Goal 3 after 28 iterations. Use EP: True\n",
      "Iteration 30: Agents have selected goals [3, 3, 3, 3, 3]. Execution Time: 0.1510028839111328s Agents have converged to Goal 3 after 30 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2]. Execution Time: 0.01298832893371582s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1]. Execution Time: 0.015098094940185547s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [4, 4]. Execution Time: 0.0149993896484375s Agents have converged to Goal 4 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 0, 1]. Execution Time: 0.03900146484375s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 22: Agents have selected goals [3, 3, 3]. Execution Time: 0.02489614486694336s Agents have converged to Goal 3 after 22 iterations. Use EP: False\n",
      "Iteration 29: Agents have selected goals [4, 4, 4]. Execution Time: 0.02801370620727539s Agents have converged to Goal 4 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [0, 1, 0, 1]. Execution Time: 0.03992319107055664s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.034972429275512695s Agents have converged to Goal 1 after 29 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 2]. Execution Time: 0.03599858283996582s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 28: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.0500028133392334s Agents have converged to Goal 1 after 28 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 3, 2]. Execution Time: 0.06410551071166992s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 3, 2, 2, 3]. Execution Time: 0.05500078201293945s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  94.0 %-------------------\n",
      "Iteration 10: Agents have selected goals [2, 2]. Execution Time: 0.025884389877319336s Agents have converged to Goal 2 after 10 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.03000164031982422s Agents have converged to Goal 1 after 11 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1]. Execution Time: 0.030025482177734375s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 37: Agents have selected goals [2, 2, 2]. Execution Time: 0.07899999618530273s Agents have converged to Goal 2 after 37 iterations. Use EP: True\n",
      "Iteration 19: Agents have selected goals [1, 1, 1]. Execution Time: 0.05600094795227051s Agents have converged to Goal 1 after 19 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1]. Execution Time: 0.06508469581604004s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 41: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09387993812561035s Agents have converged to Goal 2 after 41 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.0930032730102539s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.09932374954223633s Agents have converged to Goal 1 after 20 iterations. Use EP: True\n",
      "Iteration 24: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.13699984550476074s Agents have converged to Goal 1 after 24 iterations. Use EP: True\n",
      "Iteration 29: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.1500842571258545s Agents have converged to Goal 1 after 29 iterations. Use EP: True\n",
      "Iteration 18: Agents have selected goals [1, 1, 1, 1, 1]. Execution Time: 0.16301894187927246s Agents have converged to Goal 1 after 18 iterations. Use EP: True\n",
      "Iteration 11: Agents have selected goals [2, 2]. Execution Time: 0.013906002044677734s Agents have converged to Goal 2 after 11 iterations. Use EP: False\n",
      "Iteration 11: Agents have selected goals [1, 1]. Execution Time: 0.01799631118774414s Agents have converged to Goal 1 after 11 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1]. Execution Time: 0.014998912811279297s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 35: Agents have selected goals [2, 2, 2]. Execution Time: 0.02710270881652832s Agents have converged to Goal 2 after 35 iterations. Use EP: False\n",
      "Iteration 24: Agents have selected goals [1, 1, 1]. Execution Time: 0.03110814094543457s Agents have converged to Goal 1 after 24 iterations. Use EP: False\n",
      "Iteration 20: Agents have selected goals [1, 1, 1]. Execution Time: 0.024913549423217773s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [1, 2, 2, 1]. Execution Time: 0.03701329231262207s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 20: Agents have selected goals [1, 1, 1, 1]. Execution Time: 0.038986921310424805s Agents have converged to Goal 1 after 20 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [3, 1, 1, 3]. Execution Time: 0.03800034523010254s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [2, 1, 1, 1, 2]. Execution Time: 0.057018280029296875s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 2, 2, 3, 3]. Execution Time: 0.13100194931030273s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [3, 4, 4, 4, 3]. Execution Time: 0.05891275405883789s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  96.0 %-------------------\n",
      "Iteration 34: Agents have selected goals [1, 1]. Execution Time: 0.0298922061920166s Agents have converged to Goal 1 after 34 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.026999950408935547s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 21: Agents have selected goals [4, 4]. Execution Time: 0.03600430488586426s Agents have converged to Goal 4 after 21 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2]. Execution Time: 0.05399775505065918s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 14: Agents have selected goals [2, 2, 2]. Execution Time: 0.05700397491455078s Agents have converged to Goal 2 after 14 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 3]. Execution Time: 0.05908679962158203s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.10209512710571289s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0951070785522461s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.09499597549438477s Agents have converged to Goal 2 after 22 iterations. Use EP: True\n",
      "Iteration 15: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.1419811248779297s Agents have converged to Goal 2 after 15 iterations. Use EP: True\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 3]. Execution Time: 0.1529982089996338s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 100: Agents have selected goals [0, 0, 3, 0, 3]. Execution Time: 0.16490888595581055s Agents did not converge to the same goal within the maximum iterations.\n",
      "Iteration 15: Agents have selected goals [2, 2]. Execution Time: 0.014995813369750977s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.014923810958862305s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2]. Execution Time: 0.01600337028503418s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2, 2]. Execution Time: 0.025088071823120117s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 14: Agents have selected goals [2, 2, 2]. Execution Time: 0.02599310874938965s Agents have converged to Goal 2 after 14 iterations. Use EP: False\n",
      "Iteration 15: Agents have selected goals [2, 2, 2]. Execution Time: 0.026088714599609375s Agents have converged to Goal 2 after 15 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.0440974235534668s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 21: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.03799891471862793s Agents have converged to Goal 2 after 21 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2]. Execution Time: 0.04101419448852539s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 19: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05091357231140137s Agents have converged to Goal 2 after 19 iterations. Use EP: False\n",
      "Iteration 22: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.051911354064941406s Agents have converged to Goal 2 after 22 iterations. Use EP: False\n",
      "Iteration 100: Agents have selected goals [2, 2, 2, 2, 2]. Execution Time: 0.05990433692932129s Agents did not converge to the same goal within the maximum iterations.\n",
      "-------------------\n",
      "Percentage Complete:  98.0 %-------------------\n"
     ]
    }
   ],
   "source": [
    "# Re-define the environment and simulation parameters here\n",
    "interactive = True  # Set to True to display the animation in the notebook\n",
    "args = {}\n",
    "count = 0; flag_converged = True\n",
    "draft_results = []\n",
    "max_iterations = 50\n",
    "convergence_type = 'converge'\n",
    "list_types = ['A','B']\n",
    "number_of_heading_options = 8; number_of_velocity_options = 4\n",
    "env_size = 30  # Environment size\n",
    "iterations_per_episode = 100  # Number of iterations per episode\n",
    "\n",
    "while flag_converged and count < max_iterations:\n",
    "    for use_ep in [True, False]:\n",
    "        for num_agents in np.arange(2, 6, 1):\n",
    "            for num_goals in np.arange(3, 6, 1):\n",
    "                random_seed = count  # Random seed \n",
    "                np.random.seed(random_seed)  # Set random seed\n",
    "                goals = np.random.uniform(1,env_size-1,size=(num_goals, 2))  # Goal positions\n",
    "                agent_positions = np.hstack((np.random.uniform(0,env_size,size=(num_agents, 2)),np.zeros((num_agents,1))))  # Initial agent positions\n",
    "                # Set random goals\n",
    "                args = dict({\n",
    "                'goals': goals, # Goal positions\n",
    "                'agent_types': np.random.choice(list_types,num_agents), # Agent types\n",
    "                'home_base': np.array([0,0]), # Home base position\n",
    "                'agent_positions': agent_positions, # Initial agent positions\n",
    "                'velocity_options': np.linspace(0,1,number_of_velocity_options,endpoint=True), # Velocity options\n",
    "                'num_heading_options': number_of_heading_options, # Number of heading options\n",
    "                'heading_options': np.linspace(-np.pi,np.pi,number_of_heading_options,endpoint=True),\n",
    "                'observation_error_std': 0.0, # Observation error standard deviation\n",
    "                'num_actions': number_of_heading_options*number_of_velocity_options, # Number of actions\n",
    "                'env_size': env_size, # Environment size\n",
    "                'max_distance_measure': env_size + 20,\n",
    "                'max_heading_measure': np.pi, # Maximum heading measure\n",
    "                'prior': np.ones(goals.shape[0]) / goals.shape[0], # Prior belief\n",
    "                'use_ep': use_ep, # Use epistemic planning (2nd order reasoning)\n",
    "                'horizon': 5, # Horizon for free energy checking\n",
    "                'mcts_iterations': 100, # Number of MCTS iterations\n",
    "                'use_mcts': False,\n",
    "                'use_rhc': False, # Use receding horizon control\n",
    "                'use_threading': False, #TODO: Implement threading\n",
    "                'convergence_type': convergence_type, # Convergence type\n",
    "                'dt': 0.1, # Time step\n",
    "                })\n",
    "\n",
    "                # Check convergence for different types of conergence criterion\n",
    "                if args['convergence_type'] == 'exclusive':\n",
    "                    tuple_elements = [i for i in range(goals.shape[0])]\n",
    "                    configurations = list(itertools.permutations(tuple_elements))\n",
    "                    args['reward_configs'] = configurations # Reward configurations if different goals\n",
    "                else:\n",
    "                    args['reward_configs'] = [tuple(np.repeat(i, num_agents)) for i in range(num_goals)]\n",
    "                \n",
    "\n",
    "                # print(\"Initial Prior: \", args['prior'])\n",
    "\n",
    "                # Run the simulation\n",
    "                results = aif.run_simulation(args, iterations_per_episode)\n",
    "                # print(\"Final Prior: \", prior)\n",
    "                # print(\"Agent Types: \", args['agent_types'])\n",
    "\n",
    "                # energy_results, ending_energy = aif.parse_free_energy_scores(avg_nrg_over_time, num_frames)\n",
    "                draft_results.append([random_seed, results['converged'], num_goals, num_agents, args['agent_types'], \n",
    "                                      use_ep ,results['iteration']])\n",
    "    print(\"-------------------\")\n",
    "    print(\"\\rPercentage Complete: \", count/max_iterations*100, \"%\", end=\"\")\n",
    "    print(\"-------------------\")\n",
    "    count += 1\n",
    "\n",
    "# Save the results\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "df = pd.DataFrame(draft_results, columns=['seed','converged','num_goals','num_agents','agent_types','use_ep','num_iters'])    \n",
    "df.to_csv(pwd + 'data/results_isobeliefs_envSize30_2-5Agents_numGoals2-5_NoUncertainty_Convergent{}.csv'.format(current_time), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "energy_results, ending_energy = aif.parse_free_energy_scores(avg_nrg_over_time, num_frames)\n",
    "aif.plot_energy(energy_results, num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final distances:  [[0.02488646 9.98047395]\n",
      " [0.03748569 9.97078675]\n",
      " [0.09155599 9.99940493]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate distance to final goals\n",
    "final_distances = np.zeros((num_agents, goals.shape[0]))\n",
    "for i in range(num_agents):\n",
    "    for j in range(goals.shape[0]):\n",
    "        final_distances[i,j] = np.linalg.norm(final_positions[i,:2] - goals[j,:])\n",
    "print(\"Final distances: \", final_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Azimuth:  [-2.40692159 -2.9485224 ]\n",
      "Relative Azimuth:  [0.1201765  0.10942825]\n",
      "Observed Azimuth:  -2.5305504167886905\n",
      "Salience:  [0.1201765  0.10942825]\n",
      "1.2900073408606396\n"
     ]
    }
   ],
   "source": [
    "# Scratch code for testing\n",
    "\n",
    "goals = np.array([[0,0],[0.,10.]])\n",
    "my_pose = np.array([14.12709979, 12.76192634,  0.])\n",
    "other_pose = np.array([6.30305407,  7.28140647,  0.])\n",
    "saliences = np.zeros(goals.shape[0])\n",
    "goal_azimuths = np.arctan2(goals[:, 1] - my_pose[1], goals[:, 0] - my_pose[0])\n",
    "observed_azimuth = np.arctan2(other_pose[1] - my_pose[1], other_pose[0] - my_pose[0])\n",
    "relative_azimuths = np.abs((goal_azimuths - observed_azimuth + np.pi) % (2 * np.pi) - np.pi)\n",
    "azimuth_salience = 1./8 * np.exp(- relative_azimuths / np.pi)  # normalize and invert to make smaller angles more salient\n",
    "saliences += azimuth_salience\n",
    "# Compute if observed robot is heading towards the goal\n",
    "# heading_to_goal = (np.arctan2(goals[:, 1] - observation['position'][1], goals[:, 0] - observation['position'][0]) - observation['heading'] + np.pi) % (2 * np.pi) - np.pi\n",
    "# heading_salience = 1./8 * np.exp(- np.abs(heading_to_goal) / np.pi)\n",
    "# saliences += heading_salience\n",
    "\n",
    "\n",
    "print(\"Goal Azimuth: \", goal_azimuths)\n",
    "print(\"Relative Azimuth: \", azimuth_salience)\n",
    "print(\"Observed Azimuth: \", observed_azimuth)\n",
    "print(\"Salience: \", saliences)\n",
    "# print(\"Heading Salience: \", heading_salience)\n",
    "print(np.exp(0.8/np.pi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
